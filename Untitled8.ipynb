{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elizabethreji/mental-well-being-chatbot/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kSfBI_6LJ5dy",
        "outputId": "ecb17bd3-f6ca-462c-e160-086dbb1996cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio==3.50.2\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.2)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (5.5.0)\n",
            "Collecting fastapi (from gradio==3.50.2)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==3.50.2)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.2)\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.30.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio==3.50.2)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.10.0)\n",
            "Collecting numpy~=1.0 (from gradio==3.50.2)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m779.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.2.2)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio==3.50.2)\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.11.1)\n",
            "Collecting pydub (from gradio==3.50.2)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart (from gradio==3.50.2)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (6.0.2)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.32.3)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.50.2)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (4.13.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.50.2)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2)\n",
            "  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==0.6.1->gradio==3.50.2) (2025.3.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (1.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (3.18.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (2025.1.31)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (0.14.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi->gradio==3.50.2)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.50.2) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.50.2) (1.0.7)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.50.2) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->gradio==3.50.2) (1.3.1)\n",
            "Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, semantic-version, python-multipart, pillow, numpy, markupsafe, ffmpy, aiofiles, starlette, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.9.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-3.50.2 gradio-client-0.6.1 markupsafe-2.1.5 numpy-1.26.4 pillow-10.4.0 pydub-0.25.1 python-multipart-0.0.20 semantic-version-2.10.0 starlette-0.46.1 uvicorn-0.34.0 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "6ce9c9de056243eeb512f2149fb1c641"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: firebase-admin in /usr/local/lib/python3.11/dist-packages (6.7.0)\n",
            "Requirement already satisfied: cachecontrol>=0.12.14 in /usr/local/lib/python3.11/dist-packages (from firebase-admin) (0.14.2)\n",
            "Requirement already satisfied: google-api-python-client>=1.7.8 in /usr/local/lib/python3.11/dist-packages (from firebase-admin) (2.164.0)\n",
            "Requirement already satisfied: google-cloud-storage>=1.37.1 in /usr/local/lib/python3.11/dist-packages (from firebase-admin) (2.19.0)\n",
            "Requirement already satisfied: pyjwt>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.5.0->firebase-admin) (2.10.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=1.22.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2.24.2)\n",
            "Requirement already satisfied: google-cloud-firestore>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from firebase-admin) (2.20.1)\n",
            "Requirement already satisfied: requests>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from cachecontrol>=0.12.14->firebase-admin) (2.32.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from cachecontrol>=0.12.14->firebase-admin) (1.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.69.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.71.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (4.1.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-firestore>=2.19.0->firebase-admin) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.37.1->firebase-admin) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage>=1.37.1->firebase-admin) (1.7.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.5.0->firebase-admin) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase-admin) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=1.7.8->firebase-admin) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.14->firebase-admin) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.14->firebase-admin) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.14->firebase-admin) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.14->firebase-admin) (2025.1.31)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase-admin) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (0.6.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.49)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.22)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (4.13.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.3.49)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.22.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.13.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.3.22)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.10.16)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.3.0)\n",
            "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading groq-0.22.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.22.0 langchain-groq-0.3.2\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.1)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.23.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.16)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Collecting opentelemetry-util-http==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.0.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.31.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.23.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53800 sha256=edf2021f8f048edaecaf7faa23412856109e1b5c044cae6982fcccc7357a8b82\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, python-dotenv, pyproject_hooks, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, build, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.46.1\n",
            "    Uninstalling starlette-0.46.1:\n",
            "      Successfully uninstalled starlette-0.46.1\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.115.12\n",
            "    Uninstalling fastapi-0.115.12:\n",
            "      Successfully uninstalled fastapi-0.115.12\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.0 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.0 opentelemetry-exporter-otlp-proto-common-1.31.1 opentelemetry-exporter-otlp-proto-grpc-1.31.1 opentelemetry-instrumentation-0.52b1 opentelemetry-instrumentation-asgi-0.52b1 opentelemetry-instrumentation-fastapi-0.52b1 opentelemetry-proto-1.31.1 opentelemetry-util-http-0.52b1 overrides-7.7.0 posthog-3.23.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 starlette-0.45.3 uvloop-0.21.0 watchfiles-1.0.4\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.11/dist-packages (0.30.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.3) (2025.1.31)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain<1.0.0,>=0.3.23 (from langchain-community)\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.22)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.49\n",
            "    Uninstalling langchain-core-0.3.49:\n",
            "      Successfully uninstalled langchain-core-0.3.49\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.7\n",
            "    Uninstalling langchain-text-splitters-0.3.7:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.22\n",
            "    Uninstalling langchain-0.3.22:\n",
            "      Successfully uninstalled langchain-0.3.22\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.51 langchain-text-splitters-0.3.8 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio==3.50.2\n",
        "!pip install torch torchaudio\n",
        "!pip install transformers\n",
        "!pip install firebase-admin\n",
        "!pip install langchain\n",
        "!pip install langchain-groq\n",
        "!pip install chromadb\n",
        "!pip install sentence-transformers\n",
        "!pip install \"huggingface-hub>=0.19.3\"\n",
        "!pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjN0MPZ0QBZK",
        "outputId": "401a2cc8-8d5b-4afb-d1a4-075c2237c32a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.93-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (10.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.18.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.8.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.1.0)\n",
            "Collecting flask-cors>=4.0.1 (from deepface)\n",
            "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/gunicorn/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.4.0->deepface) (3.0.1)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (3.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface)\n",
            "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2025.1.31)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.13.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (2.1.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Downloading deepface-0.0.93-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.6/108.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=f7e96be93ce3c752bfb16fc540c9ba77093cb8968b041c624da342791386f668\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: lz4, gunicorn, fire, mtcnn, flask-cors, retina-face, deepface\n",
            "Successfully installed deepface-0.0.93 fire-0.7.0 flask-cors-5.0.1 gunicorn-23.0.0 lz4-4.4.4 mtcnn-1.0.0 retina-face-0.0.17\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install deepface\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viIAKoQzLB4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ec9399e-d043-4656-c8d5-6b3ded679aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 3.50.2 requires numpy~=1.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting torch==2.6.0 (from torchaudio)\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting filelock (from torch==2.6.0->torchaudio)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0->torchaudio)\n",
            "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch==2.6.0->torchaudio)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.6.0->torchaudio)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0->torchaudio)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchaudio)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchaudio)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchaudio)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchaudio)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchaudio)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchaudio)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0->torchaudio)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0->torchaudio)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0->torchaudio)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0->torchaudio)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchaudio\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 3.50.2 requires markupsafe~=2.0, but you have markupsafe 3.0.2 which is incompatible.\n",
            "gradio 3.50.2 requires numpy~=1.0, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "google-genai 1.9.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 torchaudio-2.6.0 triton-3.2.0 typing-extensions-4.13.1\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting filelock (from transformers)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting packaging>=20.0 (from transformers)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from transformers)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
            "  Using cached typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading transformers-4.51.0-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.2/481.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 3.50.2 requires numpy~=1.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "google-genai 1.9.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.1 idna-3.10 numpy-2.2.4 packaging-24.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.0 typing-extensions-4.13.1 urllib3-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi"
                ]
              },
              "id": "3632797c711f455eb82d51ded1ace858"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Using cached transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting tqdm (from sentence-transformers)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting torch>=1.11.0 (from sentence-transformers)\n",
            "  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting scikit-learn (from sentence-transformers)\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scipy (from sentence-transformers)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
            "  Using cached huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting Pillow (from sentence-transformers)\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
            "  Using cached typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting packaging>=20.9 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pyyaml>=5.1 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting requests (from huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting numpy>=1.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.6/340.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
            "Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached transformers-4.51.0-py3-none-any.whl (10.4 MB)\n",
            "Using cached typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
            "Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Installing collected packages: triton, nvidia-cusparselt-cu12, mpmath, urllib3, typing_extensions, tqdm, threadpoolctl, sympy, safetensors, regex, pyyaml, Pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, joblib, idna, fsspec, filelock, charset-normalizer, certifi, scipy, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, scikit-learn, nvidia-cusolver-cu12, huggingface-hub, torch, tokenizers, transformers, sentence-transformers\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 3.50.2 requires markupsafe~=2.0, but you have markupsafe 3.0.2 which is incompatible.\n",
            "gradio 3.50.2 requires numpy~=1.0, but you have numpy 2.2.4 which is incompatible.\n",
            "gradio 3.50.2 requires pillow<11.0,>=8.0, but you have pillow 11.1.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "google-genai 1.9.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 Pillow-10.4.0 certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.1 idna-3.10 jinja2-3.1.6 joblib-1.4.2 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 packaging-24.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-4.0.2 sympy-1.13.1 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.6.0 tqdm-4.67.1 transformers-4.51.0 triton-3.2.0 typing_extensions-4.13.1 urllib3-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi"
                ]
              },
              "id": "ab63d7d6892244b3975ac05555376161"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install numpy --upgrade --ignore-installed\n",
        "!pip install torchaudio --upgrade --ignore-installed\n",
        "!pip install transformers --upgrade --ignore-installed\n",
        "!pip install sentence-transformers --upgrade --ignore-installed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "6WGwh-uIpbfi",
        "outputId": "d64f758d-8a8a-49be-c8f5-fa126aed1845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ASR model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ASR model loaded successfully\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://b5892e2edd6074c13c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://b5892e2edd6074c13c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7863 <> https://b5892e2edd6074c13c.gradio.live\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import pipeline\n",
        "import os\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, auth, firestore\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from datetime import datetime\n",
        "import random\n",
        "\n",
        "\n",
        "# Predefined wellness tips\n",
        "WELLNESS_TIPS = [\n",
        "    \"Take a few deep breaths when feeling stressed.\",\n",
        "    \"Stay hydrated throughout the day.\",\n",
        "    \"Try to get at least 7-8 hours of sleep each night.\",\n",
        "    \"Take short breaks during work to stretch and move.\",\n",
        "    \"Practice gratitude by noting three things you're thankful for.\",\n",
        "    \"Spend time in nature when possible.\",\n",
        "    \"Limit screen time before bed for better sleep.\",\n",
        "    \"Connect with a friend or family member today.\",\n",
        "    \"Try a 5-minute meditation to clear your mind.\",\n",
        "    \"Move your body for at least 30 minutes today.\"\n",
        "]\n",
        "\n",
        "# Initialize Firebase only once\n",
        "def initialize_firebase():\n",
        "    if not firebase_admin._apps:\n",
        "        try:\n",
        "            cred = credentials.Certificate(\"/content/data/firebase_credentials.json\")  # Update this path!\n",
        "            firebase_admin.initialize_app(cred)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Firebase initialization error: {e}\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Initialize Firestore\n",
        "def get_firestore_db():\n",
        "    if initialize_firebase():\n",
        "        return firestore.client()\n",
        "    return None\n",
        "\n",
        "# Load ASR Model\n",
        "def load_asr_model():\n",
        "    try:\n",
        "        return pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading ASR model: {e}\")\n",
        "        return None\n",
        "\n",
        "# Get random wellness tip\n",
        "def get_daily_tip():\n",
        "    \"\"\"Returns a random wellness tip\"\"\"\n",
        "    return random.choice(WELLNESS_TIPS)\n",
        "\n",
        "# Initialize LLM with mental wellbeing focus\n",
        "def initialize_llm(api_key=None, temperature=0.2):\n",
        "    try:\n",
        "        # Use provided API key or default to environment variable\n",
        "        groq_api_key = api_key or \"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\"\n",
        "        llm = ChatGroq(\n",
        "            temperature=temperature,  # Slightly increased for more natural responses\n",
        "            groq_api_key=groq_api_key,\n",
        "            model_name=\"llama-3.3-70b-versatile\"\n",
        "        )\n",
        "        return llm\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing LLM: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create or load vector database\n",
        "def create_vector_db(db_path=\"/content/chroma_db\"):\n",
        "    try:\n",
        "        if not os.path.exists(db_path):\n",
        "            os.makedirs(db_path)\n",
        "\n",
        "        embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "        return Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating vector database: {e}\")\n",
        "        return None\n",
        "\n",
        "# Set up QA chain with a focus on context-aware and psychiatrist-like responses\n",
        "def setup_qa_chain(vector_db, llm):\n",
        "    \"\"\"Set up the QA retrieval chain with a focus on providing context-aware and psychiatrist-like responses\"\"\"\n",
        "    if vector_db is None or llm is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        retriever = vector_db.as_retriever()\n",
        "        prompt_template = \"\"\"You are a compassionate and knowledgeable mental wellbeing assistant named Serene, akin to a psychiatrist.\n",
        "\n",
        "        Your primary goal is to provide supportive, empathetic, and insightful responses that help the user improve their mental wellbeing.\n",
        "        Always maintain a warm, understanding tone and never judge the user.\n",
        "\n",
        "        Guidelines for your responses:\n",
        "        - Begin with validation of the user's feelings (\"I understand that feeling...\", \"That sounds really challenging...\")\n",
        "        - Use a warm, conversational tone that shows genuine care\n",
        "        - Offer specific, actionable suggestions tailored to their situation, not generic advice\n",
        "        - Ask thoughtful follow-up questions to show you're really listening\n",
        "        - Share relevant coping strategies or techniques that might help their specific situation\n",
        "        - When appropriate, gently normalize their experiences (\"Many people feel this way...\")\n",
        "        - Always respond with empathy first, then helpful information second\n",
        "        - Provide deeper insights and reflective questions to encourage self-awareness and personal growth\n",
        "\n",
        "        For different emotional states:\n",
        "        - When user seems anxious: Use calming language, offer grounding techniques, validate their worries\n",
        "        - When user seems sad: Show compassion, acknowledge the pain, offer gentle encouragement\n",
        "        - When user seems frustrated: Validate their feelings, show patience, offer perspective\n",
        "        - When user seems confused: Provide clarity, break down concepts, be reassuring\n",
        "\n",
        "        If the user appears to be in crisis, gently suggest they reach out to a mental health professional or crisis hotline,\n",
        "        but continue to engage with them supportively.\n",
        "\n",
        "        Relevant context from your knowledge base:\n",
        "        {context}\n",
        "\n",
        "        User: {question}\n",
        "\n",
        "        Serene:\"\"\"\n",
        "\n",
        "        PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "        qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=retriever,\n",
        "            chain_type_kwargs={\"prompt\": PROMPT}\n",
        "        )\n",
        "\n",
        "        return qa_chain\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up QA chain: {e}\")\n",
        "        return None\n",
        "\n",
        "# Generate chatbot response with crisis detection and coping strategies\n",
        "def chatbot_response(db, user_id, user_input, history, vector_db=None, llm=None):\n",
        "    \"\"\" Generate chatbot response and store it in chat history \"\"\"\n",
        "    try:\n",
        "        # Initialize components if not provided\n",
        "        if vector_db is None:\n",
        "            vector_db = create_vector_db()\n",
        "\n",
        "        if llm is None:\n",
        "            llm = initialize_llm()\n",
        "\n",
        "        qa_chain = setup_qa_chain(vector_db, llm)\n",
        "\n",
        "        # Check for crisis keywords\n",
        "        is_crisis = check_for_crisis(user_input)\n",
        "\n",
        "        if is_crisis:\n",
        "            response = \"\"\"I notice you've mentioned something concerning. If you're in crisis, please consider reaching out to a crisis helpline:\n",
        "            - National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "            - Crisis Text Line: Text HOME to 741741 📱\n",
        "\n",
        "            These services are available 24/7 and provide confidential support. Would you like to talk about what you're feeling right now? I'm here to listen. 💬\"\"\"\n",
        "        elif qa_chain is None:\n",
        "            response = \"I'm having trouble connecting to my knowledge base. Let's focus on how you're feeling today. What would help you feel more at ease right now? 🧘\"\n",
        "        else:\n",
        "            # Generate a response using the QA chain\n",
        "            raw_response = qa_chain.run(user_input)\n",
        "\n",
        "            # Enhance with empathy, context-awareness, and coping strategies\n",
        "            response = f\"I understand that you're feeling {user_input}. {raw_response} 🤗\"\n",
        "\n",
        "            # Add specific coping strategies based on emotional state\n",
        "            if \"anxious\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with anxiety:\\n- Practice deep breathing exercises 🧘\\n- Try grounding techniques like focusing on your senses 🌱\\n- Take a short walk to clear your mind 🚶\\n- Write down your thoughts in a journal 📓\"\n",
        "            elif \"sad\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with sadness:\\n- Reach out to a friend or family member 📞\\n- Engage in a hobby or activity you enjoy 🎨\\n- Practice self-compassion and be kind to yourself 💖\\n- Reflect on positive memories or experiences 📝\"\n",
        "            elif \"frustrated\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with frustration:\\n- Take a few deep breaths and count to ten 🧘\\n- Step away from the situation and take a break 🌳\\n- Talk it out with someone you trust 🗣️\\n- Focus on solutions rather than problems 🔍\"\n",
        "\n",
        "        # Update history\n",
        "        updated_history = history.copy()\n",
        "        updated_history.append((user_input, response))\n",
        "\n",
        "        # Store in Firebase if available\n",
        "        if db is not None and user_id:\n",
        "            store_chat_history(db, user_id, updated_history)\n",
        "\n",
        "        return user_input, response, updated_history\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return user_input, \"Sorry, I encountered an error while processing your request.\", history\n",
        "\n",
        "# Transcribe audio to text\n",
        "def transcribe_audio(audio_path, asr_model):\n",
        "    if not audio_path or not os.path.exists(audio_path) or asr_model is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        transcription = asr_model(audio_path)[\"text\"]\n",
        "        return transcription\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing audio: {e}\")\n",
        "        return None\n",
        "\n",
        "# Store chat history in Firebase with timestamps\n",
        "def store_chat_history(db, user_id, history):\n",
        "    if db is None or not user_id:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        formatted_history = [{\"message\": msg, \"response\": resp, \"timestamp\": timestamp} for msg, resp in history]\n",
        "        db.collection(\"chat_history\").document(user_id).set({\"history\": formatted_history})\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error storing chat history: {e}\")\n",
        "        return False\n",
        "\n",
        "# Fetch chat history from Firebase\n",
        "def fetch_chat_history(db, user_id):\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            chat_list = chats.to_dict().get(\"history\", [])\n",
        "            return [(chat[\"message\"], chat[\"response\"]) for chat in chat_list]\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching chat history: {e}\")\n",
        "        return []\n",
        "\n",
        "# Get chat sessions by timestamp\n",
        "def get_chat_sessions(db, user_id):\n",
        "    \"\"\" Get list of chat sessions with timestamps \"\"\"\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            chat_list = chats.to_dict().get(\"history\", [])\n",
        "            if chat_list:\n",
        "                # Group by timestamps to create session names\n",
        "                timestamps = set([chat.get(\"timestamp\", \"Unknown\") for chat in chat_list])\n",
        "                return list(timestamps)\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting chat sessions: {e}\")\n",
        "        return []\n",
        "\n",
        "# Check for crisis keywords in user input\n",
        "def check_for_crisis(user_input):\n",
        "    crisis_keywords = [\"suicide\", \"kill myself\", \"end my life\", \"don't want to live\"]\n",
        "    return any(keyword in user_input.lower() for keyword in crisis_keywords)\n",
        "\n",
        "# Generate chatbot response with crisis detection\n",
        "\n",
        "def process_input(db, user_id, user_message, audio_file, history, asr_model, vector_db, llm):\n",
        "    if audio_file:\n",
        "        transcribed_text = transcribe_audio(audio_file, asr_model)\n",
        "        if transcribed_text:\n",
        "            _, _, updated_history = chatbot_response(db, user_id, transcribed_text, history, vector_db, llm)\n",
        "            return updated_history, \"\", None\n",
        "\n",
        "    if user_message:\n",
        "        _, _, updated_history = chatbot_response(db, user_id, user_message, history, vector_db, llm)\n",
        "        return updated_history, \"\", None\n",
        "\n",
        "    return history, \"\", None\n",
        "\n",
        "# Store conversation in Firestore\n",
        "def store_conversation(db, user_id, conversation_id, message, response):\n",
        "    if db is None or not user_id:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        conv_ref = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").document(conversation_id)\n",
        "        conv_doc = conv_ref.get()\n",
        "\n",
        "        if conv_doc.exists:\n",
        "            conv_data = conv_doc.to_dict()\n",
        "            messages = conv_data.get(\"messages\", [])\n",
        "            messages.append({\n",
        "                \"user_message\": message,\n",
        "                \"assistant_response\": response,\n",
        "                \"timestamp\": timestamp\n",
        "            })\n",
        "            conv_ref.update({\n",
        "                \"messages\": messages,\n",
        "                \"last_updated\": timestamp,\n",
        "                \"title\": message[:30] + \"...\" if len(message) > 30 else message\n",
        "            })\n",
        "        else:\n",
        "            conv_ref.set({\n",
        "                \"messages\": [{\n",
        "                    \"user_message\": message,\n",
        "                    \"assistant_response\": response,\n",
        "                    \"timestamp\": timestamp\n",
        "                }],\n",
        "                \"created_at\": timestamp,\n",
        "                \"last_updated\": timestamp,\n",
        "                \"title\": message[:30] + \"...\" if len(message) > 30 else message\n",
        "            })\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error storing conversation: {e}\")\n",
        "        return False\n",
        "\n",
        "# Get all conversations for a user\n",
        "def get_all_conversations(db, user_id):\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        conversations = []\n",
        "        conv_refs = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").order_by(\"last_updated\", direction=firestore.Query.DESCENDING)\n",
        "\n",
        "        for conv in conv_refs.stream():\n",
        "            conv_data = conv.to_dict()\n",
        "            conversations.append({\n",
        "                \"id\": conv.id,\n",
        "                \"title\": conv_data.get(\"title\", \"Unnamed conversation\"),\n",
        "                \"last_updated\": conv_data.get(\"last_updated\", \"Unknown date\"),\n",
        "                \"message_count\": len(conv_data.get(\"messages\", []))\n",
        "            })\n",
        "        return conversations\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching conversations: {e}\")\n",
        "        return []\n",
        "\n",
        "# Get a specific conversation by ID\n",
        "def get_conversation_by_id(db, user_id, conversation_id):\n",
        "    if db is None or not user_id or not conversation_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        conv_ref = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").document(conversation_id)\n",
        "        conv_doc = conv_ref.get()\n",
        "\n",
        "        if conv_doc.exists:\n",
        "            conv_data = conv_doc.to_dict()\n",
        "            messages = conv_data.get(\"messages\", [])\n",
        "            return [(msg[\"user_message\"], msg[\"assistant_response\"]) for msg in messages]\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching conversation: {e}\")\n",
        "        return []\n",
        "\n",
        "# Authenticate user via Firebase\n",
        "def authenticate_user(db, email, password):\n",
        "    try:\n",
        "        user = auth.get_user_by_email(email)\n",
        "        user_id = user.uid\n",
        "\n",
        "        # Fetch chat sessions\n",
        "        chat_sessions = get_chat_sessions(db, user_id)\n",
        "        daily_tip = get_daily_tip()\n",
        "\n",
        "        return True, user_id, \"Login successful!\", chat_sessions, daily_tip\n",
        "    except Exception as e:\n",
        "        print(f\"Authentication error: {e}\")\n",
        "        return False, \"\", f\"Login failed: {str(e)}\", [], \"\"\n",
        "\n",
        "# Register a new user\n",
        "def register_user(db, email, password):\n",
        "    try:\n",
        "        # Check if user already exists\n",
        "        try:\n",
        "            existing_user = auth.get_user_by_email(email)\n",
        "            if existing_user:\n",
        "                return False, \"\", \"Email already in use. Please log in instead.\", [], \"\"\n",
        "        except:\n",
        "            # User doesn't exist, proceed with registration\n",
        "            pass\n",
        "\n",
        "        # Create new user\n",
        "        user = auth.create_user(\n",
        "            email=email,\n",
        "            password=password,\n",
        "            email_verified=False\n",
        "        )\n",
        "\n",
        "        user_id = user.uid\n",
        "\n",
        "        # Initialize user data in Firestore\n",
        "        db.collection(\"user_data\").document(user_id).set({\n",
        "            \"email\": email,\n",
        "            \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        })\n",
        "\n",
        "        daily_tip = get_daily_tip()\n",
        "\n",
        "        return True, user_id, \"Registration successful! Welcome!\", [], daily_tip\n",
        "    except Exception as e:\n",
        "        print(f\"Registration error: {e}\")\n",
        "        return False, \"\", f\"Registration failed: {str(e)}\", [], \"\"\n",
        "\n",
        "# Load custom theme for mental wellbeing UI\n",
        "def load_theme():\n",
        "    \"\"\" Load the custom theme for the mental wellbeing chatbot \"\"\"\n",
        "    return gr.themes.Soft(\n",
        "        primary_hue=\"teal\",\n",
        "        secondary_hue=\"blue\",\n",
        "        neutral_hue=\"slate\",\n",
        "        radius_size=gr.themes.sizes.radius_md,\n",
        "        font=[gr.themes.GoogleFont(\"Nunito\"), gr.themes.GoogleFont(\"Quicksand\"), \"system-ui\", \"sans-serif\"]\n",
        "    )\n",
        "\n",
        "# Load chat by session timestamp\n",
        "def load_chat_by_session(db, user_id, session_timestamp):\n",
        "    if not session_timestamp or db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            all_chats = chats.to_dict().get(\"history\", [])\n",
        "            session_chats = [(chat[\"message\"], chat[\"response\"])\n",
        "                            for chat in all_chats\n",
        "                            if chat.get(\"timestamp\") == session_timestamp]\n",
        "            return session_chats\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading chat session: {e}\")\n",
        "        return []\n",
        "def analyze_emotional_content(text):\n",
        "    \"\"\"\n",
        "    Analyzes text for emotional content and returns detected emotions.\n",
        "\n",
        "    Args:\n",
        "        text (str): The user's message text\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing detected emotions and their confidence scores\n",
        "    \"\"\"\n",
        "    # Define emotion keywords for basic detection\n",
        "    emotion_keywords = {\n",
        "        'anxious': ['anxious', 'worried', 'nervous', 'panic', 'fear', 'stress', 'overwhelm', 'scared'],\n",
        "        'sad': ['sad', 'depressed', 'unhappy', 'miserable', 'grief', 'blue', 'down', 'heartbroken', 'upset'],\n",
        "        'angry': ['angry', 'frustrated', 'mad', 'furious', 'irritated', 'annoyed', 'rage', 'hate'],\n",
        "        'happy': ['happy', 'joy', 'excited', 'delighted', 'pleased', 'content', 'grateful', 'thankful'],\n",
        "        'neutral': ['okay', 'fine', 'alright', 'neutral']\n",
        "    }\n",
        "\n",
        "    # Initialize results with default values\n",
        "    results = {\n",
        "        'primary_emotion': 'neutral',\n",
        "        'confidence': 0.0,\n",
        "        'detected_emotions': {},\n",
        "        'intensity': 'low'\n",
        "    }\n",
        "\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Count emotion keywords in text\n",
        "    emotion_counts = {}\n",
        "    max_count = 0\n",
        "    primary_emotion = 'neutral'\n",
        "\n",
        "    for emotion, keywords in emotion_keywords.items():\n",
        "        count = sum(1 for keyword in keywords if keyword in text_lower)\n",
        "        if count > 0:\n",
        "            emotion_counts[emotion] = count\n",
        "            if count > max_count:\n",
        "                max_count = count\n",
        "                primary_emotion = emotion\n",
        "\n",
        "    # If no emotions detected, return neutral\n",
        "    if not emotion_counts:\n",
        "        return results\n",
        "\n",
        "    # Calculate rough confidence based on keyword frequency\n",
        "    total_keywords = sum(emotion_counts.values())\n",
        "\n",
        "    # Set primary emotion and confidence\n",
        "    results['primary_emotion'] = primary_emotion\n",
        "    results['confidence'] = min(0.95, max_count / (len(text.split()) * 0.5)) if total_keywords > 0 else 0.4\n",
        "    results['detected_emotions'] = emotion_counts\n",
        "\n",
        "    # Determine intensity based on modifier words and punctuation\n",
        "    intensity_markers = ['very', 'extremely', 'so', 'really', 'completely', 'absolutely', 'totally']\n",
        "    exclamation_count = text.count('!')\n",
        "    uppercase_ratio = sum(1 for c in text if c.isupper()) / max(len(text), 1)\n",
        "\n",
        "    intensity_score = sum(1 for marker in intensity_markers if marker in text_lower) + exclamation_count\n",
        "    intensity_score += 3 if uppercase_ratio > 0.3 else 0\n",
        "\n",
        "    if intensity_score > 3:\n",
        "        results['intensity'] = 'high'\n",
        "    elif intensity_score > 1:\n",
        "        results['intensity'] = 'medium'\n",
        "    else:\n",
        "        results['intensity'] = 'low'\n",
        "\n",
        "    return results\n",
        "\n",
        "# Function to check for crisis keywords with severity assessment\n",
        "def check_for_crisis_and_severity(text):\n",
        "    \"\"\"\n",
        "    Checks user input for crisis indicators and assesses severity.\n",
        "\n",
        "    Args:\n",
        "        text (str): The user's message text\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains crisis detection results and severity level\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Define crisis keywords with severity levels\n",
        "    high_severity_keywords = [\n",
        "        'kill myself', 'suicide', 'end my life', 'want to die',\n",
        "        'take my life', 'harm myself', 'hurt myself badly'\n",
        "    ]\n",
        "\n",
        "    medium_severity_keywords = [\n",
        "        'don\\'t want to live', 'no reason to live', 'better off dead',\n",
        "        'can\\'t go on', 'giving up', 'no hope', 'no future',\n",
        "        'self harm', 'cutting myself', 'hurting myself'\n",
        "    ]\n",
        "\n",
        "    low_severity_keywords = [\n",
        "        'hopeless', 'worthless', 'nothing matters', 'what\\'s the point',\n",
        "        'exhausted', 'can\\'t handle this', 'too much pain'\n",
        "    ]\n",
        "\n",
        "    # Check for high severity keywords (immediate crisis)\n",
        "    for keyword in high_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'high', 'keyword': keyword}\n",
        "\n",
        "    # Check for medium severity keywords (concerning)\n",
        "    for keyword in medium_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'medium', 'keyword': keyword}\n",
        "\n",
        "    # Check for low severity keywords (distress)\n",
        "    for keyword in low_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'low', 'keyword': keyword}\n",
        "\n",
        "    # No crisis keywords detected\n",
        "    return {'detected': False, 'severity': 'none', 'keyword': None}\n",
        "\n",
        "# Function to generate crisis responses based on severity\n",
        "def generate_crisis_response(severity, emotions):\n",
        "    \"\"\"\n",
        "    Generates appropriate responses for different crisis severity levels.\n",
        "\n",
        "    Args:\n",
        "        severity (str): The detected crisis severity level\n",
        "        emotions (dict): The emotional analysis results\n",
        "\n",
        "    Returns:\n",
        "        str: A compassionate response appropriate to the severity level\n",
        "    \"\"\"\n",
        "    if severity == 'high':\n",
        "        return \"\"\"I'm really concerned about what you're sharing. If you're having thoughts of harming yourself, please reach out to a crisis helpline immediately:\n",
        "\n",
        "• National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "• Crisis Text Line: Text HOME to 741741 📱\n",
        "• Or go to your nearest emergency room\n",
        "\n",
        "These services have trained professionals available 24/7 who can help you through this difficult time. Your life matters, and support is available. Would you like to talk more about what you're experiencing right now?\"\"\"\n",
        "\n",
        "    elif severity == 'medium':\n",
        "        return \"\"\"I hear that you're going through a really difficult time, and I'm concerned about what you're sharing. It's important to talk to someone who can provide professional support:\n",
        "\n",
        "• National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "• Crisis Text Line: Text HOME to 741741 📱\n",
        "\n",
        "Would it be possible for you to reach out to a mental health professional or trusted person in your life today? Your feelings are valid, and support is available. I'm here to listen if you'd like to share more.\"\"\"\n",
        "\n",
        "    elif severity == 'low':\n",
        "        primary_emotion = emotions.get('primary_emotion', 'distress')\n",
        "\n",
        "        responses = {\n",
        "            'anxious': \"I can hear the anxiety in your message, and that sounds really challenging. When everything feels overwhelming, it's important to be gentle with yourself. Would it help to talk about specific things that are causing you to feel this way?\",\n",
        "            'sad': \"I'm sorry you're feeling such sadness right now. It's okay to not be okay sometimes, and your feelings are valid. Would you like to share more about what's contributing to these feelings?\",\n",
        "            'angry': \"I can sense your frustration and anger. These are completely valid emotions, especially when dealing with difficult situations. Would it help to talk more about what's triggering these feelings?\",\n",
        "            'neutral': \"It sounds like you're going through a difficult time. Everyone struggles sometimes, and it's okay to reach out for support. Would talking to a mental health professional be an option for you?\"\n",
        "        }\n",
        "\n",
        "        base_response = responses.get(primary_emotion, responses['neutral'])\n",
        "        return base_response + \"\\n\\nIf you ever feel these thoughts becoming more intense or have thoughts of harming yourself, please reach out to a crisis helpline like the National Suicide Prevention Lifeline at 988.\"\n",
        "\n",
        "    else:\n",
        "        # Default response if severity assessment fails\n",
        "        return \"I notice you may be going through a difficult time. If you're feeling overwhelmed, talking to a mental health professional can really help. Would you like to share more about what you're experiencing?\"\n",
        "\n",
        "# Function to enhance responses with empathy based on emotions\n",
        "def enhance_response_with_empathy(base_response, emotions):\n",
        "    \"\"\"\n",
        "    Enhances LLM responses with appropriate empathetic elements based on detected emotions.\n",
        "\n",
        "    Args:\n",
        "        base_response (str): The original LLM response\n",
        "        emotions (dict): The emotional analysis results\n",
        "\n",
        "    Returns:\n",
        "        str: Enhanced response with appropriate empathetic elements\n",
        "    \"\"\"\n",
        "    primary_emotion = emotions.get('primary_emotion', 'neutral')\n",
        "    intensity = emotions.get('intensity', 'low')\n",
        "\n",
        "    # Add appropriate emoji based on emotion and intensity\n",
        "    emotion_emojis = {\n",
        "        'anxious': ['😟', '😥', '😰'],  # Low, Medium, High\n",
        "        'sad': ['😔', '😢', '😭'],\n",
        "        'angry': ['😒', '😠', '😡'],\n",
        "        'happy': ['🙂', '😊', '😄'],\n",
        "        'neutral': ['🙂', '😊', '💭']\n",
        "    }\n",
        "\n",
        "    intensity_index = {'low': 0, 'medium': 1, 'high': 2}.get(intensity, 0)\n",
        "    emoji = emotion_emojis.get(primary_emotion, emotion_emojis['neutral'])[intensity_index]\n",
        "\n",
        "    # Add empathetic prefix based on emotion\n",
        "    empathy_prefixes = {\n",
        "        'anxious': [\"I understand that anxiety can be overwhelming. \",\n",
        "                   \"It makes sense that you're feeling anxious. \",\n",
        "                   \"That kind of worry is really challenging to navigate. \"],\n",
        "        'sad': [\"I hear the sadness in your message. \",\n",
        "               \"I'm sorry you're feeling down right now. \",\n",
        "               \"It's okay to feel sad sometimes. \"],\n",
        "        'angry': [\"I can sense your frustration. \",\n",
        "                 \"I understand why that would be upsetting. \",\n",
        "                 \"It's natural to feel frustrated in that situation. \"],\n",
        "        'happy': [\"It's wonderful to hear that positivity! \",\n",
        "                 \"I'm glad you're feeling good. \",\n",
        "                 \"That's really great to hear. \"],\n",
        "        'neutral': [\"I appreciate you sharing that. \",\n",
        "                   \"Thank you for telling me about this. \",\n",
        "                   \"I'm here to listen. \"]\n",
        "    }\n",
        "\n",
        "    import random\n",
        "    prefix = random.choice(empathy_prefixes.get(primary_emotion, empathy_prefixes['neutral']))\n",
        "\n",
        "    # Combine elements\n",
        "    enhanced_response = prefix + base_response\n",
        "\n",
        "    # Add emoji only if it's not already a very long response\n",
        "    if len(enhanced_response) < 500:\n",
        "        enhanced_response += f\" {emoji}\"\n",
        "\n",
        "    return enhanced_response\n",
        "# Main application class\n",
        "class WellbeingChatbotApp:\n",
        "    def __init__(self):\n",
        "        # Initialize components\n",
        "        self.db = get_firestore_db()\n",
        "\n",
        "        # More specific ASR model loading with better error handling\n",
        "        print(\"Loading ASR model...\")\n",
        "        try:\n",
        "            self.asr_model = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
        "            print(\"ASR model loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading ASR model: {str(e)}\")\n",
        "            print(\"Using fallback for ASR (text-only functionality)\")\n",
        "            self.asr_model = None\n",
        "\n",
        "        self.vector_db = create_vector_db()\n",
        "        self.llm = initialize_llm(temperature=0.2)\n",
        "        self.theme = load_theme()\n",
        "        self.current_user = \"Guest\"\n",
        "        self.current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        # Define UI\n",
        "        self.interface = self.build_interface()\n",
        "\n",
        "    # Add this new method to process audio inputs specifically\n",
        "    def process_audio_input(self, user_id, user_message, audio_file, history, conversation_id):\n",
        "        \"\"\"Handle audio input specifically\"\"\"\n",
        "        try:\n",
        "            if audio_file is None:\n",
        "                return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "            # Transcribe audio to text\n",
        "            transcribed_text = transcribe_audio(audio_file, self.asr_model)\n",
        "\n",
        "            if not transcribed_text or not transcribed_text.strip():\n",
        "                # Failed transcription\n",
        "                new_history = history.copy()\n",
        "                new_history.append((\"\", \"I couldn't understand the audio. Could you please try speaking again or type your message?\"))\n",
        "                return new_history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "            # Process the transcribed text - first show what was transcribed\n",
        "            new_history = history.copy()\n",
        "            new_history.append((f\"[Audio] {transcribed_text}\", \"\"))\n",
        "\n",
        "            # Now process it like a normal message\n",
        "            final_history, _, final_conv_id, conv_list, conv_ids = self.process_conversation_input(\n",
        "                user_id, transcribed_text, new_history, conversation_id\n",
        "            )\n",
        "\n",
        "            return final_history, \"\", final_conv_id, conv_list, conv_ids\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing audio input: {str(e)}\")\n",
        "            new_history = history.copy()\n",
        "            new_history.append((\"\", f\"I encountered an error processing your audio. Could you please try again?\"))\n",
        "            return new_history, \"\", conversation_id, gr.update(), []\n",
        "    def check_login(self, email, password):\n",
        "        success, user_id, message, chat_sessions, daily_tip = authenticate_user(self.db, email, password)\n",
        "\n",
        "        if success:\n",
        "            try:\n",
        "            # Fetch all conversations for the user\n",
        "                conversations = get_all_conversations(self.db, user_id)\n",
        "                conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "                conv_ids = [c[\"id\"] for c in conversations]\n",
        "\n",
        "            # If there are conversations, load the most recent one\n",
        "                initial_history = []\n",
        "                initial_conv_id = None\n",
        "\n",
        "                return (\n",
        "                    message,                              # Login status message\n",
        "                    gr.update(visible=False),             # Hide login container\n",
        "                    gr.update(visible=True),              # Show chat container\n",
        "                    user_id,                              # User ID\n",
        "                    gr.update(choices=conv_choices,       # Update conversation list\n",
        "                            value=None),\n",
        "                    daily_tip,                            # Daily tip\n",
        "                    initial_history,                      # Initial chat history\n",
        "                    initial_conv_id,                      # Initial conversation ID\n",
        "                    conv_ids                              # List of conversation IDs\n",
        "              )\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading initial conversations: {e}\")\n",
        "                return (\n",
        "                    f\"Login successful but error loading conversations: {str(e)}\",\n",
        "                    gr.update(visible=True),\n",
        "                    gr.update(visible=False),\n",
        "                    \"\",\n",
        "                    gr.update(choices=[]),\n",
        "                    \"\",\n",
        "                    [],\n",
        "                    None,\n",
        "                    []\n",
        "                )\n",
        "        else:\n",
        "            return (\n",
        "                message,\n",
        "                gr.update(visible=True),\n",
        "                gr.update(visible=False),\n",
        "                \"\",\n",
        "                gr.update(choices=[]),\n",
        "                \"\",\n",
        "                [],\n",
        "                None,\n",
        "                []\n",
        "            )\n",
        "\n",
        "    def register_new_user(self, email, password):\n",
        "        success, user_id, message, chat_sessions, daily_tip = register_user(self.db, email, password)\n",
        "\n",
        "        if success:\n",
        "            return message, gr.update(visible=False), gr.update(visible=True), user_id, gr.update(choices=chat_sessions, value=None), daily_tip\n",
        "        else:\n",
        "            return message, gr.update(visible=True), gr.update(visible=False), \"\", gr.update(choices=[]), \"\"\n",
        "\n",
        "    def process_user_input(self, user_id, user_message, audio_file, history):\n",
        "        return process_input(\n",
        "            self.db, user_id, user_message, audio_file, history,\n",
        "            self.asr_model, self.vector_db, self.llm\n",
        "        )\n",
        "\n",
        "    def new_chat(self):\n",
        "        return []\n",
        "\n",
        "    def load_session(self, user_id, session_timestamp):\n",
        "        return load_chat_by_session(self.db, user_id, session_timestamp)\n",
        "\n",
        "    def toggle_login_signup(self, is_login):\n",
        "        if is_login:\n",
        "            return gr.update(visible=True), gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)\n",
        "        else:\n",
        "            return gr.update(visible=False), gr.update(visible=True), gr.update(visible=False), gr.update(visible=True)\n",
        "\n",
        "    def load_conversation(self, user_id, selected_conversation, conversation_ids):\n",
        "        if not all([user_id, selected_conversation, conversation_ids]):\n",
        "            return [], None\n",
        "\n",
        "        try:\n",
        "            conversations = get_all_conversations(self.db, user_id)\n",
        "            conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "\n",
        "            if selected_conversation not in conv_choices:\n",
        "                return [], None\n",
        "\n",
        "            selected_idx = conv_choices.index(selected_conversation)\n",
        "\n",
        "            if selected_idx >= 0 and selected_idx < len(conversation_ids):\n",
        "                conversation_id = conversation_ids[selected_idx]\n",
        "                history = get_conversation_by_id(self.db, user_id, conversation_id)\n",
        "                return history, conversation_id\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading conversation: {e}\")\n",
        "        return [], None\n",
        "\n",
        "    def process_conversation_input(self, user_id, message, history, conversation_id):\n",
        "     try:\n",
        "        if not message:\n",
        "            return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "        # Get response using the LLM\n",
        "        llm = initialize_llm()\n",
        "        if llm:\n",
        "            # Analyze emotional content\n",
        "            emotions = analyze_emotional_content(message)\n",
        "\n",
        "            # Check for crisis keywords with more nuanced detection\n",
        "            crisis_check = check_for_crisis_and_severity(message)\n",
        "\n",
        "            if crisis_check['detected']:\n",
        "                response = generate_crisis_response(crisis_check['severity'], emotions)\n",
        "            else:\n",
        "                # Format the conversation history for context\n",
        "                conversation_context = \"\"\n",
        "                if history:\n",
        "                    for i, (user_msg, assistant_msg) in enumerate(history[-3:]):  # Include last 3 exchanges for context\n",
        "                        conversation_context += f\"User: {user_msg}\\nAssistant: {assistant_msg}\\n\\n\"\n",
        "\n",
        "                # Create prompt with conversation history and instructions for brevity\n",
        "                prompt = f\"\"\"You are Serene, a deeply empathetic mental wellbeing assistant with expertise in emotional support.\n",
        "\n",
        "                Previous conversation:\n",
        "                {conversation_context}\n",
        "\n",
        "                Current message: {message}\n",
        "\n",
        "                Remember to respond with warmth, empathy, and emotional intelligence, but keep your response brief and concise (2-3 sentences maximum). Focus on the most important aspects of the user's message.\n",
        "                \"\"\"\n",
        "\n",
        "                # Generate response using LLM with lower max_tokens\n",
        "                # Set temperature lower for more focused responses\n",
        "                llm_brief = initialize_llm(temperature=0.5)  # Lower temperature for more focused responses\n",
        "                base_response = llm_brief.invoke(prompt).content\n",
        "\n",
        "                # If response is still too long, truncate it\n",
        "                sentences = base_response.split('. ')\n",
        "                if len(sentences) > 3:\n",
        "                    base_response = '. '.join(sentences[:3]) + '.'\n",
        "\n",
        "                response = enhance_response_with_empathy(base_response, emotions)\n",
        "        else:\n",
        "            response = \"I'm here to listen and support you. What's on your mind today?\"\n",
        "\n",
        "        # Update history\n",
        "        new_history = history.copy()\n",
        "        new_history.append((message, response))\n",
        "\n",
        "        # Store conversation\n",
        "        if conversation_id is None:\n",
        "            conversation_id = f\"conv_{datetime.now().strftime('%Y%m%d%H%M%S')}_{random.randint(1000, 9999)}\"\n",
        "\n",
        "        store_conversation(self.db, user_id, conversation_id, message, response)\n",
        "\n",
        "        # Update conversation list\n",
        "        conversations = get_all_conversations(self.db, user_id)\n",
        "        conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "        conv_ids = [c[\"id\"] for c in conversations]\n",
        "\n",
        "        return new_history, \"\", conversation_id, gr.update(choices=conv_choices), conv_ids\n",
        "\n",
        "     except Exception as e:\n",
        "        print(f\"Error processing input: {e}\")\n",
        "        return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "    def build_interface(self):\n",
        "        with gr.Blocks(theme=self.theme, css=\"\"\"\n",
        "            .gradio-container {max-width: 1200px !important}\n",
        "            .header-text {text-align: center; font-weight: 600 !important}\n",
        "            .chat-history {border-left: 1px solid rgba(0,0,0,0.1)}\n",
        "            .welcome-box {background-color: rgba(89, 193, 189, 0.1); padding: 20px; border-radius: 12px; margin-bottom: 20px}\n",
        "            .tip-box {background-color: linear-gradient(135deg, #43c6ac, #59C1BD);; border-left: 4px solid teal; padding: 12px; margin: 12px 0; border-radius: 4px}\n",
        "            .tab-buttons {text-align: center; margin-bottom: 20px;}\n",
        "            .tab-button {margin: 0 10px; padding: 8px 16px; border-radius: 20px; background-color: #f0f0f0; border: none; cursor: pointer;}\n",
        "            .tab-button.active {background-color: #59C1BD; color: white;}\n",
        "        \"\"\") as interface:\n",
        "            # State variables\n",
        "            user_id = gr.State(\"\")\n",
        "            current_conversation_id = gr.State(None)\n",
        "            conversation_ids = gr.State([])\n",
        "\n",
        "            # Login container\n",
        "            login_container = gr.Column(visible=True)\n",
        "            chat_container = gr.Column(visible=False)\n",
        "\n",
        "            with login_container:\n",
        "                gr.Markdown(\"# Mental Wellbeing Chatbot\", elem_classes=[\"header-text\"])\n",
        "\n",
        "                # Tab buttons for login/signup\n",
        "                with gr.Row(elem_classes=[\"tab-buttons\"]):\n",
        "                    login_tab_btn = gr.Button(\"Login\", elem_classes=[\"tab-button\", \"active\"])\n",
        "                    signup_tab_btn = gr.Button(\"Sign Up\", elem_classes=[\"tab-button\"])\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        # Login Form\n",
        "                        login_form = gr.Group(visible=True)\n",
        "                        with login_form:\n",
        "                            gr.Markdown(\"### Sign in to your account\")\n",
        "                            email_login = gr.Textbox(label=\"Email\", interactive=True, placeholder=\"Your email\")\n",
        "                            password_login = gr.Textbox(label=\"Password\", type=\"password\", interactive=True, placeholder=\"Your password\")\n",
        "                            login_button = gr.Button(\"Sign In\", variant=\"primary\", size=\"lg\")\n",
        "                            login_status = gr.Textbox(label=\"Status\", interactive=False, visible=False)\n",
        "\n",
        "                        # Register Form\n",
        "                        register_form = gr.Group(visible=False)\n",
        "                        with register_form:\n",
        "                            gr.Markdown(\"### Create a new account\")\n",
        "                            email_register = gr.Textbox(label=\"Email\", interactive=True, placeholder=\"Your email\")\n",
        "                            password_register = gr.Textbox(label=\"Password\", type=\"password\", interactive=True, placeholder=\"Create a password\")\n",
        "                            confirm_password = gr.Textbox(label=\"Confirm Password\", type=\"password\", interactive=True, placeholder=\"Confirm your password\")\n",
        "                            register_button = gr.Button(\"Create Account\", variant=\"primary\", size=\"lg\")\n",
        "                            register_status = gr.Textbox(label=\"Status\", interactive=False, visible=False)\n",
        "\n",
        "            with chat_container:\n",
        "                gr.Markdown(\"# Mental Wellbeing Chatbot\", elem_classes=[\"header-text\"])\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        with gr.Group(elem_classes=[\"welcome-box\"]):\n",
        "                            gr.Markdown(\"### Welcome back!\")\n",
        "                            daily_tip_display = gr.Markdown(elem_classes=[\"tip-box\"])\n",
        "\n",
        "                        gr.Markdown(\"### Quick Resources\")\n",
        "                        resource_links = gr.Markdown(\"\"\"\n",
        "                        - [Guided Meditation](https://www.mindful.org/meditation/mindfulness-getting-started/)\n",
        "                        - [Deep Breathing Exercises](https://tools.wearewithyou.org.uk/deepbreathing/)\n",
        "                        - [Positive Affirmations](https://www.priorygroup.com/self-care/positive-affirmations-for-mental-health)\n",
        "                        - [Crisis Support Resources](https://www.crisistextline.org/)\n",
        "                        \"\"\")\n",
        "\n",
        "                        gr.Markdown(\"### Start a New Chat or View Past Conversations\")\n",
        "                        conversation_list = gr.Radio(choices=[], label=\"Select a previous conversation or start typing below to begin a new chat\",\n",
        "                                                                        value=None)\n",
        "                        load_conversation_button = gr.Button(\"Load Selected Conversation\", variant=\"secondary\")\n",
        "                        new_chat_button = gr.Button(\"+ Start New Conversation\", variant=\"secondary\")\n",
        "\n",
        "                    with gr.Column(scale=3, elem_classes=[\"chat-history\"]):\n",
        "                        chat_display = gr.Chatbot(\n",
        "                            label=\"Your conversation\",\n",
        "                            height=500,\n",
        "                            avatar_images=[\n",
        "                                \"https://img.icons8.com/ios-filled/50/000000/user-male-circle.png\",\n",
        "                                \"https://img.icons8.com/ios-filled/50/59C1BD/teal-meditation.png\"\n",
        "                            ]\n",
        "                        )\n",
        "\n",
        "                        with gr.Row():\n",
        "                           user_input = gr.Textbox(\n",
        "                           label=\"Type your message...\",\n",
        "                           placeholder=\"Share how you're feeling or ask for support...\",\n",
        "                           lines=2,\n",
        "                           scale=4\n",
        "            )\n",
        "                           audio_input = gr.Audio(\n",
        "                           label=\"🎤 Speak\",\n",
        "                           source=\"microphone\",\n",
        "                           type=\"filepath\",\n",
        "                           streaming=False,  # Set to False for better browser compatibility\n",
        "                           format=\"wav\",     # Specify format for better compatibility\n",
        "                           scale=1\n",
        "            )\n",
        "\n",
        "\n",
        "                        send_button = gr.Button(\"Send Message\", variant=\"primary\")\n",
        "\n",
        "                        gr.Markdown(\"\"\"\n",
        "                        ### About the Chatbot\n",
        "                        This is an AI companion for mental wellbeing. Share your thoughts, feelings, and concerns in a safe, judgment-free space. While this chatbot can provide support and guidance, it's not a replacement for professional mental health care. If you're experiencing a crisis, please contact a mental health professional or crisis hotline.\n",
        "                        \"\"\")\n",
        "\n",
        "            # Connect the buttons to functions\n",
        "            login_tab_btn.click(\n",
        "                self.toggle_login_signup,\n",
        "                inputs=[gr.State(True)],\n",
        "                outputs=[login_form, register_form, login_tab_btn, signup_tab_btn]\n",
        "            )\n",
        "\n",
        "            signup_tab_btn.click(\n",
        "                self.toggle_login_signup,\n",
        "                inputs=[gr.State(False)],\n",
        "                outputs=[login_form, register_form, login_tab_btn, signup_tab_btn]\n",
        "            )\n",
        "\n",
        "            # Login functionality\n",
        "            # In build_interface method, update the login button click event\n",
        "            login_button.click(\n",
        "                self.check_login,\n",
        "                inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                login_status,\n",
        "                login_container,\n",
        "                chat_container,\n",
        "                user_id,\n",
        "                conversation_list,\n",
        "                daily_tip_display,\n",
        "                chat_display,              # Add chat display to outputs\n",
        "                current_conversation_id,    # Add current conversation ID\n",
        "                conversation_ids           # Add conversation IDs\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            # Also update the email and password submit events similarly\n",
        "            email_login.submit(\n",
        "                self.check_login,\n",
        "                inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                    login_status,\n",
        "                    login_container,\n",
        "                    chat_container,\n",
        "                    user_id,\n",
        "                    conversation_list,\n",
        "                    daily_tip_display,\n",
        "                    chat_display,\n",
        "                    current_conversation_id,\n",
        "                    conversation_ids\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            password_login.submit(\n",
        "                  self.check_login,\n",
        "                  inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                      login_status,\n",
        "                      login_container,\n",
        "                      chat_container,\n",
        "                      user_id,\n",
        "                      conversation_list,\n",
        "                      daily_tip_display,\n",
        "                      chat_display,\n",
        "                      current_conversation_id,\n",
        "                      conversation_ids\n",
        "                    ]\n",
        "              )\n",
        "\n",
        "            # Registration functionality\n",
        "            def validate_and_register(email, password, confirm_password):\n",
        "                if password != confirm_password:\n",
        "                    return \"Passwords do not match. Please try again.\", gr.update(visible=True), gr.update(visible=False), \"\", gr.update(choices=[]), \"\"\n",
        "                return self.register_new_user(email, password)\n",
        "\n",
        "            register_button.click(\n",
        "                validate_and_register,\n",
        "                inputs=[email_register, password_register, confirm_password],\n",
        "                outputs=[register_status, login_container, chat_container, user_id, conversation_list, daily_tip_display]\n",
        "            )\n",
        "\n",
        "            # Chat functionality\n",
        "            send_button.click(\n",
        "                self.process_conversation_input,\n",
        "                inputs=[user_id, user_input, chat_display, current_conversation_id],\n",
        "                outputs=[chat_display, user_input, current_conversation_id, conversation_list, conversation_ids]\n",
        "            )\n",
        "\n",
        "            user_input.submit(\n",
        "                self.process_conversation_input,\n",
        "                inputs=[user_id, user_input, chat_display, current_conversation_id],\n",
        "                outputs=[chat_display, user_input, current_conversation_id, conversation_list, conversation_ids]\n",
        "            )\n",
        "\n",
        "            load_conversation_button.click(\n",
        "                self.load_conversation,\n",
        "                inputs=[user_id, conversation_list, conversation_ids],\n",
        "                outputs=[chat_display, current_conversation_id]\n",
        "            )\n",
        "            audio_input.change(\n",
        "               self.process_audio_input,\n",
        "               inputs=[user_id, gr.State(\"\"), audio_input, chat_display, current_conversation_id],  # Empty string for user_message\n",
        "               outputs=[chat_display, gr.State(\"\"), current_conversation_id, conversation_list, conversation_ids]\n",
        "             )\n",
        "\n",
        "            new_chat_button.click(\n",
        "                lambda: ([], None),\n",
        "                outputs=[chat_display, current_conversation_id]\n",
        "            )\n",
        "\n",
        "            return interface\n",
        "\n",
        "    def launch(self, **kwargs):\n",
        "        self.interface.launch(**kwargs)\n",
        "\n",
        "# Run the application\n",
        "if __name__ == \"__main__\":\n",
        "    app = WellbeingChatbotApp()\n",
        "    app.launch(debug=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "5SvLc4QI4P7Y",
        "outputId": "6da37447-75a7-4674-e8a8-aecc52055de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ASR model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASR model loaded successfully\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://ad236e7d8bf6643f93.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ad236e7d8bf6643f93.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://ad236e7d8bf6643f93.gradio.live\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import pipeline\n",
        "import os\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, auth, firestore\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from datetime import datetime\n",
        "import random\n",
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import base64\n",
        "import io\n",
        "def detect_emotion_from_image(image_data):\n",
        "    try:\n",
        "        # Convert the image data to a format DeepFace can process\n",
        "        if isinstance(image_data, str) and image_data.startswith('data:image'):\n",
        "            # Handle base64 encoded image\n",
        "            image_data = image_data.split(',')[1]\n",
        "            image_bytes = base64.b64decode(image_data)\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            image_array = np.array(image)\n",
        "        else:\n",
        "            # Handle numpy array\n",
        "            image_array = image_data\n",
        "\n",
        "        # Detect emotion using DeepFace\n",
        "        result = DeepFace.analyze(\n",
        "            image_array,\n",
        "            actions=['emotion'],\n",
        "            enforce_detection=False\n",
        "        )\n",
        "\n",
        "        # Get the dominant emotion\n",
        "        emotion = result[0]['dominant_emotion']\n",
        "\n",
        "        # Get all emotions with their scores\n",
        "        emotions = result[0]['emotion']\n",
        "\n",
        "        return {\n",
        "            'status': 'success',\n",
        "            'dominant_emotion': emotion,\n",
        "            'emotion_scores': emotions\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'status': 'error',\n",
        "            'message': str(e)\n",
        "        }\n",
        "\n",
        "def generate_emotion_based_response(emotion_data):\n",
        "    \"\"\"\n",
        "    Generate a response based on detected emotion\n",
        "    \"\"\"\n",
        "    if emotion_data['status'] == 'error':\n",
        "        return \"I couldn't detect your emotion clearly. Would you like to tell me how you're feeling?\"\n",
        "\n",
        "    emotion = emotion_data['dominant_emotion']\n",
        "\n",
        "    emotion_responses = {\n",
        "        'happy': [\n",
        "            \"I can see that you're feeling happy! That's wonderful! Would you like to share what's bringing you joy?\",\n",
        "            \"Your happiness is contagious! What's made your day special?\",\n",
        "            \"It's great to see you in such good spirits! How would you like to maintain this positive energy?\"\n",
        "        ],\n",
        "        'sad': [\n",
        "            \"I notice that you might be feeling down. Would you like to talk about what's troubling you?\",\n",
        "            \"It's okay to feel sad sometimes. I'm here to listen if you want to share.\",\n",
        "            \"I can see that you're going through a difficult moment. How can I support you right now?\"\n",
        "        ],\n",
        "        'angry': [\n",
        "            \"I can see that something might be frustrating you. Would you like to talk about what's bothering you?\",\n",
        "            \"It's natural to feel angry sometimes. Would you like to discuss what triggered these feelings?\",\n",
        "            \"I notice you might be feeling upset. How can I help you process these emotions?\"\n",
        "        ],\n",
        "        'fear': [\n",
        "            \"I can sense that you might be feeling anxious or afraid. Would you like to talk about your concerns?\",\n",
        "            \"It's okay to feel scared. We can work through these feelings together.\",\n",
        "            \"I'm here to support you through your fears. What's on your mind?\"\n",
        "        ],\n",
        "        'surprise': [\n",
        "            \"You seem surprised! Would you like to share what's unexpected?\",\n",
        "            \"Something seems to have caught you off guard. Would you like to talk about it?\",\n",
        "            \"I notice your surprise! What's on your mind?\"\n",
        "        ],\n",
        "        'neutral': [\n",
        "            \"How are you feeling right now? I'm here to listen.\",\n",
        "            \"Would you like to share what's on your mind?\",\n",
        "            \"I'm here to support you. What would you like to talk about?\"\n",
        "        ],\n",
        "        'disgust': [\n",
        "            \"I notice you might be feeling uncomfortable. Would you like to talk about what's bothering you?\",\n",
        "            \"Something seems to be troubling you. I'm here to listen if you want to share.\",\n",
        "            \"Would you like to discuss what's making you feel this way?\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return random.choice(emotion_responses.get(emotion, emotion_responses['neutral']))\n",
        "# Predefined wellness tips\n",
        "WELLNESS_TIPS = [\n",
        "    \"Take a few deep breaths when feeling stressed.\",\n",
        "    \"Stay hydrated throughout the day.\",\n",
        "    \"Try to get at least 7-8 hours of sleep each night.\",\n",
        "    \"Take short breaks during work to stretch and move.\",\n",
        "    \"Practice gratitude by noting three things you're thankful for.\",\n",
        "    \"Spend time in nature when possible.\",\n",
        "    \"Limit screen time before bed for better sleep.\",\n",
        "    \"Connect with a friend or family member today.\",\n",
        "    \"Try a 5-minute meditation to clear your mind.\",\n",
        "    \"Move your body for at least 30 minutes today.\"\n",
        "]\n",
        "\n",
        "# Initialize Firebase only once\n",
        "def initialize_firebase():\n",
        "    if not firebase_admin._apps:\n",
        "        try:\n",
        "            cred = credentials.Certificate(\"/content/data/firebase_credentials.json\")  # Update this path!\n",
        "            firebase_admin.initialize_app(cred)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Firebase initialization error: {e}\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Initialize Firestore\n",
        "def get_firestore_db():\n",
        "    if initialize_firebase():\n",
        "        return firestore.client()\n",
        "    return None\n",
        "\n",
        "# Load ASR Model\n",
        "def load_asr_model():\n",
        "    try:\n",
        "        return pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading ASR model: {e}\")\n",
        "        return None\n",
        "\n",
        "# Get random wellness tip\n",
        "def get_daily_tip():\n",
        "    \"\"\"Returns a random wellness tip\"\"\"\n",
        "    return random.choice(WELLNESS_TIPS)\n",
        "\n",
        "# Initialize LLM with mental wellbeing focus\n",
        "def initialize_llm(api_key=None, temperature=0.2):\n",
        "    try:\n",
        "        # Use provided API key or default to environment variable\n",
        "        groq_api_key = api_key or \"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\"\n",
        "        llm = ChatGroq(\n",
        "            temperature=temperature,  # Slightly increased for more natural responses\n",
        "            groq_api_key=groq_api_key,\n",
        "            model_name=\"llama-3.3-70b-versatile\"\n",
        "        )\n",
        "        return llm\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing LLM: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create or load vector database\n",
        "def create_vector_db(db_path=\"/content/chroma_db\"):\n",
        "    try:\n",
        "        if not os.path.exists(db_path):\n",
        "            os.makedirs(db_path)\n",
        "\n",
        "        embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "        return Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating vector database: {e}\")\n",
        "        return None\n",
        "\n",
        "# Set up QA chain with a focus on context-aware and psychiatrist-like responses\n",
        "def setup_qa_chain(vector_db, llm):\n",
        "    \"\"\"Set up the QA retrieval chain with a focus on providing context-aware and psychiatrist-like responses\"\"\"\n",
        "    if vector_db is None or llm is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        retriever = vector_db.as_retriever()\n",
        "        prompt_template = \"\"\"You are a compassionate and knowledgeable mental wellbeing assistant named Serene, akin to a psychiatrist.\n",
        "\n",
        "        Your primary goal is to provide supportive, empathetic, and insightful responses that help the user improve their mental wellbeing.\n",
        "        Always maintain a warm, understanding tone and never judge the user.\n",
        "\n",
        "        Guidelines for your responses:\n",
        "        - Begin with validation of the user's feelings (\"I understand that feeling...\", \"That sounds really challenging...\")\n",
        "        - Use a warm, conversational tone that shows genuine care\n",
        "        - Offer specific, actionable suggestions tailored to their situation, not generic advice\n",
        "        - Ask thoughtful follow-up questions to show you're really listening\n",
        "        - Share relevant coping strategies or techniques that might help their specific situation\n",
        "        - When appropriate, gently normalize their experiences (\"Many people feel this way...\")\n",
        "        - Always respond with empathy first, then helpful information second\n",
        "        - Provide deeper insights and reflective questions to encourage self-awareness and personal growth\n",
        "\n",
        "        For different emotional states:\n",
        "        - When user seems anxious: Use calming language, offer grounding techniques, validate their worries\n",
        "        - When user seems sad: Show compassion, acknowledge the pain, offer gentle encouragement\n",
        "        - When user seems frustrated: Validate their feelings, show patience, offer perspective\n",
        "        - When user seems confused: Provide clarity, break down concepts, be reassuring\n",
        "\n",
        "        If the user appears to be in crisis, gently suggest they reach out to a mental health professional or crisis hotline,\n",
        "        but continue to engage with them supportively.\n",
        "\n",
        "        Relevant context from your knowledge base:\n",
        "        {context}\n",
        "\n",
        "        User: {question}\n",
        "\n",
        "        Serene:\"\"\"\n",
        "\n",
        "        PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "        qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=retriever,\n",
        "            chain_type_kwargs={\"prompt\": PROMPT}\n",
        "        )\n",
        "\n",
        "        return qa_chain\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up QA chain: {e}\")\n",
        "        return None\n",
        "\n",
        "# Generate chatbot response with crisis detection and coping strategies\n",
        "def chatbot_response(db, user_id, user_input, history, vector_db=None, llm=None):\n",
        "    \"\"\" Generate chatbot response and store it in chat history \"\"\"\n",
        "    try:\n",
        "        # Initialize components if not provided\n",
        "        if vector_db is None:\n",
        "            vector_db = create_vector_db()\n",
        "\n",
        "        if llm is None:\n",
        "            llm = initialize_llm()\n",
        "\n",
        "        qa_chain = setup_qa_chain(vector_db, llm)\n",
        "\n",
        "        # Check for crisis keywords\n",
        "        is_crisis = check_for_crisis(user_input)\n",
        "\n",
        "        if is_crisis:\n",
        "            response = \"\"\"I notice you've mentioned something concerning. If you're in crisis, please consider reaching out to a crisis helpline:\n",
        "            - National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "            - Crisis Text Line: Text HOME to 741741 📱\n",
        "\n",
        "            These services are available 24/7 and provide confidential support. Would you like to talk about what you're feeling right now? I'm here to listen. 💬\"\"\"\n",
        "        elif qa_chain is None:\n",
        "            response = \"I'm having trouble connecting to my knowledge base. Let's focus on how you're feeling today. What would help you feel more at ease right now? 🧘\"\n",
        "        else:\n",
        "            # Generate a response using the QA chain\n",
        "            raw_response = qa_chain.run(user_input)\n",
        "\n",
        "            # Enhance with empathy, context-awareness, and coping strategies\n",
        "            response = f\"I understand that you're feeling {user_input}. {raw_response} 🤗\"\n",
        "\n",
        "            # Add specific coping strategies based on emotional state\n",
        "            if \"anxious\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with anxiety:\\n- Practice deep breathing exercises 🧘\\n- Try grounding techniques like focusing on your senses 🌱\\n- Take a short walk to clear your mind 🚶\\n- Write down your thoughts in a journal 📓\"\n",
        "            elif \"sad\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with sadness:\\n- Reach out to a friend or family member 📞\\n- Engage in a hobby or activity you enjoy 🎨\\n- Practice self-compassion and be kind to yourself 💖\\n- Reflect on positive memories or experiences 📝\"\n",
        "            elif \"frustrated\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with frustration:\\n- Take a few deep breaths and count to ten 🧘\\n- Step away from the situation and take a break 🌳\\n- Talk it out with someone you trust 🗣️\\n- Focus on solutions rather than problems 🔍\"\n",
        "\n",
        "        # Update history\n",
        "        updated_history = history.copy()\n",
        "        updated_history.append((user_input, response))\n",
        "\n",
        "        # Store in Firebase if available\n",
        "        if db is not None and user_id:\n",
        "            store_chat_history(db, user_id, updated_history)\n",
        "\n",
        "        return user_input, response, updated_history\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return user_input, \"Sorry, I encountered an error while processing your request.\", history\n",
        "\n",
        "# Transcribe audio to text\n",
        "def transcribe_audio(audio_path, asr_model):\n",
        "    if not audio_path or not os.path.exists(audio_path) or asr_model is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        transcription = asr_model(audio_path)[\"text\"]\n",
        "        return transcription\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing audio: {e}\")\n",
        "        return None\n",
        "\n",
        "# Store chat history in Firebase with timestamps\n",
        "def store_chat_history(db, user_id, history):\n",
        "    if db is None or not user_id:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        formatted_history = [{\"message\": msg, \"response\": resp, \"timestamp\": timestamp} for msg, resp in history]\n",
        "        db.collection(\"chat_history\").document(user_id).set({\"history\": formatted_history})\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error storing chat history: {e}\")\n",
        "        return False\n",
        "\n",
        "# Fetch chat history from Firebase\n",
        "def fetch_chat_history(db, user_id):\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            chat_list = chats.to_dict().get(\"history\", [])\n",
        "            return [(chat[\"message\"], chat[\"response\"]) for chat in chat_list]\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching chat history: {e}\")\n",
        "        return []\n",
        "\n",
        "# Get chat sessions by timestamp\n",
        "def get_chat_sessions(db, user_id):\n",
        "    \"\"\" Get list of chat sessions with timestamps \"\"\"\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            chat_list = chats.to_dict().get(\"history\", [])\n",
        "            if chat_list:\n",
        "                # Group by timestamps to create session names\n",
        "                timestamps = set([chat.get(\"timestamp\", \"Unknown\") for chat in chat_list])\n",
        "                return list(timestamps)\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting chat sessions: {e}\")\n",
        "        return []\n",
        "\n",
        "# Check for crisis keywords in user input\n",
        "def check_for_crisis(user_input):\n",
        "    crisis_keywords = [\"suicide\", \"kill myself\", \"end my life\", \"don't want to live\"]\n",
        "    return any(keyword in user_input.lower() for keyword in crisis_keywords)\n",
        "\n",
        "# Generate chatbot response with crisis detection\n",
        "\n",
        "def process_input(db, user_id, user_message, audio_file, history, asr_model, vector_db, llm):\n",
        "    if audio_file:\n",
        "        transcribed_text = transcribe_audio(audio_file, asr_model)\n",
        "        if transcribed_text:\n",
        "            _, _, updated_history = chatbot_response(db, user_id, transcribed_text, history, vector_db, llm)\n",
        "            return updated_history, \"\", None\n",
        "\n",
        "    if user_message:\n",
        "        _, _, updated_history = chatbot_response(db, user_id, user_message, history, vector_db, llm)\n",
        "        return updated_history, \"\", None\n",
        "\n",
        "    return history, \"\", None\n",
        "\n",
        "# Store conversation in Firestore\n",
        "def store_conversation(db, user_id, conversation_id, message, response):\n",
        "    if db is None or not user_id:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        conv_ref = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").document(conversation_id)\n",
        "        conv_doc = conv_ref.get()\n",
        "\n",
        "        if conv_doc.exists:\n",
        "            conv_data = conv_doc.to_dict()\n",
        "            messages = conv_data.get(\"messages\", [])\n",
        "            messages.append({\n",
        "                \"user_message\": message,\n",
        "                \"assistant_response\": response,\n",
        "                \"timestamp\": timestamp\n",
        "            })\n",
        "            conv_ref.update({\n",
        "                \"messages\": messages,\n",
        "                \"last_updated\": timestamp,\n",
        "                \"title\": message[:30] + \"...\" if len(message) > 30 else message\n",
        "            })\n",
        "        else:\n",
        "            conv_ref.set({\n",
        "                \"messages\": [{\n",
        "                    \"user_message\": message,\n",
        "                    \"assistant_response\": response,\n",
        "                    \"timestamp\": timestamp\n",
        "                }],\n",
        "                \"created_at\": timestamp,\n",
        "                \"last_updated\": timestamp,\n",
        "                \"title\": message[:30] + \"...\" if len(message) > 30 else message\n",
        "            })\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error storing conversation: {e}\")\n",
        "        return False\n",
        "\n",
        "# Get all conversations for a user\n",
        "def get_all_conversations(db, user_id):\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        conversations = []\n",
        "        conv_refs = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").order_by(\"last_updated\", direction=firestore.Query.DESCENDING)\n",
        "\n",
        "        for conv in conv_refs.stream():\n",
        "            conv_data = conv.to_dict()\n",
        "            conversations.append({\n",
        "                \"id\": conv.id,\n",
        "                \"title\": conv_data.get(\"title\", \"Unnamed conversation\"),\n",
        "                \"last_updated\": conv_data.get(\"last_updated\", \"Unknown date\"),\n",
        "                \"message_count\": len(conv_data.get(\"messages\", []))\n",
        "            })\n",
        "        return conversations\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching conversations: {e}\")\n",
        "        return []\n",
        "\n",
        "# Get a specific conversation by ID\n",
        "def get_conversation_by_id(db, user_id, conversation_id):\n",
        "    if db is None or not user_id or not conversation_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        conv_ref = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").document(conversation_id)\n",
        "        conv_doc = conv_ref.get()\n",
        "\n",
        "        if conv_doc.exists:\n",
        "            conv_data = conv_doc.to_dict()\n",
        "            messages = conv_data.get(\"messages\", [])\n",
        "            return [(msg[\"user_message\"], msg[\"assistant_response\"]) for msg in messages]\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching conversation: {e}\")\n",
        "        return []\n",
        "\n",
        "# Authenticate user via Firebase\n",
        "def authenticate_user(db, email, password):\n",
        "    try:\n",
        "        user = auth.get_user_by_email(email)\n",
        "        user_id = user.uid\n",
        "\n",
        "        # Fetch chat sessions\n",
        "        chat_sessions = get_chat_sessions(db, user_id)\n",
        "        daily_tip = get_daily_tip()\n",
        "\n",
        "        return True, user_id, \"Login successful!\", chat_sessions, daily_tip\n",
        "    except Exception as e:\n",
        "        print(f\"Authentication error: {e}\")\n",
        "        return False, \"\", f\"Login failed: {str(e)}\", [], \"\"\n",
        "\n",
        "# Register a new user\n",
        "def register_user(db, email, password):\n",
        "    try:\n",
        "        # Check if user already exists\n",
        "        try:\n",
        "            existing_user = auth.get_user_by_email(email)\n",
        "            if existing_user:\n",
        "                return False, \"\", \"Email already in use. Please log in instead.\", [], \"\"\n",
        "        except:\n",
        "            # User doesn't exist, proceed with registration\n",
        "            pass\n",
        "\n",
        "        # Create new user\n",
        "        user = auth.create_user(\n",
        "            email=email,\n",
        "            password=password,\n",
        "            email_verified=False\n",
        "        )\n",
        "\n",
        "        user_id = user.uid\n",
        "\n",
        "        # Initialize user data in Firestore\n",
        "        db.collection(\"user_data\").document(user_id).set({\n",
        "            \"email\": email,\n",
        "            \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        })\n",
        "\n",
        "        daily_tip = get_daily_tip()\n",
        "\n",
        "        return True, user_id, \"Registration successful! Welcome!\", [], daily_tip\n",
        "    except Exception as e:\n",
        "        print(f\"Registration error: {e}\")\n",
        "        return False, \"\", f\"Registration failed: {str(e)}\", [], \"\"\n",
        "\n",
        "# Load custom theme for mental wellbeing UI\n",
        "def load_theme():\n",
        "    \"\"\" Load the custom theme for the mental wellbeing chatbot \"\"\"\n",
        "    return gr.themes.Soft(\n",
        "        primary_hue=\"teal\",\n",
        "        secondary_hue=\"blue\",\n",
        "        neutral_hue=\"slate\",\n",
        "        radius_size=gr.themes.sizes.radius_md,\n",
        "        font=[gr.themes.GoogleFont(\"Nunito\"), gr.themes.GoogleFont(\"Quicksand\"), \"system-ui\", \"sans-serif\"]\n",
        "    )\n",
        "\n",
        "# Load chat by session timestamp\n",
        "def load_chat_by_session(db, user_id, session_timestamp):\n",
        "    if not session_timestamp or db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            all_chats = chats.to_dict().get(\"history\", [])\n",
        "            session_chats = [(chat[\"message\"], chat[\"response\"])\n",
        "                            for chat in all_chats\n",
        "                            if chat.get(\"timestamp\") == session_timestamp]\n",
        "            return session_chats\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading chat session: {e}\")\n",
        "        return []\n",
        "def analyze_emotional_content(text):\n",
        "    \"\"\"\n",
        "    Analyzes text for emotional content and returns detected emotions.\n",
        "\n",
        "    Args:\n",
        "        text (str): The user's message text\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing detected emotions and their confidence scores\n",
        "    \"\"\"\n",
        "    # Define emotion keywords for basic detection\n",
        "    emotion_keywords = {\n",
        "        'anxious': ['anxious', 'worried', 'nervous', 'panic', 'fear', 'stress', 'overwhelm', 'scared'],\n",
        "        'sad': ['sad', 'depressed', 'unhappy', 'miserable', 'grief', 'blue', 'down', 'heartbroken', 'upset'],\n",
        "        'angry': ['angry', 'frustrated', 'mad', 'furious', 'irritated', 'annoyed', 'rage', 'hate'],\n",
        "        'happy': ['happy', 'joy', 'excited', 'delighted', 'pleased', 'content', 'grateful', 'thankful'],\n",
        "        'neutral': ['okay', 'fine', 'alright', 'neutral']\n",
        "    }\n",
        "\n",
        "    # Initialize results with default values\n",
        "    results = {\n",
        "        'primary_emotion': 'neutral',\n",
        "        'confidence': 0.0,\n",
        "        'detected_emotions': {},\n",
        "        'intensity': 'low'\n",
        "    }\n",
        "\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Count emotion keywords in text\n",
        "    emotion_counts = {}\n",
        "    max_count = 0\n",
        "    primary_emotion = 'neutral'\n",
        "\n",
        "    for emotion, keywords in emotion_keywords.items():\n",
        "        count = sum(1 for keyword in keywords if keyword in text_lower)\n",
        "        if count > 0:\n",
        "            emotion_counts[emotion] = count\n",
        "            if count > max_count:\n",
        "                max_count = count\n",
        "                primary_emotion = emotion\n",
        "\n",
        "    # If no emotions detected, return neutral\n",
        "    if not emotion_counts:\n",
        "        return results\n",
        "\n",
        "    # Calculate rough confidence based on keyword frequency\n",
        "    total_keywords = sum(emotion_counts.values())\n",
        "\n",
        "    # Set primary emotion and confidence\n",
        "    results['primary_emotion'] = primary_emotion\n",
        "    results['confidence'] = min(0.95, max_count / (len(text.split()) * 0.5)) if total_keywords > 0 else 0.4\n",
        "    results['detected_emotions'] = emotion_counts\n",
        "\n",
        "    # Determine intensity based on modifier words and punctuation\n",
        "    intensity_markers = ['very', 'extremely', 'so', 'really', 'completely', 'absolutely', 'totally']\n",
        "    exclamation_count = text.count('!')\n",
        "    uppercase_ratio = sum(1 for c in text if c.isupper()) / max(len(text), 1)\n",
        "\n",
        "    intensity_score = sum(1 for marker in intensity_markers if marker in text_lower) + exclamation_count\n",
        "    intensity_score += 3 if uppercase_ratio > 0.3 else 0\n",
        "\n",
        "    if intensity_score > 3:\n",
        "        results['intensity'] = 'high'\n",
        "    elif intensity_score > 1:\n",
        "        results['intensity'] = 'medium'\n",
        "    else:\n",
        "        results['intensity'] = 'low'\n",
        "\n",
        "    return results\n",
        "\n",
        "# Function to check for crisis keywords with severity assessment\n",
        "def check_for_crisis_and_severity(text):\n",
        "    \"\"\"\n",
        "    Checks user input for crisis indicators and assesses severity.\n",
        "\n",
        "    Args:\n",
        "        text (str): The user's message text\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains crisis detection results and severity level\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Define crisis keywords with severity levels\n",
        "    high_severity_keywords = [\n",
        "        'kill myself', 'suicide', 'end my life', 'want to die',\n",
        "        'take my life', 'harm myself', 'hurt myself badly'\n",
        "    ]\n",
        "\n",
        "    medium_severity_keywords = [\n",
        "        'don\\'t want to live', 'no reason to live', 'better off dead',\n",
        "        'can\\'t go on', 'giving up', 'no hope', 'no future',\n",
        "        'self harm', 'cutting myself', 'hurting myself'\n",
        "    ]\n",
        "\n",
        "    low_severity_keywords = [\n",
        "        'hopeless', 'worthless', 'nothing matters', 'what\\'s the point',\n",
        "        'exhausted', 'can\\'t handle this', 'too much pain'\n",
        "    ]\n",
        "\n",
        "    # Check for high severity keywords (immediate crisis)\n",
        "    for keyword in high_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'high', 'keyword': keyword}\n",
        "\n",
        "    # Check for medium severity keywords (concerning)\n",
        "    for keyword in medium_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'medium', 'keyword': keyword}\n",
        "\n",
        "    # Check for low severity keywords (distress)\n",
        "    for keyword in low_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'low', 'keyword': keyword}\n",
        "\n",
        "    # No crisis keywords detected\n",
        "    return {'detected': False, 'severity': 'none', 'keyword': None}\n",
        "\n",
        "# Function to generate crisis responses based on severity\n",
        "def generate_crisis_response(severity, emotions):\n",
        "    \"\"\"\n",
        "    Generates appropriate responses for different crisis severity levels.\n",
        "\n",
        "    Args:\n",
        "        severity (str): The detected crisis severity level\n",
        "        emotions (dict): The emotional analysis results\n",
        "\n",
        "    Returns:\n",
        "        str: A compassionate response appropriate to the severity level\n",
        "    \"\"\"\n",
        "    if severity == 'high':\n",
        "        return \"\"\"I'm really concerned about what you're sharing. If you're having thoughts of harming yourself, please reach out to a crisis helpline immediately:\n",
        "\n",
        "• National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "• Crisis Text Line: Text HOME to 741741 📱\n",
        "• Or go to your nearest emergency room\n",
        "\n",
        "These services have trained professionals available 24/7 who can help you through this difficult time. Your life matters, and support is available. Would you like to talk more about what you're experiencing right now?\"\"\"\n",
        "\n",
        "    elif severity == 'medium':\n",
        "        return \"\"\"I hear that you're going through a really difficult time, and I'm concerned about what you're sharing. It's important to talk to someone who can provide professional support:\n",
        "\n",
        "• National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "• Crisis Text Line: Text HOME to 741741 📱\n",
        "\n",
        "Would it be possible for you to reach out to a mental health professional or trusted person in your life today? Your feelings are valid, and support is available. I'm here to listen if you'd like to share more.\"\"\"\n",
        "\n",
        "    elif severity == 'low':\n",
        "        primary_emotion = emotions.get('primary_emotion', 'distress')\n",
        "\n",
        "        responses = {\n",
        "            'anxious': \"I can hear the anxiety in your message, and that sounds really challenging. When everything feels overwhelming, it's important to be gentle with yourself. Would it help to talk about specific things that are causing you to feel this way?\",\n",
        "            'sad': \"I'm sorry you're feeling such sadness right now. It's okay to not be okay sometimes, and your feelings are valid. Would you like to share more about what's contributing to these feelings?\",\n",
        "            'angry': \"I can sense your frustration and anger. These are completely valid emotions, especially when dealing with difficult situations. Would it help to talk more about what's triggering these feelings?\",\n",
        "            'neutral': \"It sounds like you're going through a difficult time. Everyone struggles sometimes, and it's okay to reach out for support. Would talking to a mental health professional be an option for you?\"\n",
        "        }\n",
        "\n",
        "        base_response = responses.get(primary_emotion, responses['neutral'])\n",
        "        return base_response + \"\\n\\nIf you ever feel these thoughts becoming more intense or have thoughts of harming yourself, please reach out to a crisis helpline like the National Suicide Prevention Lifeline at 988.\"\n",
        "\n",
        "    else:\n",
        "        # Default response if severity assessment fails\n",
        "        return \"I notice you may be going through a difficult time. If you're feeling overwhelmed, talking to a mental health professional can really help. Would you like to share more about what you're experiencing?\"\n",
        "\n",
        "# Function to enhance responses with empathy based on emotions\n",
        "def enhance_response_with_empathy(base_response, emotions):\n",
        "    \"\"\"\n",
        "    Enhances LLM responses with appropriate empathetic elements based on detected emotions.\n",
        "\n",
        "    Args:\n",
        "        base_response (str): The original LLM response\n",
        "        emotions (dict): The emotional analysis results\n",
        "\n",
        "    Returns:\n",
        "        str: Enhanced response with appropriate empathetic elements\n",
        "    \"\"\"\n",
        "    primary_emotion = emotions.get('primary_emotion', 'neutral')\n",
        "    intensity = emotions.get('intensity', 'low')\n",
        "\n",
        "    # Add appropriate emoji based on emotion and intensity\n",
        "    emotion_emojis = {\n",
        "        'anxious': ['😟', '😥', '😰'],  # Low, Medium, High\n",
        "        'sad': ['😔', '😢', '😭'],\n",
        "        'angry': ['😒', '😠', '😡'],\n",
        "        'happy': ['🙂', '😊', '😄'],\n",
        "        'neutral': ['🙂', '😊', '💭']\n",
        "    }\n",
        "\n",
        "    intensity_index = {'low': 0, 'medium': 1, 'high': 2}.get(intensity, 0)\n",
        "    emoji = emotion_emojis.get(primary_emotion, emotion_emojis['neutral'])[intensity_index]\n",
        "\n",
        "    # Add empathetic prefix based on emotion\n",
        "    empathy_prefixes = {\n",
        "        'anxious': [\"I understand that anxiety can be overwhelming. \",\n",
        "                   \"It makes sense that you're feeling anxious. \",\n",
        "                   \"That kind of worry is really challenging to navigate. \"],\n",
        "        'sad': [\"I hear the sadness in your message. \",\n",
        "               \"I'm sorry you're feeling down right now. \",\n",
        "               \"It's okay to feel sad sometimes. \"],\n",
        "        'angry': [\"I can sense your frustration. \",\n",
        "                 \"I understand why that would be upsetting. \",\n",
        "                 \"It's natural to feel frustrated in that situation. \"],\n",
        "        'happy': [\"It's wonderful to hear that positivity! \",\n",
        "                 \"I'm glad you're feeling good. \",\n",
        "                 \"That's really great to hear. \"],\n",
        "        'neutral': [ \"\"]\n",
        "    }\n",
        "\n",
        "    import random\n",
        "    prefix = random.choice(empathy_prefixes.get(primary_emotion, empathy_prefixes['neutral']))\n",
        "\n",
        "    # Combine elements\n",
        "    enhanced_response = prefix + base_response\n",
        "\n",
        "    # Add emoji only if it's not already a very long response\n",
        "    if len(enhanced_response) < 500:\n",
        "        enhanced_response += f\" {emoji}\"\n",
        "\n",
        "    return enhanced_response\n",
        "# Main application class\n",
        "class WellbeingChatbotApp:\n",
        "    def __init__(self):\n",
        "        # Initialize components\n",
        "        self.db = get_firestore_db()\n",
        "\n",
        "        # More specific ASR model loading with better error handling\n",
        "        print(\"Loading ASR model...\")\n",
        "        try:\n",
        "            self.asr_model = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
        "            print(\"ASR model loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading ASR model: {str(e)}\")\n",
        "            print(\"Using fallback for ASR (text-only functionality)\")\n",
        "            self.asr_model = None\n",
        "\n",
        "        self.vector_db = create_vector_db()\n",
        "        self.llm = initialize_llm(temperature=0.2)\n",
        "        self.theme = load_theme()\n",
        "        self.current_user = \"Guest\"\n",
        "        self.current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        # Define UI\n",
        "        self.interface = self.build_interface()\n",
        "\n",
        "    # Add this new method to process audio inputs specifically\n",
        "    def process_audio_input(self, user_id, user_message, audio_file, history, conversation_id):\n",
        "        \"\"\"Handle audio input specifically\"\"\"\n",
        "        try:\n",
        "            if audio_file is None:\n",
        "                return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "            # Transcribe audio to text\n",
        "            transcribed_text = transcribe_audio(audio_file, self.asr_model)\n",
        "\n",
        "            if not transcribed_text or not transcribed_text.strip():\n",
        "                # Failed transcription\n",
        "                new_history = history.copy()\n",
        "                new_history.append((\"\", \"I couldn't understand the audio. Could you please try speaking again or type your message?\"))\n",
        "                return new_history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "            # Process the transcribed text - first show what was transcribed\n",
        "            new_history = history.copy()\n",
        "            new_history.append((f\"[Audio] {transcribed_text}\", \"\"))\n",
        "\n",
        "            # Now process it like a normal message\n",
        "            final_history, _, final_conv_id, conv_list, conv_ids = self.process_conversation_input(\n",
        "                user_id, transcribed_text, new_history, conversation_id\n",
        "            )\n",
        "\n",
        "            return final_history, \"\", final_conv_id, conv_list, conv_ids\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing audio input: {str(e)}\")\n",
        "            new_history = history.copy()\n",
        "            new_history.append((\"\", f\"I encountered an error processing your audio. Could you please try again?\"))\n",
        "            return new_history, \"\", conversation_id, gr.update(), []\n",
        "    def check_login(self, email, password):\n",
        "        success, user_id, message, chat_sessions, daily_tip = authenticate_user(self.db, email, password)\n",
        "\n",
        "        if success:\n",
        "            try:\n",
        "            # Fetch all conversations for the user\n",
        "                conversations = get_all_conversations(self.db, user_id)\n",
        "                conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "                conv_ids = [c[\"id\"] for c in conversations]\n",
        "\n",
        "            # If there are conversations, load the most recent one\n",
        "                initial_history = []\n",
        "                initial_conv_id = None\n",
        "\n",
        "                return (\n",
        "                    message,                              # Login status message\n",
        "                    gr.update(visible=False),             # Hide login container\n",
        "                    gr.update(visible=True),              # Show chat container\n",
        "                    user_id,                              # User ID\n",
        "                    gr.update(choices=conv_choices,       # Update conversation list\n",
        "                            value=None),\n",
        "                    daily_tip,                            # Daily tip\n",
        "                    initial_history,                      # Initial chat history\n",
        "                    initial_conv_id,                      # Initial conversation ID\n",
        "                    conv_ids                              # List of conversation IDs\n",
        "              )\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading initial conversations: {e}\")\n",
        "                return (\n",
        "                    f\"Login successful but error loading conversations: {str(e)}\",\n",
        "                    gr.update(visible=True),\n",
        "                    gr.update(visible=False),\n",
        "                    \"\",\n",
        "                    gr.update(choices=[]),\n",
        "                    \"\",\n",
        "                    [],\n",
        "                    None,\n",
        "                    []\n",
        "                )\n",
        "        else:\n",
        "            return (\n",
        "                message,\n",
        "                gr.update(visible=True),\n",
        "                gr.update(visible=False),\n",
        "                \"\",\n",
        "                gr.update(choices=[]),\n",
        "                \"\",\n",
        "                [],\n",
        "                None,\n",
        "                []\n",
        "            )\n",
        "    def process_emotion_detection(self, user_id, image, history, conversation_id):\n",
        "        try:\n",
        "            if image is None:\n",
        "                return history, conversation_id, gr.update(), []\n",
        "\n",
        "        # Detect emotion from the image\n",
        "            emotion_data = detect_emotion_from_image(image)\n",
        "\n",
        "        # Generate response based on detected emotion\n",
        "            response = generate_emotion_based_response(emotion_data)\n",
        "\n",
        "        # Update history with emotion detection result\n",
        "            new_history = history.copy()\n",
        "            emotion_message = f\"[Emotion Detection] Detected emotion: {emotion_data['dominant_emotion']}\"\n",
        "            new_history.append((emotion_message, response))\n",
        "\n",
        "        # Store conversation\n",
        "            if conversation_id is None:\n",
        "                conversation_id = f\"conv_{datetime.now().strftime('%Y%m%d%H%M%S')}_{random.randint(1000, 9999)}\"\n",
        "\n",
        "            store_conversation(self.db, user_id, conversation_id, emotion_message, response)\n",
        "\n",
        "        # Update conversation list\n",
        "            conversations = get_all_conversations(self.db, user_id)\n",
        "            conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "            conv_ids = [c[\"id\"] for c in conversations]\n",
        "\n",
        "            return new_history, conversation_id, gr.update(choices=conv_choices), conv_ids\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing emotion detection: {e}\")\n",
        "            return history, conversation_id, gr.update(), []\n",
        "    def register_new_user(self, email, password):\n",
        "        success, user_id, message, chat_sessions, daily_tip = register_user(self.db, email, password)\n",
        "\n",
        "        if success:\n",
        "            return message, gr.update(visible=False), gr.update(visible=True), user_id, gr.update(choices=chat_sessions, value=None), daily_tip\n",
        "        else:\n",
        "            return message, gr.update(visible=True), gr.update(visible=False), \"\", gr.update(choices=[]), \"\"\n",
        "\n",
        "    def process_user_input(self, user_id, user_message, audio_file, history):\n",
        "        return process_input(\n",
        "            self.db, user_id, user_message, audio_file, history,\n",
        "            self.asr_model, self.vector_db, self.llm\n",
        "        )\n",
        "\n",
        "    def new_chat(self):\n",
        "        return []\n",
        "\n",
        "    def load_session(self, user_id, session_timestamp):\n",
        "        return load_chat_by_session(self.db, user_id, session_timestamp)\n",
        "\n",
        "    def toggle_login_signup(self, is_login):\n",
        "        if is_login:\n",
        "            return gr.update(visible=True), gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)\n",
        "        else:\n",
        "            return gr.update(visible=False), gr.update(visible=True), gr.update(visible=False), gr.update(visible=True)\n",
        "\n",
        "    def load_conversation(self, user_id, selected_conversation, conversation_ids):\n",
        "        if not all([user_id, selected_conversation, conversation_ids]):\n",
        "            return [], None\n",
        "\n",
        "        try:\n",
        "            conversations = get_all_conversations(self.db, user_id)\n",
        "            conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "\n",
        "            if selected_conversation not in conv_choices:\n",
        "                return [], None\n",
        "\n",
        "            selected_idx = conv_choices.index(selected_conversation)\n",
        "\n",
        "            if selected_idx >= 0 and selected_idx < len(conversation_ids):\n",
        "                conversation_id = conversation_ids[selected_idx]\n",
        "                history = get_conversation_by_id(self.db, user_id, conversation_id)\n",
        "                return history, conversation_id\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading conversation: {e}\")\n",
        "        return [], None\n",
        "\n",
        "    def process_conversation_input(self, user_id, message, history, conversation_id):\n",
        "     try:\n",
        "        if not message:\n",
        "            return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "        # Get response using the LLM\n",
        "        llm = initialize_llm()\n",
        "        if llm:\n",
        "            # Analyze emotional content\n",
        "            emotions = analyze_emotional_content(message)\n",
        "\n",
        "            # Check for crisis keywords with more nuanced detection\n",
        "            crisis_check = check_for_crisis_and_severity(message)\n",
        "\n",
        "            if crisis_check['detected']:\n",
        "                response = generate_crisis_response(crisis_check['severity'], emotions)\n",
        "            else:\n",
        "                # Format the conversation history for context\n",
        "                conversation_context = \"\"\n",
        "                if history:\n",
        "                    for i, (user_msg, assistant_msg) in enumerate(history[-3:]):  # Include last 3 exchanges for context\n",
        "                        conversation_context += f\"User: {user_msg}\\nAssistant: {assistant_msg}\\n\\n\"\n",
        "\n",
        "                # Create prompt with conversation history and instructions for brevity\n",
        "                prompt = f\"\"\"You are Serene, a deeply empathetic mental wellbeing assistant with expertise in emotional support.\n",
        "\n",
        "                Previous conversation:\n",
        "                {conversation_context}\n",
        "\n",
        "                Current message: {message}\n",
        "\n",
        "                Remember to respond with warmth, empathy, and emotional intelligence, but keep your response brief and concise (2-3 sentences maximum). Focus on the most important aspects of the user's message.\n",
        "                \"\"\"\n",
        "\n",
        "                # Generate response using LLM with lower max_tokens\n",
        "                # Set temperature lower for more focused responses\n",
        "                llm_brief = initialize_llm(temperature=0.5)  # Lower temperature for more focused responses\n",
        "                base_response = llm_brief.invoke(prompt).content\n",
        "\n",
        "                # If response is still too long, truncate it\n",
        "                sentences = base_response.split('. ')\n",
        "                if len(sentences) > 3:\n",
        "                    base_response = '. '.join(sentences[:3]) + '.'\n",
        "\n",
        "                response = enhance_response_with_empathy(base_response, emotions)\n",
        "        else:\n",
        "            response = \"I'm here to listen and support you. What's on your mind today?\"\n",
        "\n",
        "        # Update history\n",
        "        new_history = history.copy()\n",
        "        new_history.append((message, response))\n",
        "\n",
        "        # Store conversation\n",
        "        if conversation_id is None:\n",
        "            conversation_id = f\"conv_{datetime.now().strftime('%Y%m%d%H%M%S')}_{random.randint(1000, 9999)}\"\n",
        "\n",
        "        store_conversation(self.db, user_id, conversation_id, message, response)\n",
        "\n",
        "        # Update conversation list\n",
        "        conversations = get_all_conversations(self.db, user_id)\n",
        "        conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "        conv_ids = [c[\"id\"] for c in conversations]\n",
        "\n",
        "        return new_history, \"\", conversation_id, gr.update(choices=conv_choices), conv_ids\n",
        "\n",
        "     except Exception as e:\n",
        "        print(f\"Error processing input: {e}\")\n",
        "        return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "    def build_interface(self):\n",
        "        with gr.Blocks(theme=self.theme, css=\"\"\"\n",
        "            .gradio-container {max-width: 1200px !important}\n",
        "            .header-text {text-align: center; font-weight: 600 !important}\n",
        "            .chat-history {border-left: 1px solid rgba(0,0,0,0.1)}\n",
        "            .welcome-box {background-color: rgba(89, 193, 189, 0.1); padding: 20px; border-radius: 12px; margin-bottom: 20px}\n",
        "            .tip-box {background-color: linear-gradient(135deg, #43c6ac, #59C1BD);; border-left: 4px solid teal; padding: 12px; margin: 12px 0; border-radius: 4px}\n",
        "            .tab-buttons {text-align: center; margin-bottom: 20px;}\n",
        "            .tab-button {margin: 0 10px; padding: 8px 16px; border-radius: 20px; background-color: #f0f0f0; border: none; cursor: pointer;}\n",
        "            .tab-button.active {background-color: #59C1BD; color: white;}\n",
        "        \"\"\") as interface:\n",
        "            # State variables\n",
        "            user_id = gr.State(\"\")\n",
        "            current_conversation_id = gr.State(None)\n",
        "            conversation_ids = gr.State([])\n",
        "\n",
        "            # Login container\n",
        "            login_container = gr.Column(visible=True)\n",
        "            chat_container = gr.Column(visible=False)\n",
        "\n",
        "            with login_container:\n",
        "                gr.Markdown(\"# Mental Wellbeing Chatbot\", elem_classes=[\"header-text\"])\n",
        "\n",
        "                # Tab buttons for login/signup\n",
        "                with gr.Row(elem_classes=[\"tab-buttons\"]):\n",
        "                    login_tab_btn = gr.Button(\"Login\", elem_classes=[\"tab-button\", \"active\"])\n",
        "                    signup_tab_btn = gr.Button(\"Sign Up\", elem_classes=[\"tab-button\"])\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        # Login Form\n",
        "                        login_form = gr.Group(visible=True)\n",
        "                        with login_form:\n",
        "                            gr.Markdown(\"### Sign in to your account\")\n",
        "                            email_login = gr.Textbox(label=\"Email\", interactive=True, placeholder=\"Your email\")\n",
        "                            password_login = gr.Textbox(label=\"Password\", type=\"password\", interactive=True, placeholder=\"Your password\")\n",
        "                            login_button = gr.Button(\"Sign In\", variant=\"primary\", size=\"lg\")\n",
        "                            login_status = gr.Textbox(label=\"Status\", interactive=False, visible=False)\n",
        "\n",
        "                        # Register Form\n",
        "                        register_form = gr.Group(visible=False)\n",
        "                        with register_form:\n",
        "                            gr.Markdown(\"### Create a new account\")\n",
        "                            email_register = gr.Textbox(label=\"Email\", interactive=True, placeholder=\"Your email\")\n",
        "                            password_register = gr.Textbox(label=\"Password\", type=\"password\", interactive=True, placeholder=\"Create a password\")\n",
        "                            confirm_password = gr.Textbox(label=\"Confirm Password\", type=\"password\", interactive=True, placeholder=\"Confirm your password\")\n",
        "                            register_button = gr.Button(\"Create Account\", variant=\"primary\", size=\"lg\")\n",
        "                            register_status = gr.Textbox(label=\"Status\", interactive=False, visible=False)\n",
        "\n",
        "            with chat_container:\n",
        "                gr.Markdown(\"# Mental Wellbeing Chatbot\", elem_classes=[\"header-text\"])\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        with gr.Group(elem_classes=[\"welcome-box\"]):\n",
        "                            gr.Markdown(\"### Welcome back!\")\n",
        "                            daily_tip_display = gr.Markdown(elem_classes=[\"tip-box\"])\n",
        "\n",
        "                        gr.Markdown(\"### Quick Resources\")\n",
        "                        resource_links = gr.Markdown(\"\"\"\n",
        "                        - [Guided Meditation](https://www.mindful.org/meditation/mindfulness-getting-started/)\n",
        "                        - [Deep Breathing Exercises](https://tools.wearewithyou.org.uk/deepbreathing/)\n",
        "                        - [Positive Affirmations](https://www.priorygroup.com/self-care/positive-affirmations-for-mental-health)\n",
        "                        - [Crisis Support Resources](https://www.crisistextline.org/)\n",
        "                        \"\"\")\n",
        "\n",
        "                        gr.Markdown(\"### Start a New Chat or View Past Conversations\")\n",
        "                        conversation_list = gr.Radio(choices=[], label=\"Select a previous conversation or start typing below to begin a new chat\",\n",
        "                                                                        value=None)\n",
        "                        load_conversation_button = gr.Button(\"Load Selected Conversation\", variant=\"secondary\")\n",
        "                        new_chat_button = gr.Button(\"+ Start New Conversation\", variant=\"secondary\")\n",
        "\n",
        "                    with gr.Column(scale=3, elem_classes=[\"chat-history\"]):\n",
        "                        chat_display = gr.Chatbot(\n",
        "                            label=\"Your conversation\",\n",
        "                            height=500,\n",
        "                            avatar_images=[\n",
        "                                \"https://img.icons8.com/ios-filled/50/000000/user-male-circle.png\",\n",
        "                                \"https://img.icons8.com/ios-filled/50/59C1BD/teal-meditation.png\"\n",
        "                            ]\n",
        "                        )\n",
        "\n",
        "                        with gr.Row():\n",
        "                           user_input = gr.Textbox(\n",
        "                           label=\"Type your message...\",\n",
        "                           placeholder=\"Share how you're feeling or ask for support...\",\n",
        "                           lines=2,\n",
        "                           scale=4\n",
        "            )\n",
        "                           audio_input = gr.Audio(\n",
        "                           label=\"🎤 Speak\",\n",
        "                           source=\"microphone\",\n",
        "                           type=\"filepath\",\n",
        "                           streaming=False,  # Set to False for better browser compatibility\n",
        "                           format=\"wav\",     # Specify format for better compatibility\n",
        "                           scale=1\n",
        "            )\n",
        "                           emotion_input = gr.Image(\n",
        "                           label=\"📷 Detect Emotion\",\n",
        "                           source=\"webcam\",\n",
        "                           streaming=False,\n",
        "                           type=\"numpy\"\n",
        "           )\n",
        "\n",
        "\n",
        "                        send_button = gr.Button(\"Send Message\", variant=\"primary\")\n",
        "\n",
        "                        gr.Markdown(\"\"\"\n",
        "                        ### About the Chatbot\n",
        "                        This is an AI companion for mental wellbeing. Share your thoughts, feelings, and concerns in a safe, judgment-free space. While this chatbot can provide support and guidance, it's not a replacement for professional mental health care. If you're experiencing a crisis, please contact a mental health professional or crisis hotline.\n",
        "                        \"\"\")\n",
        "\n",
        "            # Connect the buttons to functions\n",
        "            login_tab_btn.click(\n",
        "                self.toggle_login_signup,\n",
        "                inputs=[gr.State(True)],\n",
        "                outputs=[login_form, register_form, login_tab_btn, signup_tab_btn]\n",
        "            )\n",
        "\n",
        "            signup_tab_btn.click(\n",
        "                self.toggle_login_signup,\n",
        "                inputs=[gr.State(False)],\n",
        "                outputs=[login_form, register_form, login_tab_btn, signup_tab_btn]\n",
        "            )\n",
        "# Add this with your other event handlers\n",
        "            emotion_input.change(\n",
        "                self.process_emotion_detection,\n",
        "                inputs=[user_id, emotion_input, chat_display, current_conversation_id],\n",
        "                outputs=[chat_display, current_conversation_id, conversation_list, conversation_ids]\n",
        "            )\n",
        "            # Login functionality\n",
        "            # In build_interface method, update the login button click event\n",
        "            login_button.click(\n",
        "                self.check_login,\n",
        "                inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                login_status,\n",
        "                login_container,\n",
        "                chat_container,\n",
        "                user_id,\n",
        "                conversation_list,\n",
        "                daily_tip_display,\n",
        "                chat_display,              # Add chat display to outputs\n",
        "                current_conversation_id,    # Add current conversation ID\n",
        "                conversation_ids           # Add conversation IDs\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            # Also update the email and password submit events similarly\n",
        "            email_login.submit(\n",
        "                self.check_login,\n",
        "                inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                    login_status,\n",
        "                    login_container,\n",
        "                    chat_container,\n",
        "                    user_id,\n",
        "                    conversation_list,\n",
        "                    daily_tip_display,\n",
        "                    chat_display,\n",
        "                    current_conversation_id,\n",
        "                    conversation_ids\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            password_login.submit(\n",
        "                  self.check_login,\n",
        "                  inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                      login_status,\n",
        "                      login_container,\n",
        "                      chat_container,\n",
        "                      user_id,\n",
        "                      conversation_list,\n",
        "                      daily_tip_display,\n",
        "                      chat_display,\n",
        "                      current_conversation_id,\n",
        "                      conversation_ids\n",
        "                    ]\n",
        "              )\n",
        "\n",
        "            # Registration functionality\n",
        "            def validate_and_register(email, password, confirm_password):\n",
        "                if password != confirm_password:\n",
        "                    return \"Passwords do not match. Please try again.\", gr.update(visible=True), gr.update(visible=False), \"\", gr.update(choices=[]), \"\"\n",
        "                return self.register_new_user(email, password)\n",
        "\n",
        "            register_button.click(\n",
        "                validate_and_register,\n",
        "                inputs=[email_register, password_register, confirm_password],\n",
        "                outputs=[register_status, login_container, chat_container, user_id, conversation_list, daily_tip_display]\n",
        "            )\n",
        "\n",
        "            # Chat functionality\n",
        "            send_button.click(\n",
        "                self.process_conversation_input,\n",
        "                inputs=[user_id, user_input, chat_display, current_conversation_id],\n",
        "                outputs=[chat_display, user_input, current_conversation_id, conversation_list, conversation_ids]\n",
        "            )\n",
        "\n",
        "            user_input.submit(\n",
        "                self.process_conversation_input,\n",
        "                inputs=[user_id, user_input, chat_display, current_conversation_id],\n",
        "                outputs=[chat_display, user_input, current_conversation_id, conversation_list, conversation_ids]\n",
        "            )\n",
        "\n",
        "            load_conversation_button.click(\n",
        "                self.load_conversation,\n",
        "                inputs=[user_id, conversation_list, conversation_ids],\n",
        "                outputs=[chat_display, current_conversation_id]\n",
        "            )\n",
        "            audio_input.change(\n",
        "               self.process_audio_input,\n",
        "               inputs=[user_id, gr.State(\"\"), audio_input, chat_display, current_conversation_id],  # Empty string for user_message\n",
        "               outputs=[chat_display, gr.State(\"\"), current_conversation_id, conversation_list, conversation_ids]\n",
        "             )\n",
        "\n",
        "            new_chat_button.click(\n",
        "                lambda: ([], None),\n",
        "                outputs=[chat_display, current_conversation_id]\n",
        "            )\n",
        "\n",
        "            return interface\n",
        "\n",
        "    def launch(self, **kwargs):\n",
        "        self.interface.launch(**kwargs)\n",
        "\n",
        "# Run the application\n",
        "if __name__ == \"__main__\":\n",
        "    app = WellbeingChatbotApp()\n",
        "    app.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okuDuEuj7CE7"
      },
      "outputs": [],
      "source": [
        "#need changes with a;lways webcam on and ability to take multiple times images in a single conversation\n",
        "import gradio as gr\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import pipeline\n",
        "import os\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, auth, firestore\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from datetime import datetime\n",
        "import random\n",
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import base64\n",
        "import io\n",
        "def detect_emotion_from_image(image_data):\n",
        "    try:\n",
        "        # Convert the image data to a format DeepFace can process\n",
        "        if isinstance(image_data, str) and image_data.startswith('data:image'):\n",
        "            # Handle base64 encoded image\n",
        "            image_data = image_data.split(',')[1]\n",
        "            image_bytes = base64.b64decode(image_data)\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            image_array = np.array(image)\n",
        "        else:\n",
        "            # Handle numpy array\n",
        "            image_array = image_data\n",
        "\n",
        "        # Detect emotion using DeepFace\n",
        "        result = DeepFace.analyze(\n",
        "            image_array,\n",
        "            actions=['emotion'],\n",
        "            enforce_detection=False\n",
        "        )\n",
        "\n",
        "        # Get the dominant emotion\n",
        "        emotion = result[0]['dominant_emotion']\n",
        "\n",
        "        # Get all emotions with their scores\n",
        "        emotions = result[0]['emotion']\n",
        "\n",
        "        return {\n",
        "            'status': 'success',\n",
        "            'dominant_emotion': emotion,\n",
        "            'emotion_scores': emotions\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'status': 'error',\n",
        "            'message': str(e)\n",
        "        }\n",
        "\n",
        "def generate_emotion_based_response(emotion_data):\n",
        "    \"\"\"\n",
        "    Generate a response based on detected emotion\n",
        "    \"\"\"\n",
        "    if emotion_data['status'] == 'error':\n",
        "        return \"I couldn't detect your emotion clearly. Would you like to tell me how you're feeling?\"\n",
        "\n",
        "    emotion = emotion_data['dominant_emotion']\n",
        "\n",
        "    emotion_responses = {\n",
        "        'happy': [\n",
        "            \"I can see that you're feeling happy! That's wonderful! Would you like to share what's bringing you joy?\",\n",
        "            \"Your happiness is contagious! What's made your day special?\",\n",
        "            \"It's great to see you in such good spirits! How would you like to maintain this positive energy?\"\n",
        "        ],\n",
        "        'sad': [\n",
        "            \"I notice that you might be feeling down. Would you like to talk about what's troubling you?\",\n",
        "            \"It's okay to feel sad sometimes. I'm here to listen if you want to share.\",\n",
        "            \"I can see that you're going through a difficult moment. How can I support you right now?\"\n",
        "        ],\n",
        "        'angry': [\n",
        "            \"I can see that something might be frustrating you. Would you like to talk about what's bothering you?\",\n",
        "            \"It's natural to feel angry sometimes. Would you like to discuss what triggered these feelings?\",\n",
        "            \"I notice you might be feeling upset. How can I help you process these emotions?\"\n",
        "        ],\n",
        "        'fear': [\n",
        "            \"I can sense that you might be feeling anxious or afraid. Would you like to talk about your concerns?\",\n",
        "            \"It's okay to feel scared. We can work through these feelings together.\",\n",
        "            \"I'm here to support you through your fears. What's on your mind?\"\n",
        "        ],\n",
        "        'surprise': [\n",
        "            \"You seem surprised! Would you like to share what's unexpected?\",\n",
        "            \"Something seems to have caught you off guard. Would you like to talk about it?\",\n",
        "            \"I notice your surprise! What's on your mind?\"\n",
        "        ],\n",
        "        'neutral': [\n",
        "            \"How are you feeling right now? I'm here to listen.\",\n",
        "            \"Would you like to share what's on your mind?\",\n",
        "            \"I'm here to support you. What would you like to talk about?\"\n",
        "        ],\n",
        "        'disgust': [\n",
        "            \"I notice you might be feeling uncomfortable. Would you like to talk about what's bothering you?\",\n",
        "            \"Something seems to be troubling you. I'm here to listen if you want to share.\",\n",
        "            \"Would you like to discuss what's making you feel this way?\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return random.choice(emotion_responses.get(emotion, emotion_responses['neutral']))\n",
        "# Predefined wellness tips\n",
        "WELLNESS_TIPS = [\n",
        "    \"Take a few deep breaths when feeling stressed.\",\n",
        "    \"Stay hydrated throughout the day.\",\n",
        "    \"Try to get at least 7-8 hours of sleep each night.\",\n",
        "    \"Take short breaks during work to stretch and move.\",\n",
        "    \"Practice gratitude by noting three things you're thankful for.\",\n",
        "    \"Spend time in nature when possible.\",\n",
        "    \"Limit screen time before bed for better sleep.\",\n",
        "    \"Connect with a friend or family member today.\",\n",
        "    \"Try a 5-minute meditation to clear your mind.\",\n",
        "    \"Move your body for at least 30 minutes today.\"\n",
        "]\n",
        "\n",
        "# Initialize Firebase only once\n",
        "def initialize_firebase():\n",
        "    if not firebase_admin._apps:\n",
        "        try:\n",
        "            cred = credentials.Certificate(\"/content/data/firebase_credentials.json\")  # Update this path!\n",
        "            firebase_admin.initialize_app(cred)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Firebase initialization error: {e}\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Initialize Firestore\n",
        "def get_firestore_db():\n",
        "    if initialize_firebase():\n",
        "        return firestore.client()\n",
        "    return None\n",
        "\n",
        "# Load ASR Model\n",
        "def load_asr_model():\n",
        "    try:\n",
        "        return pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading ASR model: {e}\")\n",
        "        return None\n",
        "\n",
        "# Get random wellness tip\n",
        "def get_daily_tip():\n",
        "    \"\"\"Returns a random wellness tip\"\"\"\n",
        "    return random.choice(WELLNESS_TIPS)\n",
        "\n",
        "# Initialize LLM with mental wellbeing focus\n",
        "def initialize_llm(api_key=None, temperature=0.2):\n",
        "    try:\n",
        "        # Use provided API key or default to environment variable\n",
        "        groq_api_key = api_key or \"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\"\n",
        "        llm = ChatGroq(\n",
        "            temperature=temperature,  # Slightly increased for more natural responses\n",
        "            groq_api_key=groq_api_key,\n",
        "            model_name=\"llama-3.3-70b-versatile\"\n",
        "        )\n",
        "        return llm\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing LLM: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create or load vector database\n",
        "def create_vector_db(db_path=\"/content/chroma_db\"):\n",
        "    try:\n",
        "        if not os.path.exists(db_path):\n",
        "            os.makedirs(db_path)\n",
        "\n",
        "        embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "        return Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating vector database: {e}\")\n",
        "        return None\n",
        "\n",
        "# Set up QA chain with a focus on context-aware and psychiatrist-like responses\n",
        "def setup_qa_chain(vector_db, llm):\n",
        "    \"\"\"Set up the QA retrieval chain with a focus on providing context-aware and psychiatrist-like responses\"\"\"\n",
        "    if vector_db is None or llm is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        retriever = vector_db.as_retriever()\n",
        "        prompt_template = \"\"\"You are a compassionate and knowledgeable mental wellbeing assistant named Serene, akin to a psychiatrist.\n",
        "\n",
        "        Your primary goal is to provide supportive, empathetic, and insightful responses that help the user improve their mental wellbeing.\n",
        "        Always maintain a warm, understanding tone and never judge the user.\n",
        "\n",
        "        Guidelines for your responses:\n",
        "        - Begin with validation of the user's feelings (\"I understand that feeling...\", \"That sounds really challenging...\")\n",
        "        - Use a warm, conversational tone that shows genuine care\n",
        "        - Offer specific, actionable suggestions tailored to their situation, not generic advice\n",
        "        - Ask thoughtful follow-up questions to show you're really listening\n",
        "        - Share relevant coping strategies or techniques that might help their specific situation\n",
        "        - When appropriate, gently normalize their experiences (\"Many people feel this way...\")\n",
        "        - Always respond with empathy first, then helpful information second\n",
        "        - Provide deeper insights and reflective questions to encourage self-awareness and personal growth\n",
        "\n",
        "        For different emotional states:\n",
        "        - When user seems anxious: Use calming language, offer grounding techniques, validate their worries\n",
        "        - When user seems sad: Show compassion, acknowledge the pain, offer gentle encouragement\n",
        "        - When user seems frustrated: Validate their feelings, show patience, offer perspective\n",
        "        - When user seems confused: Provide clarity, break down concepts, be reassuring\n",
        "\n",
        "        If the user appears to be in crisis, gently suggest they reach out to a mental health professional or crisis hotline,\n",
        "        but continue to engage with them supportively.\n",
        "\n",
        "        Relevant context from your knowledge base:\n",
        "        {context}\n",
        "\n",
        "        User: {question}\n",
        "\n",
        "        Serene:\"\"\"\n",
        "\n",
        "        PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "        qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=retriever,\n",
        "            chain_type_kwargs={\"prompt\": PROMPT}\n",
        "        )\n",
        "\n",
        "        return qa_chain\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up QA chain: {e}\")\n",
        "        return None\n",
        "\n",
        "# Generate chatbot response with crisis detection and coping strategies\n",
        "def chatbot_response(db, user_id, user_input, history, vector_db=None, llm=None):\n",
        "    \"\"\" Generate chatbot response and store it in chat history \"\"\"\n",
        "    try:\n",
        "        # Initialize components if not provided\n",
        "        if vector_db is None:\n",
        "            vector_db = create_vector_db()\n",
        "\n",
        "        if llm is None:\n",
        "            llm = initialize_llm()\n",
        "\n",
        "        qa_chain = setup_qa_chain(vector_db, llm)\n",
        "\n",
        "        # Check for crisis keywords\n",
        "        is_crisis = check_for_crisis(user_input)\n",
        "\n",
        "        if is_crisis:\n",
        "            response = \"\"\"I notice you've mentioned something concerning. If you're in crisis, please consider reaching out to a crisis helpline:\n",
        "            - National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "            - Crisis Text Line: Text HOME to 741741 📱\n",
        "\n",
        "            These services are available 24/7 and provide confidential support. Would you like to talk about what you're feeling right now? I'm here to listen. 💬\"\"\"\n",
        "        elif qa_chain is None:\n",
        "            response = \"I'm having trouble connecting to my knowledge base. Let's focus on how you're feeling today. What would help you feel more at ease right now? 🧘\"\n",
        "        else:\n",
        "            # Generate a response using the QA chain\n",
        "            raw_response = qa_chain.run(user_input)\n",
        "\n",
        "            # Enhance with empathy, context-awareness, and coping strategies\n",
        "            response = f\"I understand that you're feeling {user_input}. {raw_response} 🤗\"\n",
        "\n",
        "            # Add specific coping strategies based on emotional state\n",
        "            if \"anxious\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with anxiety:\\n- Practice deep breathing exercises 🧘\\n- Try grounding techniques like focusing on your senses 🌱\\n- Take a short walk to clear your mind 🚶\\n- Write down your thoughts in a journal 📓\"\n",
        "            elif \"sad\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with sadness:\\n- Reach out to a friend or family member 📞\\n- Engage in a hobby or activity you enjoy 🎨\\n- Practice self-compassion and be kind to yourself 💖\\n- Reflect on positive memories or experiences 📝\"\n",
        "            elif \"frustrated\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with frustration:\\n- Take a few deep breaths and count to ten 🧘\\n- Step away from the situation and take a break 🌳\\n- Talk it out with someone you trust 🗣️\\n- Focus on solutions rather than problems 🔍\"\n",
        "\n",
        "        # Update history\n",
        "        updated_history = history.copy()\n",
        "        updated_history.append((user_input, response))\n",
        "\n",
        "        # Store in Firebase if available\n",
        "        if db is not None and user_id:\n",
        "            store_chat_history(db, user_id, updated_history)\n",
        "\n",
        "        return user_input, response, updated_history\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return user_input, \"Sorry, I encountered an error while processing your request.\", history\n",
        "\n",
        "# Transcribe audio to text\n",
        "def transcribe_audio(audio_path, asr_model):\n",
        "    if not audio_path or not os.path.exists(audio_path) or asr_model is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        transcription = asr_model(audio_path)[\"text\"]\n",
        "        return transcription\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing audio: {e}\")\n",
        "        return None\n",
        "\n",
        "# Store chat history in Firebase with timestamps\n",
        "def store_chat_history(db, user_id, history):\n",
        "    if db is None or not user_id:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        formatted_history = [{\"message\": msg, \"response\": resp, \"timestamp\": timestamp} for msg, resp in history]\n",
        "        db.collection(\"chat_history\").document(user_id).set({\"history\": formatted_history})\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error storing chat history: {e}\")\n",
        "        return False\n",
        "\n",
        "# Fetch chat history from Firebase\n",
        "def fetch_chat_history(db, user_id):\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            chat_list = chats.to_dict().get(\"history\", [])\n",
        "            return [(chat[\"message\"], chat[\"response\"]) for chat in chat_list]\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching chat history: {e}\")\n",
        "        return []\n",
        "\n",
        "# Get chat sessions by timestamp\n",
        "def get_chat_sessions(db, user_id):\n",
        "    \"\"\" Get list of chat sessions with timestamps \"\"\"\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            chat_list = chats.to_dict().get(\"history\", [])\n",
        "            if chat_list:\n",
        "                # Group by timestamps to create session names\n",
        "                timestamps = set([chat.get(\"timestamp\", \"Unknown\") for chat in chat_list])\n",
        "                return list(timestamps)\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting chat sessions: {e}\")\n",
        "        return []\n",
        "\n",
        "# Check for crisis keywords in user input\n",
        "def check_for_crisis(user_input):\n",
        "    crisis_keywords = [\"suicide\", \"kill myself\", \"end my life\", \"don't want to live\"]\n",
        "    return any(keyword in user_input.lower() for keyword in crisis_keywords)\n",
        "\n",
        "# Generate chatbot response with crisis detection\n",
        "\n",
        "def process_input(db, user_id, user_message, audio_file, history, asr_model, vector_db, llm):\n",
        "    if audio_file:\n",
        "        transcribed_text = transcribe_audio(audio_file, asr_model)\n",
        "        if transcribed_text:\n",
        "            _, _, updated_history = chatbot_response(db, user_id, transcribed_text, history, vector_db, llm)\n",
        "            return updated_history, \"\", None\n",
        "\n",
        "    if user_message:\n",
        "        _, _, updated_history = chatbot_response(db, user_id, user_message, history, vector_db, llm)\n",
        "        return updated_history, \"\", None\n",
        "\n",
        "    return history, \"\", None\n",
        "\n",
        "# Store conversation in Firestore\n",
        "def store_conversation(db, user_id, conversation_id, message, response):\n",
        "    if db is None or not user_id:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        conv_ref = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").document(conversation_id)\n",
        "        conv_doc = conv_ref.get()\n",
        "\n",
        "        if conv_doc.exists:\n",
        "            conv_data = conv_doc.to_dict()\n",
        "            messages = conv_data.get(\"messages\", [])\n",
        "            messages.append({\n",
        "                \"user_message\": message,\n",
        "                \"assistant_response\": response,\n",
        "                \"timestamp\": timestamp\n",
        "            })\n",
        "            conv_ref.update({\n",
        "                \"messages\": messages,\n",
        "                \"last_updated\": timestamp,\n",
        "                \"title\": message[:30] + \"...\" if len(message) > 30 else message\n",
        "            })\n",
        "        else:\n",
        "            conv_ref.set({\n",
        "                \"messages\": [{\n",
        "                    \"user_message\": message,\n",
        "                    \"assistant_response\": response,\n",
        "                    \"timestamp\": timestamp\n",
        "                }],\n",
        "                \"created_at\": timestamp,\n",
        "                \"last_updated\": timestamp,\n",
        "                \"title\": message[:30] + \"...\" if len(message) > 30 else message\n",
        "            })\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error storing conversation: {e}\")\n",
        "        return False\n",
        "\n",
        "# Get all conversations for a user\n",
        "def get_all_conversations(db, user_id):\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        conversations = []\n",
        "        conv_refs = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").order_by(\"last_updated\", direction=firestore.Query.DESCENDING)\n",
        "\n",
        "        for conv in conv_refs.stream():\n",
        "            conv_data = conv.to_dict()\n",
        "            conversations.append({\n",
        "                \"id\": conv.id,\n",
        "                \"title\": conv_data.get(\"title\", \"Unnamed conversation\"),\n",
        "                \"last_updated\": conv_data.get(\"last_updated\", \"Unknown date\"),\n",
        "                \"message_count\": len(conv_data.get(\"messages\", []))\n",
        "            })\n",
        "        return conversations\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching conversations: {e}\")\n",
        "        return []\n",
        "\n",
        "# Get a specific conversation by ID\n",
        "def get_conversation_by_id(db, user_id, conversation_id):\n",
        "    if db is None or not user_id or not conversation_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        conv_ref = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").document(conversation_id)\n",
        "        conv_doc = conv_ref.get()\n",
        "\n",
        "        if conv_doc.exists:\n",
        "            conv_data = conv_doc.to_dict()\n",
        "            messages = conv_data.get(\"messages\", [])\n",
        "            return [(msg[\"user_message\"], msg[\"assistant_response\"]) for msg in messages]\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching conversation: {e}\")\n",
        "        return []\n",
        "\n",
        "# Authenticate user via Firebase\n",
        "def authenticate_user(db, email, password):\n",
        "    try:\n",
        "        user = auth.get_user_by_email(email)\n",
        "        user_id = user.uid\n",
        "\n",
        "        # Fetch chat sessions\n",
        "        chat_sessions = get_chat_sessions(db, user_id)\n",
        "        daily_tip = get_daily_tip()\n",
        "\n",
        "        return True, user_id, \"Login successful!\", chat_sessions, daily_tip\n",
        "    except Exception as e:\n",
        "        print(f\"Authentication error: {e}\")\n",
        "        return False, \"\", f\"Login failed: {str(e)}\", [], \"\"\n",
        "\n",
        "# Register a new user\n",
        "def register_user(db, email, password):\n",
        "    try:\n",
        "        # Check if user already exists\n",
        "        try:\n",
        "            existing_user = auth.get_user_by_email(email)\n",
        "            if existing_user:\n",
        "                return False, \"\", \"Email already in use. Please log in instead.\", [], \"\"\n",
        "        except:\n",
        "            # User doesn't exist, proceed with registration\n",
        "            pass\n",
        "\n",
        "        # Create new user\n",
        "        user = auth.create_user(\n",
        "            email=email,\n",
        "            password=password,\n",
        "            email_verified=False\n",
        "        )\n",
        "\n",
        "        user_id = user.uid\n",
        "\n",
        "        # Initialize user data in Firestore\n",
        "        db.collection(\"user_data\").document(user_id).set({\n",
        "            \"email\": email,\n",
        "            \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        })\n",
        "\n",
        "        daily_tip = get_daily_tip()\n",
        "\n",
        "        return True, user_id, \"Registration successful! Welcome!\", [], daily_tip\n",
        "    except Exception as e:\n",
        "        print(f\"Registration error: {e}\")\n",
        "        return False, \"\", f\"Registration failed: {str(e)}\", [], \"\"\n",
        "\n",
        "# Load custom theme for mental wellbeing UI\n",
        "def load_theme():\n",
        "    \"\"\" Load the custom theme for the mental wellbeing chatbot \"\"\"\n",
        "    return gr.themes.Soft(\n",
        "        primary_hue=\"teal\",\n",
        "        secondary_hue=\"blue\",\n",
        "        neutral_hue=\"slate\",\n",
        "        radius_size=gr.themes.sizes.radius_md,\n",
        "        font=[gr.themes.GoogleFont(\"Nunito\"), gr.themes.GoogleFont(\"Quicksand\"), \"system-ui\", \"sans-serif\"]\n",
        "    )\n",
        "\n",
        "# Load chat by session timestamp\n",
        "def load_chat_by_session(db, user_id, session_timestamp):\n",
        "    if not session_timestamp or db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            all_chats = chats.to_dict().get(\"history\", [])\n",
        "            session_chats = [(chat[\"message\"], chat[\"response\"])\n",
        "                            for chat in all_chats\n",
        "                            if chat.get(\"timestamp\") == session_timestamp]\n",
        "            return session_chats\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading chat session: {e}\")\n",
        "        return []\n",
        "def analyze_emotional_content(text):\n",
        "    \"\"\"\n",
        "    Analyzes text for emotional content and returns detected emotions.\n",
        "\n",
        "    Args:\n",
        "        text (str): The user's message text\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing detected emotions and their confidence scores\n",
        "    \"\"\"\n",
        "    # Define emotion keywords for basic detection\n",
        "    emotion_keywords = {\n",
        "        'anxious': ['anxious', 'worried', 'nervous', 'panic', 'fear', 'stress', 'overwhelm', 'scared'],\n",
        "        'sad': ['sad', 'depressed', 'unhappy', 'miserable', 'grief', 'blue', 'down', 'heartbroken', 'upset'],\n",
        "        'angry': ['angry', 'frustrated', 'mad', 'furious', 'irritated', 'annoyed', 'rage', 'hate'],\n",
        "        'happy': ['happy', 'joy', 'excited', 'delighted', 'pleased', 'content', 'grateful', 'thankful'],\n",
        "        'neutral': ['okay', 'fine', 'alright', 'neutral']\n",
        "    }\n",
        "\n",
        "    # Initialize results with default values\n",
        "    results = {\n",
        "        'primary_emotion': 'neutral',\n",
        "        'confidence': 0.0,\n",
        "        'detected_emotions': {},\n",
        "        'intensity': 'low'\n",
        "    }\n",
        "\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Count emotion keywords in text\n",
        "    emotion_counts = {}\n",
        "    max_count = 0\n",
        "    primary_emotion = 'neutral'\n",
        "\n",
        "    for emotion, keywords in emotion_keywords.items():\n",
        "        count = sum(1 for keyword in keywords if keyword in text_lower)\n",
        "        if count > 0:\n",
        "            emotion_counts[emotion] = count\n",
        "            if count > max_count:\n",
        "                max_count = count\n",
        "                primary_emotion = emotion\n",
        "\n",
        "    # If no emotions detected, return neutral\n",
        "    if not emotion_counts:\n",
        "        return results\n",
        "\n",
        "    # Calculate rough confidence based on keyword frequency\n",
        "    total_keywords = sum(emotion_counts.values())\n",
        "\n",
        "    # Set primary emotion and confidence\n",
        "    results['primary_emotion'] = primary_emotion\n",
        "    results['confidence'] = min(0.95, max_count / (len(text.split()) * 0.5)) if total_keywords > 0 else 0.4\n",
        "    results['detected_emotions'] = emotion_counts\n",
        "\n",
        "    # Determine intensity based on modifier words and punctuation\n",
        "    intensity_markers = ['very', 'extremely', 'so', 'really', 'completely', 'absolutely', 'totally']\n",
        "    exclamation_count = text.count('!')\n",
        "    uppercase_ratio = sum(1 for c in text if c.isupper()) / max(len(text), 1)\n",
        "\n",
        "    intensity_score = sum(1 for marker in intensity_markers if marker in text_lower) + exclamation_count\n",
        "    intensity_score += 3 if uppercase_ratio > 0.3 else 0\n",
        "\n",
        "    if intensity_score > 3:\n",
        "        results['intensity'] = 'high'\n",
        "    elif intensity_score > 1:\n",
        "        results['intensity'] = 'medium'\n",
        "    else:\n",
        "        results['intensity'] = 'low'\n",
        "\n",
        "    return results\n",
        "\n",
        "# Function to check for crisis keywords with severity assessment\n",
        "def check_for_crisis_and_severity(text):\n",
        "    \"\"\"\n",
        "    Checks user input for crisis indicators and assesses severity.\n",
        "\n",
        "    Args:\n",
        "        text (str): The user's message text\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains crisis detection results and severity level\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Define crisis keywords with severity levels\n",
        "    high_severity_keywords = [\n",
        "        'kill myself', 'suicide', 'end my life', 'want to die',\n",
        "        'take my life', 'harm myself', 'hurt myself badly'\n",
        "    ]\n",
        "\n",
        "    medium_severity_keywords = [\n",
        "        'don\\'t want to live', 'no reason to live', 'better off dead',\n",
        "        'can\\'t go on', 'giving up', 'no hope', 'no future',\n",
        "        'self harm', 'cutting myself', 'hurting myself'\n",
        "    ]\n",
        "\n",
        "    low_severity_keywords = [\n",
        "        'hopeless', 'worthless', 'nothing matters', 'what\\'s the point',\n",
        "        'exhausted', 'can\\'t handle this', 'too much pain'\n",
        "    ]\n",
        "\n",
        "    # Check for high severity keywords (immediate crisis)\n",
        "    for keyword in high_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'high', 'keyword': keyword}\n",
        "\n",
        "    # Check for medium severity keywords (concerning)\n",
        "    for keyword in medium_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'medium', 'keyword': keyword}\n",
        "\n",
        "    # Check for low severity keywords (distress)\n",
        "    for keyword in low_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'low', 'keyword': keyword}\n",
        "\n",
        "    # No crisis keywords detected\n",
        "    return {'detected': False, 'severity': 'none', 'keyword': None}\n",
        "\n",
        "# Function to generate crisis responses based on severity\n",
        "def generate_crisis_response(severity, emotions):\n",
        "    \"\"\"\n",
        "    Generates appropriate responses for different crisis severity levels.\n",
        "\n",
        "    Args:\n",
        "        severity (str): The detected crisis severity level\n",
        "        emotions (dict): The emotional analysis results\n",
        "\n",
        "    Returns:\n",
        "        str: A compassionate response appropriate to the severity level\n",
        "    \"\"\"\n",
        "    if severity == 'high':\n",
        "        return \"\"\"I'm really concerned about what you're sharing. If you're having thoughts of harming yourself, please reach out to a crisis helpline immediately:\n",
        "\n",
        "• National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "• Crisis Text Line: Text HOME to 741741 📱\n",
        "• Or go to your nearest emergency room\n",
        "\n",
        "These services have trained professionals available 24/7 who can help you through this difficult time. Your life matters, and support is available. Would you like to talk more about what you're experiencing right now?\"\"\"\n",
        "\n",
        "    elif severity == 'medium':\n",
        "        return \"\"\"I hear that you're going through a really difficult time, and I'm concerned about what you're sharing. It's important to talk to someone who can provide professional support:\n",
        "\n",
        "• National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "• Crisis Text Line: Text HOME to 741741 📱\n",
        "\n",
        "Would it be possible for you to reach out to a mental health professional or trusted person in your life today? Your feelings are valid, and support is available. I'm here to listen if you'd like to share more.\"\"\"\n",
        "\n",
        "    elif severity == 'low':\n",
        "        primary_emotion = emotions.get('primary_emotion', 'distress')\n",
        "\n",
        "        responses = {\n",
        "            'anxious': \"I can hear the anxiety in your message, and that sounds really challenging. When everything feels overwhelming, it's important to be gentle with yourself. Would it help to talk about specific things that are causing you to feel this way?\",\n",
        "            'sad': \"I'm sorry you're feeling such sadness right now. It's okay to not be okay sometimes, and your feelings are valid. Would you like to share more about what's contributing to these feelings?\",\n",
        "            'angry': \"I can sense your frustration and anger. These are completely valid emotions, especially when dealing with difficult situations. Would it help to talk more about what's triggering these feelings?\",\n",
        "            'neutral': \"It sounds like you're going through a difficult time. Everyone struggles sometimes, and it's okay to reach out for support. Would talking to a mental health professional be an option for you?\"\n",
        "        }\n",
        "\n",
        "        base_response = responses.get(primary_emotion, responses['neutral'])\n",
        "        return base_response + \"\\n\\nIf you ever feel these thoughts becoming more intense or have thoughts of harming yourself, please reach out to a crisis helpline like the National Suicide Prevention Lifeline at 988.\"\n",
        "\n",
        "    else:\n",
        "        # Default response if severity assessment fails\n",
        "        return \"I notice you may be going through a difficult time. If you're feeling overwhelmed, talking to a mental health professional can really help. Would you like to share more about what you're experiencing?\"\n",
        "\n",
        "# Function to enhance responses with empathy based on emotions\n",
        "def enhance_response_with_empathy(base_response, emotions):\n",
        "    \"\"\"\n",
        "    Enhances LLM responses with appropriate empathetic elements based on detected emotions.\n",
        "\n",
        "    Args:\n",
        "        base_response (str): The original LLM response\n",
        "        emotions (dict): The emotional analysis results\n",
        "\n",
        "    Returns:\n",
        "        str: Enhanced response with appropriate empathetic elements\n",
        "    \"\"\"\n",
        "    primary_emotion = emotions.get('primary_emotion', 'neutral')\n",
        "    intensity = emotions.get('intensity', 'low')\n",
        "\n",
        "    # Add appropriate emoji based on emotion and intensity\n",
        "    emotion_emojis = {\n",
        "        'anxious': ['😟', '😥', '😰'],  # Low, Medium, High\n",
        "        'sad': ['😔', '😢', '😭'],\n",
        "        'angry': ['😒', '😠', '😡'],\n",
        "        'happy': ['🙂', '😊', '😄'],\n",
        "        'neutral': ['🙂', '😊', '💭']\n",
        "    }\n",
        "\n",
        "    intensity_index = {'low': 0, 'medium': 1, 'high': 2}.get(intensity, 0)\n",
        "    emoji = emotion_emojis.get(primary_emotion, emotion_emojis['neutral'])[intensity_index]\n",
        "\n",
        "    # Add empathetic prefix based on emotion\n",
        "    empathy_prefixes = {\n",
        "        'anxious': [\"I understand that anxiety can be overwhelming. \",\n",
        "                   \"It makes sense that you're feeling anxious. \",\n",
        "                   \"That kind of worry is really challenging to navigate. \"],\n",
        "        'sad': [\"I hear the sadness in your message. \",\n",
        "               \"I'm sorry you're feeling down right now. \",\n",
        "               \"It's okay to feel sad sometimes. \"],\n",
        "        'angry': [\"I can sense your frustration. \",\n",
        "                 \"I understand why that would be upsetting. \",\n",
        "                 \"It's natural to feel frustrated in that situation. \"],\n",
        "        'happy': [\"It's wonderful to hear that positivity! \",\n",
        "                 \"I'm glad you're feeling good. \",\n",
        "                 \"That's really great to hear. \"],\n",
        "        'neutral': [\"I appreciate you sharing that. \",\n",
        "                   \"Thank you for telling me about this. \",\n",
        "                   \"I'm here to listen. \"]\n",
        "    }\n",
        "\n",
        "    import random\n",
        "    prefix = random.choice(empathy_prefixes.get(primary_emotion, empathy_prefixes['neutral']))\n",
        "\n",
        "    # Combine elements\n",
        "    enhanced_response = prefix + base_response\n",
        "\n",
        "    # Add emoji only if it's not already a very long response\n",
        "    if len(enhanced_response) < 500:\n",
        "        enhanced_response += f\" {emoji}\"\n",
        "\n",
        "    return enhanced_response\n",
        "# Main application class\n",
        "class WellbeingChatbotApp:\n",
        "    def __init__(self):\n",
        "        # Initialize components\n",
        "        self.db = get_firestore_db()\n",
        "\n",
        "        # More specific ASR model loading with better error handling\n",
        "        print(\"Loading ASR model...\")\n",
        "        try:\n",
        "            self.asr_model = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
        "            print(\"ASR model loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading ASR model: {str(e)}\")\n",
        "            print(\"Using fallback for ASR (text-only functionality)\")\n",
        "            self.asr_model = None\n",
        "\n",
        "        self.vector_db = create_vector_db()\n",
        "        self.llm = initialize_llm(temperature=0.2)\n",
        "        self.theme = load_theme()\n",
        "        self.current_user = \"Guest\"\n",
        "        self.current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        # Define UI\n",
        "        self.interface = self.build_interface()\n",
        "\n",
        "    # Add this new method to process audio inputs specifically\n",
        "    def process_audio_input(self, user_id, user_message, audio_file, history, conversation_id):\n",
        "        \"\"\"Handle audio input specifically\"\"\"\n",
        "        try:\n",
        "            if audio_file is None:\n",
        "                return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "            # Transcribe audio to text\n",
        "            transcribed_text = transcribe_audio(audio_file, self.asr_model)\n",
        "\n",
        "            if not transcribed_text or not transcribed_text.strip():\n",
        "                # Failed transcription\n",
        "                new_history = history.copy()\n",
        "                new_history.append((\"\", \"I couldn't understand the audio. Could you please try speaking again or type your message?\"))\n",
        "                return new_history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "            # Process the transcribed text - first show what was transcribed\n",
        "            new_history = history.copy()\n",
        "            new_history.append((f\"[Audio] {transcribed_text}\", \"\"))\n",
        "\n",
        "            # Now process it like a normal message\n",
        "            final_history, _, final_conv_id, conv_list, conv_ids = self.process_conversation_input(\n",
        "                user_id, transcribed_text, new_history, conversation_id\n",
        "            )\n",
        "\n",
        "            return final_history, \"\", final_conv_id, conv_list, conv_ids\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing audio input: {str(e)}\")\n",
        "            new_history = history.copy()\n",
        "            new_history.append((\"\", f\"I encountered an error processing your audio. Could you please try again?\"))\n",
        "            return new_history, \"\", conversation_id, gr.update(), []\n",
        "    def check_login(self, email, password):\n",
        "        success, user_id, message, chat_sessions, daily_tip = authenticate_user(self.db, email, password)\n",
        "\n",
        "        if success:\n",
        "            try:\n",
        "            # Fetch all conversations for the user\n",
        "                conversations = get_all_conversations(self.db, user_id)\n",
        "                conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "                conv_ids = [c[\"id\"] for c in conversations]\n",
        "\n",
        "            # If there are conversations, load the most recent one\n",
        "                initial_history = []\n",
        "                initial_conv_id = None\n",
        "\n",
        "                return (\n",
        "                    message,                              # Login status message\n",
        "                    gr.update(visible=False),             # Hide login container\n",
        "                    gr.update(visible=True),              # Show chat container\n",
        "                    user_id,                              # User ID\n",
        "                    gr.update(choices=conv_choices,       # Update conversation list\n",
        "                            value=None),\n",
        "                    daily_tip,                            # Daily tip\n",
        "                    initial_history,                      # Initial chat history\n",
        "                    initial_conv_id,                      # Initial conversation ID\n",
        "                    conv_ids                              # List of conversation IDs\n",
        "              )\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading initial conversations: {e}\")\n",
        "                return (\n",
        "                    f\"Login successful but error loading conversations: {str(e)}\",\n",
        "                    gr.update(visible=True),\n",
        "                    gr.update(visible=False),\n",
        "                    \"\",\n",
        "                    gr.update(choices=[]),\n",
        "                    \"\",\n",
        "                    [],\n",
        "                    None,\n",
        "                    []\n",
        "                )\n",
        "        else:\n",
        "            return (\n",
        "                message,\n",
        "                gr.update(visible=True),\n",
        "                gr.update(visible=False),\n",
        "                \"\",\n",
        "                gr.update(choices=[]),\n",
        "                \"\",\n",
        "                [],\n",
        "                None,\n",
        "                []\n",
        "            )\n",
        "    def process_emotion_detection(self, user_id, image, history, conversation_id):\n",
        "        try:\n",
        "            if image is None:\n",
        "                return(\n",
        "                    history,\n",
        "                    conversation_id,\n",
        "                    gr.update(),\n",
        "                    [],                         # state (conversation_ids)\n",
        "                    gr.update(visible=True),    # image\n",
        "                    gr.update(visible=True),    # capture button\n",
        "                    gr.update(visible=False)    # reset button\n",
        "                )\n",
        "\n",
        "        # Detect emotion from the image\n",
        "            emotion_data = detect_emotion_from_image(image)\n",
        "\n",
        "        # Generate response based on detected emotion\n",
        "            response = generate_emotion_based_response(emotion_data)\n",
        "\n",
        "        # Update history with emotion detection result\n",
        "            new_history = history.copy()\n",
        "            emotion_message = f\"[Emotion Detection] Detected emotion: {emotion_data['dominant_emotion']}\"\n",
        "            new_history.append((emotion_message, response))\n",
        "\n",
        "        # Store conversation\n",
        "            if conversation_id is None:\n",
        "                conversation_id = f\"conv_{datetime.now().strftime('%Y%m%d%H%M%S')}_{random.randint(1000, 9999)}\"\n",
        "\n",
        "            store_conversation(self.db, user_id, conversation_id, emotion_message, response)\n",
        "\n",
        "        # Update conversation list\n",
        "            conversations = get_all_conversations(self.db, user_id)\n",
        "            conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "            conv_ids = [c[\"id\"] for c in conversations]\n",
        "\n",
        "            return (\n",
        "                new_history,\n",
        "                conversation_id,\n",
        "                gr.update(choices=conv_choices),\n",
        "                conv_ids,\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=True)\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing emotion detection: {e}\")\n",
        "            return history, conversation_id, gr.update(), [], gr.update(visible=True), gr.update(visible=True), gr.update(visible=False)\n",
        "    def register_new_user(self, email, password):\n",
        "        success, user_id, message, chat_sessions, daily_tip = register_user(self.db, email, password)\n",
        "\n",
        "        if success:\n",
        "            return message, gr.update(visible=False), gr.update(visible=True), user_id, gr.update(choices=chat_sessions, value=None), daily_tip\n",
        "        else:\n",
        "            return message, gr.update(visible=True), gr.update(visible=False), \"\", gr.update(choices=[]), \"\"\n",
        "\n",
        "    def process_user_input(self, user_id, user_message, audio_file, history):\n",
        "        return process_input(\n",
        "            self.db, user_id, user_message, audio_file, history,\n",
        "            self.asr_model, self.vector_db, self.llm\n",
        "        )\n",
        "\n",
        "    def new_chat(self):\n",
        "        return []\n",
        "    def show_camera():\n",
        "        \"\"\"Function to show the camera when needed\"\"\"\n",
        "        return gr.update(visible=True), gr.update(visible=True), gr.update(visible=True)\n",
        "\n",
        "    def reset_camera():\n",
        "        \"\"\"Function to reset the camera for another capture\"\"\"\n",
        "        return gr.update(value=None), gr.update(visible=True), gr.update(visible=True)\n",
        "\n",
        "    def hide_camera():\n",
        "        \"\"\"Function to hide the camera after capturing\"\"\"\n",
        "        return gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "    def load_session(self, user_id, session_timestamp):\n",
        "        return load_chat_by_session(self.db, user_id, session_timestamp)\n",
        "\n",
        "    def toggle_login_signup(self, is_login):\n",
        "        if is_login:\n",
        "            return gr.update(visible=True), gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)\n",
        "        else:\n",
        "            return gr.update(visible=False), gr.update(visible=True), gr.update(visible=False), gr.update(visible=True)\n",
        "\n",
        "    def load_conversation(self, user_id, selected_conversation, conversation_ids):\n",
        "        if not all([user_id, selected_conversation, conversation_ids]):\n",
        "            return [], None\n",
        "\n",
        "        try:\n",
        "            conversations = get_all_conversations(self.db, user_id)\n",
        "            conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "\n",
        "            if selected_conversation not in conv_choices:\n",
        "                return [], None\n",
        "\n",
        "            selected_idx = conv_choices.index(selected_conversation)\n",
        "\n",
        "            if selected_idx >= 0 and selected_idx < len(conversation_ids):\n",
        "                conversation_id = conversation_ids[selected_idx]\n",
        "                history = get_conversation_by_id(self.db, user_id, conversation_id)\n",
        "                return history, conversation_id\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading conversation: {e}\")\n",
        "        return [], None\n",
        "\n",
        "    def process_conversation_input(self, user_id, message, history, conversation_id):\n",
        "     try:\n",
        "        if not message:\n",
        "            return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "        # Get response using the LLM\n",
        "        llm = initialize_llm()\n",
        "        if llm:\n",
        "            # Analyze emotional content\n",
        "            emotions = analyze_emotional_content(message)\n",
        "\n",
        "            # Check for crisis keywords with more nuanced detection\n",
        "            crisis_check = check_for_crisis_and_severity(message)\n",
        "\n",
        "            if crisis_check['detected']:\n",
        "                response = generate_crisis_response(crisis_check['severity'], emotions)\n",
        "            else:\n",
        "                # Format the conversation history for context\n",
        "                conversation_context = \"\"\n",
        "                if history:\n",
        "                    for i, (user_msg, assistant_msg) in enumerate(history[-3:]):  # Include last 3 exchanges for context\n",
        "                        conversation_context += f\"User: {user_msg}\\nAssistant: {assistant_msg}\\n\\n\"\n",
        "\n",
        "                # Create prompt with conversation history and instructions for brevity\n",
        "                prompt = f\"\"\"You are Serene, a deeply empathetic mental wellbeing assistant with expertise in emotional support.\n",
        "\n",
        "                Previous conversation:\n",
        "                {conversation_context}\n",
        "\n",
        "                Current message: {message}\n",
        "\n",
        "                Remember to respond with warmth, empathy, and emotional intelligence, but keep your response brief and concise (2-3 sentences maximum). Focus on the most important aspects of the user's message.\n",
        "                \"\"\"\n",
        "\n",
        "                # Generate response using LLM with lower max_tokens\n",
        "                # Set temperature lower for more focused responses\n",
        "                llm_brief = initialize_llm(temperature=0.5)  # Lower temperature for more focused responses\n",
        "                base_response = llm_brief.invoke(prompt).content\n",
        "\n",
        "                # If response is still too long, truncate it\n",
        "                sentences = base_response.split('. ')\n",
        "                if len(sentences) > 3:\n",
        "                    base_response = '. '.join(sentences[:3]) + '.'\n",
        "\n",
        "                response = enhance_response_with_empathy(base_response, emotions)\n",
        "        else:\n",
        "            response = \"I'm here to listen and support you. What's on your mind today?\"\n",
        "\n",
        "        # Update history\n",
        "        new_history = history.copy()\n",
        "        new_history.append((message, response))\n",
        "\n",
        "        # Store conversation\n",
        "        if conversation_id is None:\n",
        "            conversation_id = f\"conv_{datetime.now().strftime('%Y%m%d%H%M%S')}_{random.randint(1000, 9999)}\"\n",
        "\n",
        "        store_conversation(self.db, user_id, conversation_id, message, response)\n",
        "\n",
        "        # Update conversation list\n",
        "        conversations = get_all_conversations(self.db, user_id)\n",
        "        conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "        conv_ids = [c[\"id\"] for c in conversations]\n",
        "\n",
        "        return new_history, \"\", conversation_id, gr.update(choices=conv_choices), conv_ids\n",
        "\n",
        "     except Exception as e:\n",
        "        print(f\"Error processing input: {e}\")\n",
        "        return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "    def build_interface(self):\n",
        "        with gr.Blocks(theme=self.theme, css=\"\"\"\n",
        "            .gradio-container {max-width: 1200px !important}\n",
        "            .header-text {text-align: center; font-weight: 600 !important}\n",
        "            .chat-history {border-left: 1px solid rgba(0,0,0,0.1)}\n",
        "            .welcome-box {background-color: rgba(89, 193, 189, 0.1); padding: 20px; border-radius: 12px; margin-bottom: 20px}\n",
        "            .tip-box {background-color: linear-gradient(135deg, #43c6ac, #59C1BD);; border-left: 4px solid teal; padding: 12px; margin: 12px 0; border-radius: 4px}\n",
        "            .tab-buttons {text-align: center; margin-bottom: 20px;}\n",
        "            .tab-button {margin: 0 10px; padding: 8px 16px; border-radius: 20px; background-color: #f0f0f0; border: none; cursor: pointer;}\n",
        "            .tab-button.active {background-color: #59C1BD; color: white;}\n",
        "        \"\"\") as interface:\n",
        "            # State variables\n",
        "            user_id = gr.State(\"\")\n",
        "            current_conversation_id = gr.State(None)\n",
        "            conversation_ids = gr.State([])\n",
        "\n",
        "            # Login container\n",
        "            login_container = gr.Column(visible=True)\n",
        "            chat_container = gr.Column(visible=False)\n",
        "\n",
        "            with login_container:\n",
        "                gr.Markdown(\"# Mental Wellbeing Chatbot\", elem_classes=[\"header-text\"])\n",
        "\n",
        "                # Tab buttons for login/signup\n",
        "                with gr.Row(elem_classes=[\"tab-buttons\"]):\n",
        "                    login_tab_btn = gr.Button(\"Login\", elem_classes=[\"tab-button\", \"active\"])\n",
        "                    signup_tab_btn = gr.Button(\"Sign Up\", elem_classes=[\"tab-button\"])\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        # Login Form\n",
        "                        login_form = gr.Group(visible=True)\n",
        "                        with login_form:\n",
        "                            gr.Markdown(\"### Sign in to your account\")\n",
        "                            email_login = gr.Textbox(label=\"Email\", interactive=True, placeholder=\"Your email\")\n",
        "                            password_login = gr.Textbox(label=\"Password\", type=\"password\", interactive=True, placeholder=\"Your password\")\n",
        "                            login_button = gr.Button(\"Sign In\", variant=\"primary\", size=\"lg\")\n",
        "                            login_status = gr.Textbox(label=\"Status\", interactive=False, visible=False)\n",
        "\n",
        "                        # Register Form\n",
        "                        register_form = gr.Group(visible=False)\n",
        "                        with register_form:\n",
        "                            gr.Markdown(\"### Create a new account\")\n",
        "                            email_register = gr.Textbox(label=\"Email\", interactive=True, placeholder=\"Your email\")\n",
        "                            password_register = gr.Textbox(label=\"Password\", type=\"password\", interactive=True, placeholder=\"Create a password\")\n",
        "                            confirm_password = gr.Textbox(label=\"Confirm Password\", type=\"password\", interactive=True, placeholder=\"Confirm your password\")\n",
        "                            register_button = gr.Button(\"Create Account\", variant=\"primary\", size=\"lg\")\n",
        "                            register_status = gr.Textbox(label=\"Status\", interactive=False, visible=False)\n",
        "\n",
        "            with chat_container:\n",
        "                gr.Markdown(\"# Mental Wellbeing Chatbot\", elem_classes=[\"header-text\"])\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        with gr.Group(elem_classes=[\"welcome-box\"]):\n",
        "                            gr.Markdown(\"### Welcome back!\")\n",
        "                            daily_tip_display = gr.Markdown(elem_classes=[\"tip-box\"])\n",
        "\n",
        "                        gr.Markdown(\"### Quick Resources\")\n",
        "                        resource_links = gr.Markdown(\"\"\"\n",
        "                        - [Guided Meditation](https://www.mindful.org/meditation/mindfulness-getting-started/)\n",
        "                        - [Deep Breathing Exercises](https://tools.wearewithyou.org.uk/deepbreathing/)\n",
        "                        - [Positive Affirmations](https://www.priorygroup.com/self-care/positive-affirmations-for-mental-health)\n",
        "                        - [Crisis Support Resources](https://www.crisistextline.org/)\n",
        "                        \"\"\")\n",
        "\n",
        "                        gr.Markdown(\"### Start a New Chat or View Past Conversations\")\n",
        "                        conversation_list = gr.Radio(choices=[], label=\"Select a previous conversation or start typing below to begin a new chat\",\n",
        "                                                                        value=None)\n",
        "                        load_conversation_button = gr.Button(\"Load Selected Conversation\", variant=\"secondary\")\n",
        "                        new_chat_button = gr.Button(\"+ Start New Conversation\", variant=\"secondary\")\n",
        "\n",
        "                    with gr.Column(scale=3, elem_classes=[\"chat-history\"]):\n",
        "                        chat_display = gr.Chatbot(\n",
        "                            label=\"Your conversation\",\n",
        "                            height=500,\n",
        "                            avatar_images=[\n",
        "                                \"https://img.icons8.com/ios-filled/50/000000/user-male-circle.png\",\n",
        "                                \"https://img.icons8.com/ios-filled/50/59C1BD/teal-meditation.png\"\n",
        "                            ]\n",
        "                        )\n",
        "\n",
        "                        with gr.Row():\n",
        "                            user_input = gr.Textbox(\n",
        "                                label=\"Type your message...\",\n",
        "                                placeholder=\"Share how you're feeling or ask for support...\",\n",
        "                                lines=2,\n",
        "                                scale=4\n",
        "                            )\n",
        "                            audio_input = gr.Audio(\n",
        "                                label=\"🎤 Speak\",\n",
        "                                source=\"microphone\",\n",
        "                                type=\"filepath\",\n",
        "                                streaming=False,\n",
        "                                format=\"wav\",\n",
        "                                scale=1\n",
        "                            )\n",
        "                            emotion_input = gr.Image(\n",
        "                                label=\"📷 Detect Emotion\",\n",
        "                                source=\"webcam\",\n",
        "                                streaming=False,\n",
        "                                type=\"numpy\",\n",
        "                                visible=False\n",
        "                            )\n",
        "                            capture_button = gr.Button(\"📸 Capture Emotion\", variant=\"secondary\")\n",
        "                            reset_emotion = gr.Button(\"🔄 Reset Camera\", variant=\"secondary\", visible=False)\n",
        "\n",
        "                        # Add the send button definition here, before its click event\n",
        "                        send_button = gr.Button(\"Send Message\", variant=\"primary\")\n",
        "\n",
        "                        def show_camera():\n",
        "                            return gr.update(visible=True), gr.update(visible=True), gr.update(visible=True)\n",
        "\n",
        "                        def reset_camera():\n",
        "                            return gr.update(value=None), gr.update(visible=True), gr.update(visible=True)\n",
        "\n",
        "                        def hide_camera():\n",
        "                            return gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "                        # Camera control event handlers\n",
        "                        capture_button.click(\n",
        "                            show_camera,\n",
        "                            outputs=[emotion_input, capture_button, reset_emotion]\n",
        "                        )\n",
        "\n",
        "                        reset_emotion.click(\n",
        "                            reset_camera,\n",
        "                            outputs=[emotion_input, capture_button, reset_emotion]\n",
        "                        )\n",
        "\n",
        "                        emotion_input.change(\n",
        "                            self.process_emotion_detection,\n",
        "                            inputs=[user_id, emotion_input, chat_display, current_conversation_id],\n",
        "                            outputs=[\n",
        "                                chat_display,\n",
        "                                current_conversation_id,\n",
        "                                conversation_list,\n",
        "                                conversation_ids,\n",
        "                                emotion_input,\n",
        "                                capture_button,\n",
        "                                reset_emotion\n",
        "                            ]\n",
        "                        )\n",
        "\n",
        "                        # Chat functionality event handlers\n",
        "                        send_button.click(\n",
        "                            self.process_conversation_input,\n",
        "                            inputs=[user_id, user_input, chat_display, current_conversation_id],\n",
        "                            outputs=[chat_display, user_input, current_conversation_id, conversation_list, conversation_ids]\n",
        "                        )\n",
        "                        gr.Markdown(\"\"\"\n",
        "                        ### About the Chatbot\n",
        "                        This is an AI companion for mental wellbeing. Share your thoughts, feelings, and concerns in a safe, judgment-free space. While this chatbot can provide support and guidance, it's not a replacement for professional mental health care. If you're experiencing a crisis, please contact a mental health professional or crisis hotline.\n",
        "                        \"\"\")\n",
        "\n",
        "            # Connect the buttons to functions\n",
        "            login_tab_btn.click(\n",
        "                self.toggle_login_signup,\n",
        "                inputs=[gr.State(True)],\n",
        "                outputs=[login_form, register_form, login_tab_btn, signup_tab_btn]\n",
        "            )\n",
        "\n",
        "            signup_tab_btn.click(\n",
        "                self.toggle_login_signup,\n",
        "                inputs=[gr.State(False)],\n",
        "                outputs=[login_form, register_form, login_tab_btn, signup_tab_btn]\n",
        "            )\n",
        "# Add this with your other event handlers\n",
        "            emotion_input.change(\n",
        "                self.process_emotion_detection,\n",
        "                inputs=[user_id, emotion_input, chat_display, current_conversation_id],\n",
        "                outputs=[chat_display, current_conversation_id, conversation_list, conversation_ids]\n",
        "            )\n",
        "            # Login functionality\n",
        "            # In build_interface method, update the login button click event\n",
        "            login_button.click(\n",
        "                self.check_login,\n",
        "                inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                login_status,\n",
        "                login_container,\n",
        "                chat_container,\n",
        "                user_id,\n",
        "                conversation_list,\n",
        "                daily_tip_display,\n",
        "                chat_display,              # Add chat display to outputs\n",
        "                current_conversation_id,    # Add current conversation ID\n",
        "                conversation_ids           # Add conversation IDs\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            # Also update the email and password submit events similarly\n",
        "            email_login.submit(\n",
        "                self.check_login,\n",
        "                inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                    login_status,\n",
        "                    login_container,\n",
        "                    chat_container,\n",
        "                    user_id,\n",
        "                    conversation_list,\n",
        "                    daily_tip_display,\n",
        "                    chat_display,\n",
        "                    current_conversation_id,\n",
        "                    conversation_ids\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            password_login.submit(\n",
        "                  self.check_login,\n",
        "                  inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                      login_status,\n",
        "                      login_container,\n",
        "                      chat_container,\n",
        "                      user_id,\n",
        "                      conversation_list,\n",
        "                      daily_tip_display,\n",
        "                      chat_display,\n",
        "                      current_conversation_id,\n",
        "                      conversation_ids\n",
        "                    ]\n",
        "              )\n",
        "\n",
        "            # Registration functionality\n",
        "            def validate_and_register(email, password, confirm_password):\n",
        "                if password != confirm_password:\n",
        "                    return \"Passwords do not match. Please try again.\", gr.update(visible=True), gr.update(visible=False), \"\", gr.update(choices=[]), \"\"\n",
        "                return self.register_new_user(email, password)\n",
        "\n",
        "            register_button.click(\n",
        "                validate_and_register,\n",
        "                inputs=[email_register, password_register, confirm_password],\n",
        "                outputs=[register_status, login_container, chat_container, user_id, conversation_list, daily_tip_display]\n",
        "            )\n",
        "\n",
        "            # Chat functionality\n",
        "            send_button.click(\n",
        "                self.process_conversation_input,\n",
        "                inputs=[user_id, user_input, chat_display, current_conversation_id],\n",
        "                outputs=[chat_display, user_input, current_conversation_id, conversation_list, conversation_ids]\n",
        "            )\n",
        "\n",
        "            user_input.submit(\n",
        "                self.process_conversation_input,\n",
        "                inputs=[user_id, user_input, chat_display, current_conversation_id],\n",
        "                outputs=[chat_display, user_input, current_conversation_id, conversation_list, conversation_ids]\n",
        "            )\n",
        "\n",
        "            load_conversation_button.click(\n",
        "                self.load_conversation,\n",
        "                inputs=[user_id, conversation_list, conversation_ids],\n",
        "                outputs=[chat_display, current_conversation_id]\n",
        "            )\n",
        "            audio_input.change(\n",
        "               self.process_audio_input,\n",
        "               inputs=[user_id, gr.State(\"\"), audio_input, chat_display, current_conversation_id],  # Empty string for user_message\n",
        "               outputs=[chat_display, gr.State(\"\"), current_conversation_id, conversation_list, conversation_ids]\n",
        "             )\n",
        "\n",
        "            new_chat_button.click(\n",
        "                lambda: ([], None),\n",
        "                outputs=[chat_display, current_conversation_id]\n",
        "            )\n",
        "\n",
        "            return interface\n",
        "\n",
        "    def launch(self, **kwargs):\n",
        "        self.interface.launch(**kwargs)\n",
        "\n",
        "# Run the application\n",
        "if __name__ == \"__main__\":\n",
        "    app = WellbeingChatbotApp()\n",
        "    app.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import pipeline\n",
        "import os\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, auth, firestore\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from datetime import datetime\n",
        "import random\n",
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import base64\n",
        "import io\n",
        "def detect_emotion_from_image(image_data):\n",
        "    try:\n",
        "        # Convert the image data to a format DeepFace can process\n",
        "        if isinstance(image_data, str) and image_data.startswith('data:image'):\n",
        "            # Handle base64 encoded image\n",
        "            image_data = image_data.split(',')[1]\n",
        "            image_bytes = base64.b64decode(image_data)\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            image_array = np.array(image)\n",
        "        else:\n",
        "            # Handle numpy array\n",
        "            image_array = image_data\n",
        "\n",
        "        # Detect emotion using DeepFace\n",
        "        result = DeepFace.analyze(\n",
        "            image_array,\n",
        "            actions=['emotion'],\n",
        "            enforce_detection=False\n",
        "        )\n",
        "\n",
        "        # Get the dominant emotion\n",
        "        emotion = result[0]['dominant_emotion']\n",
        "\n",
        "        # Get all emotions with their scores\n",
        "        emotions = result[0]['emotion']\n",
        "\n",
        "        return {\n",
        "            'status': 'success',\n",
        "            'dominant_emotion': emotion,\n",
        "            'emotion_scores': emotions\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'status': 'error',\n",
        "            'message': str(e)\n",
        "        }\n",
        "\n",
        "def generate_emotion_based_response(emotion_data):\n",
        "    \"\"\"\n",
        "    Generate a response based on detected emotion\n",
        "    \"\"\"\n",
        "    if emotion_data['status'] == 'error':\n",
        "        return \"I couldn't detect your emotion clearly. Would you like to tell me how you're feeling?\"\n",
        "\n",
        "    emotion = emotion_data['dominant_emotion']\n",
        "\n",
        "    emotion_responses = {\n",
        "        'happy': [\n",
        "            \"I can see that you're feeling happy! That's wonderful! Would you like to share what's bringing you joy?\",\n",
        "            \"Your happiness is contagious! What's made your day special?\",\n",
        "            \"It's great to see you in such good spirits! How would you like to maintain this positive energy?\"\n",
        "        ],\n",
        "        'sad': [\n",
        "            \"I notice that you might be feeling down. Would you like to talk about what's troubling you?\",\n",
        "            \"It's okay to feel sad sometimes. I'm here to listen if you want to share.\",\n",
        "            \"I can see that you're going through a difficult moment. How can I support you right now?\"\n",
        "        ],\n",
        "        'angry': [\n",
        "            \"I can see that something might be frustrating you. Would you like to talk about what's bothering you?\",\n",
        "            \"It's natural to feel angry sometimes. Would you like to discuss what triggered these feelings?\",\n",
        "            \"I notice you might be feeling upset. How can I help you process these emotions?\"\n",
        "        ],\n",
        "        'fear': [\n",
        "            \"I can sense that you might be feeling anxious or afraid. Would you like to talk about your concerns?\",\n",
        "            \"It's okay to feel scared. We can work through these feelings together.\",\n",
        "            \"I'm here to support you through your fears. What's on your mind?\"\n",
        "        ],\n",
        "        'surprise': [\n",
        "            \"You seem surprised! Would you like to share what's unexpected?\",\n",
        "            \"Something seems to have caught you off guard. Would you like to talk about it?\",\n",
        "            \"I notice your surprise! What's on your mind?\"\n",
        "        ],\n",
        "        'neutral': [\n",
        "            \"How are you feeling right now? I'm here to listen.\",\n",
        "            \"Would you like to share what's on your mind?\",\n",
        "            \"I'm here to support you. What would you like to talk about?\"\n",
        "        ],\n",
        "        'disgust': [\n",
        "            \"I notice you might be feeling uncomfortable. Would you like to talk about what's bothering you?\",\n",
        "            \"Something seems to be troubling you. I'm here to listen if you want to share.\",\n",
        "            \"Would you like to discuss what's making you feel this way?\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return random.choice(emotion_responses.get(emotion, emotion_responses['neutral']))\n",
        "# Predefined wellness tips\n",
        "WELLNESS_TIPS = [\n",
        "    \"Take a few deep breaths when feeling stressed.\",\n",
        "    \"Stay hydrated throughout the day.\",\n",
        "    \"Try to get at least 7-8 hours of sleep each night.\",\n",
        "    \"Take short breaks during work to stretch and move.\",\n",
        "    \"Practice gratitude by noting three things you're thankful for.\",\n",
        "    \"Spend time in nature when possible.\",\n",
        "    \"Limit screen time before bed for better sleep.\",\n",
        "    \"Connect with a friend or family member today.\",\n",
        "    \"Try a 5-minute meditation to clear your mind.\",\n",
        "    \"Move your body for at least 30 minutes today.\"\n",
        "]\n",
        "\n",
        "# Initialize Firebase only once\n",
        "def initialize_firebase():\n",
        "    if not firebase_admin._apps:\n",
        "        try:\n",
        "            cred = credentials.Certificate(\"/content/data/firebase_credentials.json\")  # Update this path!\n",
        "            firebase_admin.initialize_app(cred)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Firebase initialization error: {e}\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Initialize Firestore\n",
        "def get_firestore_db():\n",
        "    if initialize_firebase():\n",
        "        return firestore.client()\n",
        "    return None\n",
        "\n",
        "# Load ASR Model\n",
        "def load_asr_model():\n",
        "    try:\n",
        "        return pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading ASR model: {e}\")\n",
        "        return None\n",
        "\n",
        "# Get random wellness tip\n",
        "def get_daily_tip():\n",
        "    \"\"\"Returns a random wellness tip\"\"\"\n",
        "    return random.choice(WELLNESS_TIPS)\n",
        "\n",
        "# Initialize LLM with mental wellbeing focus\n",
        "def initialize_llm(api_key=None, temperature=0.2):\n",
        "    try:\n",
        "        # Use provided API key or default to environment variable\n",
        "        groq_api_key = api_key or \"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\"\n",
        "        llm = ChatGroq(\n",
        "            temperature=temperature,  # Slightly increased for more natural responses\n",
        "            groq_api_key=groq_api_key,\n",
        "            model_name=\"llama-3.3-70b-versatile\"\n",
        "        )\n",
        "        return llm\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing LLM: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create or load vector database\n",
        "def create_vector_db(db_path=\"/content/chroma_db\"):\n",
        "    try:\n",
        "        if not os.path.exists(db_path):\n",
        "            os.makedirs(db_path)\n",
        "\n",
        "        embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "        return Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating vector database: {e}\")\n",
        "        return None\n",
        "\n",
        "# Set up QA chain with a focus on context-aware and psychiatrist-like responses\n",
        "def setup_qa_chain(vector_db, llm):\n",
        "    \"\"\"Set up the QA retrieval chain with a focus on providing context-aware and psychiatrist-like responses\"\"\"\n",
        "    if vector_db is None or llm is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        retriever = vector_db.as_retriever()\n",
        "        prompt_template = \"\"\"You are a compassionate and knowledgeable mental wellbeing assistant named Serene, akin to a psychiatrist.\n",
        "\n",
        "        Your primary goal is to provide supportive, empathetic, and insightful responses that help the user improve their mental wellbeing.\n",
        "        Always maintain a warm, understanding tone and never judge the user.\n",
        "\n",
        "        Guidelines for your responses:\n",
        "        - Begin with validation of the user's feelings (\"I understand that feeling...\", \"That sounds really challenging...\")\n",
        "        - Use a warm, conversational tone that shows genuine care\n",
        "        - Offer specific, actionable suggestions tailored to their situation, not generic advice\n",
        "        - Ask thoughtful follow-up questions to show you're really listening\n",
        "        - Share relevant coping strategies or techniques that might help their specific situation\n",
        "        - When appropriate, gently normalize their experiences (\"Many people feel this way...\")\n",
        "        - Always respond with empathy first, then helpful information second\n",
        "        - Provide deeper insights and reflective questions to encourage self-awareness and personal growth\n",
        "\n",
        "        For different emotional states:\n",
        "        - When user seems anxious: Use calming language, offer grounding techniques, validate their worries\n",
        "        - When user seems sad: Show compassion, acknowledge the pain, offer gentle encouragement\n",
        "        - When user seems frustrated: Validate their feelings, show patience, offer perspective\n",
        "        - When user seems confused: Provide clarity, break down concepts, be reassuring\n",
        "\n",
        "        If the user appears to be in crisis, gently suggest they reach out to a mental health professional or crisis hotline,\n",
        "        but continue to engage with them supportively.\n",
        "\n",
        "        Relevant context from your knowledge base:\n",
        "        {context}\n",
        "\n",
        "        User: {question}\n",
        "\n",
        "        Serene:\"\"\"\n",
        "\n",
        "        PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "        qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=retriever,\n",
        "            chain_type_kwargs={\"prompt\": PROMPT}\n",
        "        )\n",
        "\n",
        "        return qa_chain\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up QA chain: {e}\")\n",
        "        return None\n",
        "\n",
        "# Generate chatbot response with crisis detection and coping strategies\n",
        "def chatbot_response(db, user_id, user_input, history, vector_db=None, llm=None):\n",
        "    \"\"\" Generate chatbot response and store it in chat history \"\"\"\n",
        "    try:\n",
        "        # Initialize components if not provided\n",
        "        if vector_db is None:\n",
        "            vector_db = create_vector_db()\n",
        "\n",
        "        if llm is None:\n",
        "            llm = initialize_llm()\n",
        "\n",
        "        qa_chain = setup_qa_chain(vector_db, llm)\n",
        "\n",
        "        # Check for crisis keywords\n",
        "        is_crisis = check_for_crisis(user_input)\n",
        "\n",
        "        if is_crisis:\n",
        "            response = \"\"\"I notice you've mentioned something concerning. If you're in crisis, please consider reaching out to a crisis helpline:\n",
        "            - National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "            - Crisis Text Line: Text HOME to 741741 📱\n",
        "\n",
        "            These services are available 24/7 and provide confidential support. Would you like to talk about what you're feeling right now? I'm here to listen. 💬\"\"\"\n",
        "        elif qa_chain is None:\n",
        "            response = \"I'm having trouble connecting to my knowledge base. Let's focus on how you're feeling today. What would help you feel more at ease right now? 🧘\"\n",
        "        else:\n",
        "            # Generate a response using the QA chain\n",
        "            raw_response = qa_chain.run(user_input)\n",
        "\n",
        "            # Enhance with empathy, context-awareness, and coping strategies\n",
        "            response = f\"I understand that you're feeling {user_input}. {raw_response} 🤗\"\n",
        "\n",
        "            # Add specific coping strategies based on emotional state\n",
        "            if \"anxious\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with anxiety:\\n- Practice deep breathing exercises 🧘\\n- Try grounding techniques like focusing on your senses 🌱\\n- Take a short walk to clear your mind 🚶\\n- Write down your thoughts in a journal 📓\"\n",
        "            elif \"sad\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with sadness:\\n- Reach out to a friend or family member 📞\\n- Engage in a hobby or activity you enjoy 🎨\\n- Practice self-compassion and be kind to yourself 💖\\n- Reflect on positive memories or experiences 📝\"\n",
        "            elif \"frustrated\" in user_input.lower():\n",
        "                response += \"\\n\\nHere are some strategies that might help with frustration:\\n- Take a few deep breaths and count to ten 🧘\\n- Step away from the situation and take a break 🌳\\n- Talk it out with someone you trust 🗣️\\n- Focus on solutions rather than problems 🔍\"\n",
        "\n",
        "        # Update history\n",
        "        updated_history = history.copy()\n",
        "        updated_history.append((user_input, response))\n",
        "\n",
        "        # Store in Firebase if available\n",
        "        if db is not None and user_id:\n",
        "            store_chat_history(db, user_id, updated_history)\n",
        "\n",
        "        return user_input, response, updated_history\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return user_input, \"Sorry, I encountered an error while processing your request.\", history\n",
        "\n",
        "# Transcribe audio to text\n",
        "def transcribe_audio(audio_path, asr_model):\n",
        "    if not audio_path or not os.path.exists(audio_path) or asr_model is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        transcription = asr_model(audio_path)[\"text\"]\n",
        "        return transcription\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing audio: {e}\")\n",
        "        return None\n",
        "\n",
        "# Store chat history in Firebase with timestamps\n",
        "def store_chat_history(db, user_id, history):\n",
        "    if db is None or not user_id:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        formatted_history = [{\"message\": msg, \"response\": resp, \"timestamp\": timestamp} for msg, resp in history]\n",
        "        db.collection(\"chat_history\").document(user_id).set({\"history\": formatted_history})\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error storing chat history: {e}\")\n",
        "        return False\n",
        "\n",
        "# Fetch chat history from Firebase\n",
        "def fetch_chat_history(db, user_id):\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            chat_list = chats.to_dict().get(\"history\", [])\n",
        "            return [(chat[\"message\"], chat[\"response\"]) for chat in chat_list]\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching chat history: {e}\")\n",
        "        return []\n",
        "\n",
        "# Get chat sessions by timestamp\n",
        "def get_chat_sessions(db, user_id):\n",
        "    \"\"\" Get list of chat sessions with timestamps \"\"\"\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            chat_list = chats.to_dict().get(\"history\", [])\n",
        "            if chat_list:\n",
        "                # Group by timestamps to create session names\n",
        "                timestamps = set([chat.get(\"timestamp\", \"Unknown\") for chat in chat_list])\n",
        "                return list(timestamps)\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting chat sessions: {e}\")\n",
        "        return []\n",
        "\n",
        "# Check for crisis keywords in user input\n",
        "def check_for_crisis(user_input):\n",
        "    crisis_keywords = [\"suicide\", \"kill myself\", \"end my life\", \"don't want to live\"]\n",
        "    return any(keyword in user_input.lower() for keyword in crisis_keywords)\n",
        "\n",
        "# Generate chatbot response with crisis detection\n",
        "\n",
        "def process_input(db, user_id, user_message, audio_file, history, asr_model, vector_db, llm):\n",
        "    if audio_file:\n",
        "        transcribed_text = transcribe_audio(audio_file, asr_model)\n",
        "        if transcribed_text:\n",
        "            _, _, updated_history = chatbot_response(db, user_id, transcribed_text, history, vector_db, llm)\n",
        "            return updated_history, \"\", None\n",
        "\n",
        "    if user_message:\n",
        "        _, _, updated_history = chatbot_response(db, user_id, user_message, history, vector_db, llm)\n",
        "        return updated_history, \"\", None\n",
        "\n",
        "    return history, \"\", None\n",
        "\n",
        "# Store conversation in Firestore\n",
        "def store_conversation(db, user_id, conversation_id, message, response):\n",
        "    if db is None or not user_id:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        conv_ref = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").document(conversation_id)\n",
        "        conv_doc = conv_ref.get()\n",
        "\n",
        "        if conv_doc.exists:\n",
        "            conv_data = conv_doc.to_dict()\n",
        "            messages = conv_data.get(\"messages\", [])\n",
        "            messages.append({\n",
        "                \"user_message\": message,\n",
        "                \"assistant_response\": response,\n",
        "                \"timestamp\": timestamp\n",
        "            })\n",
        "            conv_ref.update({\n",
        "                \"messages\": messages,\n",
        "                \"last_updated\": timestamp,\n",
        "                \"title\": message[:30] + \"...\" if len(message) > 30 else message\n",
        "            })\n",
        "        else:\n",
        "            conv_ref.set({\n",
        "                \"messages\": [{\n",
        "                    \"user_message\": message,\n",
        "                    \"assistant_response\": response,\n",
        "                    \"timestamp\": timestamp\n",
        "                }],\n",
        "                \"created_at\": timestamp,\n",
        "                \"last_updated\": timestamp,\n",
        "                \"title\": message[:30] + \"...\" if len(message) > 30 else message\n",
        "            })\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error storing conversation: {e}\")\n",
        "        return False\n",
        "\n",
        "# Get all conversations for a user\n",
        "def get_all_conversations(db, user_id):\n",
        "    if db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        conversations = []\n",
        "        conv_refs = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").order_by(\"last_updated\", direction=firestore.Query.DESCENDING)\n",
        "\n",
        "        for conv in conv_refs.stream():\n",
        "            conv_data = conv.to_dict()\n",
        "            conversations.append({\n",
        "                \"id\": conv.id,\n",
        "                \"title\": conv_data.get(\"title\", \"Unnamed conversation\"),\n",
        "                \"last_updated\": conv_data.get(\"last_updated\", \"Unknown date\"),\n",
        "                \"message_count\": len(conv_data.get(\"messages\", []))\n",
        "            })\n",
        "        return conversations\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching conversations: {e}\")\n",
        "        return []\n",
        "\n",
        "# Get a specific conversation by ID\n",
        "def get_conversation_by_id(db, user_id, conversation_id):\n",
        "    if db is None or not user_id or not conversation_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        conv_ref = db.collection(\"conversations\").document(user_id).collection(\"user_conversations\").document(conversation_id)\n",
        "        conv_doc = conv_ref.get()\n",
        "\n",
        "        if conv_doc.exists:\n",
        "            conv_data = conv_doc.to_dict()\n",
        "            messages = conv_data.get(\"messages\", [])\n",
        "            return [(msg[\"user_message\"], msg[\"assistant_response\"]) for msg in messages]\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching conversation: {e}\")\n",
        "        return []\n",
        "\n",
        "# Authenticate user via Firebase\n",
        "def authenticate_user(db, email, password):\n",
        "    try:\n",
        "        user = auth.get_user_by_email(email)\n",
        "        user_id = user.uid\n",
        "\n",
        "        # Fetch chat sessions\n",
        "        chat_sessions = get_chat_sessions(db, user_id)\n",
        "        daily_tip = get_daily_tip()\n",
        "\n",
        "        return True, user_id, \"Login successful!\", chat_sessions, daily_tip\n",
        "    except Exception as e:\n",
        "        print(f\"Authentication error: {e}\")\n",
        "        return False, \"\", f\"Login failed: {str(e)}\", [], \"\"\n",
        "\n",
        "# Register a new user\n",
        "def register_user(db, email, password):\n",
        "    try:\n",
        "        # Check if user already exists\n",
        "        try:\n",
        "            existing_user = auth.get_user_by_email(email)\n",
        "            if existing_user:\n",
        "                return False, \"\", \"Email already in use. Please log in instead.\", [], \"\"\n",
        "        except:\n",
        "            # User doesn't exist, proceed with registration\n",
        "            pass\n",
        "\n",
        "        # Create new user\n",
        "        user = auth.create_user(\n",
        "            email=email,\n",
        "            password=password,\n",
        "            email_verified=False\n",
        "        )\n",
        "\n",
        "        user_id = user.uid\n",
        "\n",
        "        # Initialize user data in Firestore\n",
        "        db.collection(\"user_data\").document(user_id).set({\n",
        "            \"email\": email,\n",
        "            \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        })\n",
        "\n",
        "        daily_tip = get_daily_tip()\n",
        "\n",
        "        return True, user_id, \"Registration successful! Welcome!\", [], daily_tip\n",
        "    except Exception as e:\n",
        "        print(f\"Registration error: {e}\")\n",
        "        return False, \"\", f\"Registration failed: {str(e)}\", [], \"\"\n",
        "\n",
        "# Load custom theme for mental wellbeing UI\n",
        "def load_theme():\n",
        "    \"\"\" Load the custom theme for the mental wellbeing chatbot \"\"\"\n",
        "    return gr.themes.Soft(\n",
        "        primary_hue=\"teal\",\n",
        "        secondary_hue=\"blue\",\n",
        "        neutral_hue=\"slate\",\n",
        "        radius_size=gr.themes.sizes.radius_md,\n",
        "        font=[gr.themes.GoogleFont(\"Nunito\"), gr.themes.GoogleFont(\"Quicksand\"), \"system-ui\", \"sans-serif\"]\n",
        "    )\n",
        "\n",
        "# Load chat by session timestamp\n",
        "def load_chat_by_session(db, user_id, session_timestamp):\n",
        "    if not session_timestamp or db is None or not user_id:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        chats = db.collection(\"chat_history\").document(user_id).get()\n",
        "        if chats.exists:\n",
        "            all_chats = chats.to_dict().get(\"history\", [])\n",
        "            session_chats = [(chat[\"message\"], chat[\"response\"])\n",
        "                            for chat in all_chats\n",
        "                            if chat.get(\"timestamp\") == session_timestamp]\n",
        "            return session_chats\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading chat session: {e}\")\n",
        "        return []\n",
        "def analyze_emotional_content(text):\n",
        "    \"\"\"\n",
        "    Analyzes text for emotional content and returns detected emotions.\n",
        "\n",
        "    Args:\n",
        "        text (str): The user's message text\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing detected emotions and their confidence scores\n",
        "    \"\"\"\n",
        "    # Define emotion keywords for basic detection\n",
        "    emotion_keywords = {\n",
        "        'anxious': ['anxious', 'worried', 'nervous', 'panic', 'fear', 'stress', 'overwhelm', 'scared'],\n",
        "        'sad': ['sad', 'depressed', 'unhappy', 'miserable', 'grief', 'blue', 'down', 'heartbroken', 'upset'],\n",
        "        'angry': ['angry', 'frustrated', 'mad', 'furious', 'irritated', 'annoyed', 'rage', 'hate'],\n",
        "        'happy': ['happy', 'joy', 'excited', 'delighted', 'pleased', 'content', 'grateful', 'thankful'],\n",
        "        'neutral': ['okay', 'fine', 'alright', 'neutral']\n",
        "    }\n",
        "\n",
        "    # Initialize results with default values\n",
        "    results = {\n",
        "        'primary_emotion': 'neutral',\n",
        "        'confidence': 0.0,\n",
        "        'detected_emotions': {},\n",
        "        'intensity': 'low'\n",
        "    }\n",
        "\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Count emotion keywords in text\n",
        "    emotion_counts = {}\n",
        "    max_count = 0\n",
        "    primary_emotion = 'neutral'\n",
        "\n",
        "    for emotion, keywords in emotion_keywords.items():\n",
        "        count = sum(1 for keyword in keywords if keyword in text_lower)\n",
        "        if count > 0:\n",
        "            emotion_counts[emotion] = count\n",
        "            if count > max_count:\n",
        "                max_count = count\n",
        "                primary_emotion = emotion\n",
        "\n",
        "    # If no emotions detected, return neutral\n",
        "    if not emotion_counts:\n",
        "        return results\n",
        "\n",
        "    # Calculate rough confidence based on keyword frequency\n",
        "    total_keywords = sum(emotion_counts.values())\n",
        "\n",
        "    # Set primary emotion and confidence\n",
        "    results['primary_emotion'] = primary_emotion\n",
        "    results['confidence'] = min(0.95, max_count / (len(text.split()) * 0.5)) if total_keywords > 0 else 0.4\n",
        "    results['detected_emotions'] = emotion_counts\n",
        "\n",
        "    # Determine intensity based on modifier words and punctuation\n",
        "    intensity_markers = ['very', 'extremely', 'so', 'really', 'completely', 'absolutely', 'totally']\n",
        "    exclamation_count = text.count('!')\n",
        "    uppercase_ratio = sum(1 for c in text if c.isupper()) / max(len(text), 1)\n",
        "\n",
        "    intensity_score = sum(1 for marker in intensity_markers if marker in text_lower) + exclamation_count\n",
        "    intensity_score += 3 if uppercase_ratio > 0.3 else 0\n",
        "\n",
        "    if intensity_score > 3:\n",
        "        results['intensity'] = 'high'\n",
        "    elif intensity_score > 1:\n",
        "        results['intensity'] = 'medium'\n",
        "    else:\n",
        "        results['intensity'] = 'low'\n",
        "\n",
        "    return results\n",
        "\n",
        "# Function to check for crisis keywords with severity assessment\n",
        "def check_for_crisis_and_severity(text):\n",
        "    \"\"\"\n",
        "    Checks user input for crisis indicators and assesses severity.\n",
        "\n",
        "    Args:\n",
        "        text (str): The user's message text\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains crisis detection results and severity level\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Define crisis keywords with severity levels\n",
        "    high_severity_keywords = [\n",
        "        'kill myself', 'suicide', 'end my life', 'want to die',\n",
        "        'take my life', 'harm myself', 'hurt myself badly'\n",
        "    ]\n",
        "\n",
        "    medium_severity_keywords = [\n",
        "        'don\\'t want to live', 'no reason to live', 'better off dead',\n",
        "        'can\\'t go on', 'giving up', 'no hope', 'no future',\n",
        "        'self harm', 'cutting myself', 'hurting myself'\n",
        "    ]\n",
        "\n",
        "    low_severity_keywords = [\n",
        "        'hopeless', 'worthless', 'nothing matters', 'what\\'s the point',\n",
        "        'exhausted', 'can\\'t handle this', 'too much pain'\n",
        "    ]\n",
        "\n",
        "    # Check for high severity keywords (immediate crisis)\n",
        "    for keyword in high_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'high', 'keyword': keyword}\n",
        "\n",
        "    # Check for medium severity keywords (concerning)\n",
        "    for keyword in medium_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'medium', 'keyword': keyword}\n",
        "\n",
        "    # Check for low severity keywords (distress)\n",
        "    for keyword in low_severity_keywords:\n",
        "        if keyword in text_lower:\n",
        "            return {'detected': True, 'severity': 'low', 'keyword': keyword}\n",
        "\n",
        "    # No crisis keywords detected\n",
        "    return {'detected': False, 'severity': 'none', 'keyword': None}\n",
        "\n",
        "# Function to generate crisis responses based on severity\n",
        "def generate_crisis_response(severity, emotions):\n",
        "    \"\"\"\n",
        "    Generates appropriate responses for different crisis severity levels.\n",
        "\n",
        "    Args:\n",
        "        severity (str): The detected crisis severity level\n",
        "        emotions (dict): The emotional analysis results\n",
        "\n",
        "    Returns:\n",
        "        str: A compassionate response appropriate to the severity level\n",
        "    \"\"\"\n",
        "    if severity == 'high':\n",
        "        return \"\"\"I'm really concerned about what you're sharing. If you're having thoughts of harming yourself, please reach out to a crisis helpline immediately:\n",
        "\n",
        "• National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "• Crisis Text Line: Text HOME to 741741 📱\n",
        "• Or go to your nearest emergency room\n",
        "\n",
        "These services have trained professionals available 24/7 who can help you through this difficult time. Your life matters, and support is available. Would you like to talk more about what you're experiencing right now?\"\"\"\n",
        "\n",
        "    elif severity == 'medium':\n",
        "        return \"\"\"I hear that you're going through a really difficult time, and I'm concerned about what you're sharing. It's important to talk to someone who can provide professional support:\n",
        "\n",
        "• National Suicide Prevention Lifeline: 988 or 1-800-273-8255 📞\n",
        "• Crisis Text Line: Text HOME to 741741 📱\n",
        "\n",
        "Would it be possible for you to reach out to a mental health professional or trusted person in your life today? Your feelings are valid, and support is available. I'm here to listen if you'd like to share more.\"\"\"\n",
        "\n",
        "    elif severity == 'low':\n",
        "        primary_emotion = emotions.get('primary_emotion', 'distress')\n",
        "\n",
        "        responses = {\n",
        "            'anxious': \"I can hear the anxiety in your message, and that sounds really challenging. When everything feels overwhelming, it's important to be gentle with yourself. Would it help to talk about specific things that are causing you to feel this way?\",\n",
        "            'sad': \"I'm sorry you're feeling such sadness right now. It's okay to not be okay sometimes, and your feelings are valid. Would you like to share more about what's contributing to these feelings?\",\n",
        "            'angry': \"I can sense your frustration and anger. These are completely valid emotions, especially when dealing with difficult situations. Would it help to talk more about what's triggering these feelings?\",\n",
        "            'neutral': \"It sounds like you're going through a difficult time. Everyone struggles sometimes, and it's okay to reach out for support. Would talking to a mental health professional be an option for you?\"\n",
        "        }\n",
        "\n",
        "        base_response = responses.get(primary_emotion, responses['neutral'])\n",
        "        return base_response + \"\\n\\nIf you ever feel these thoughts becoming more intense or have thoughts of harming yourself, please reach out to a crisis helpline like the National Suicide Prevention Lifeline at 988.\"\n",
        "\n",
        "    else:\n",
        "        # Default response if severity assessment fails\n",
        "        return \"I notice you may be going through a difficult time. If you're feeling overwhelmed, talking to a mental health professional can really help. Would you like to share more about what you're experiencing?\"\n",
        "\n",
        "# Function to enhance responses with empathy based on emotions\n",
        "def enhance_response_with_empathy(base_response, emotions):\n",
        "    \"\"\"\n",
        "    Enhances LLM responses with appropriate empathetic elements based on detected emotions.\n",
        "\n",
        "    Args:\n",
        "        base_response (str): The original LLM response\n",
        "        emotions (dict): The emotional analysis results\n",
        "\n",
        "    Returns:\n",
        "        str: Enhanced response with appropriate empathetic elements\n",
        "    \"\"\"\n",
        "    primary_emotion = emotions.get('primary_emotion', 'neutral')\n",
        "    intensity = emotions.get('intensity', 'low')\n",
        "\n",
        "    # Add appropriate emoji based on emotion and intensity\n",
        "    emotion_emojis = {\n",
        "        'anxious': ['😟', '😥', '😰'],  # Low, Medium, High\n",
        "        'sad': ['😔', '😢', '😭'],\n",
        "        'angry': ['😒', '😠', '😡'],\n",
        "        'happy': ['🙂', '😊', '😄'],\n",
        "        'neutral': ['🙂', '😊', '💭']\n",
        "    }\n",
        "\n",
        "    intensity_index = {'low': 0, 'medium': 1, 'high': 2}.get(intensity, 0)\n",
        "    emoji = emotion_emojis.get(primary_emotion, emotion_emojis['neutral'])[intensity_index]\n",
        "\n",
        "    # Add empathetic prefix based on emotion\n",
        "    empathy_prefixes = {\n",
        "        'anxious': [\"I understand that anxiety can be overwhelming. \",\n",
        "                   \"It makes sense that you're feeling anxious. \",\n",
        "                   \"That kind of worry is really challenging to navigate. \"],\n",
        "        'sad': [\"I hear the sadness in your message. \",\n",
        "               \"I'm sorry you're feeling down right now. \",\n",
        "               \"It's okay to feel sad sometimes. \"],\n",
        "        'angry': [\"I can sense your frustration. \",\n",
        "                 \"I understand why that would be upsetting. \",\n",
        "                 \"It's natural to feel frustrated in that situation. \"],\n",
        "        'happy': [\"It's wonderful to hear that positivity! \",\n",
        "                 \"I'm glad you're feeling good. \",\n",
        "                 \"That's really great to hear. \"],\n",
        "        'neutral': [ \"\"]\n",
        "    }\n",
        "\n",
        "    import random\n",
        "    prefix = random.choice(empathy_prefixes.get(primary_emotion, empathy_prefixes['neutral']))\n",
        "\n",
        "    # Combine elements\n",
        "    enhanced_response = prefix + base_response\n",
        "\n",
        "    # Add emoji only if it's not already a very long response\n",
        "    if len(enhanced_response) < 500:\n",
        "        enhanced_response += f\" {emoji}\"\n",
        "\n",
        "    return enhanced_response\n",
        "# Main application class\n",
        "class WellbeingChatbotApp:\n",
        "    def __init__(self):\n",
        "        # Initialize components\n",
        "        self.db = get_firestore_db()\n",
        "\n",
        "        # More specific ASR model loading with better error handling\n",
        "        print(\"Loading ASR model...\")\n",
        "        try:\n",
        "            self.asr_model = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
        "            print(\"ASR model loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading ASR model: {str(e)}\")\n",
        "            print(\"Using fallback for ASR (text-only functionality)\")\n",
        "            self.asr_model = None\n",
        "\n",
        "        self.vector_db = create_vector_db()\n",
        "        self.llm = initialize_llm(temperature=0.2)\n",
        "        self.theme = load_theme()\n",
        "        self.current_user = \"Guest\"\n",
        "        self.current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        # Define UI\n",
        "        self.interface = self.build_interface()\n",
        "\n",
        "    # Add this new method to process audio inputs specifically\n",
        "    def process_audio_input(self, user_id, user_message, audio_file, history, conversation_id):\n",
        "        \"\"\"Handle audio input specifically\"\"\"\n",
        "        try:\n",
        "            if audio_file is None:\n",
        "                return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "            # Transcribe audio to text\n",
        "            transcribed_text = transcribe_audio(audio_file, self.asr_model)\n",
        "\n",
        "            if not transcribed_text or not transcribed_text.strip():\n",
        "                # Failed transcription\n",
        "                new_history = history.copy()\n",
        "                new_history.append((\"\", \"I couldn't understand the audio. Could you please try speaking again or type your message?\"))\n",
        "                return new_history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "            # Process the transcribed text - first show what was transcribed\n",
        "            new_history = history.copy()\n",
        "            new_history.append((f\"[Audio] {transcribed_text}\", \"\"))\n",
        "\n",
        "            # Now process it like a normal message\n",
        "            final_history, _, final_conv_id, conv_list, conv_ids = self.process_conversation_input(\n",
        "                user_id, transcribed_text, new_history, conversation_id\n",
        "            )\n",
        "\n",
        "            return final_history, \"\", final_conv_id, conv_list, conv_ids\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing audio input: {str(e)}\")\n",
        "            new_history = history.copy()\n",
        "            new_history.append((\"\", f\"I encountered an error processing your audio. Could you please try again?\"))\n",
        "            return new_history, \"\", conversation_id, gr.update(), []\n",
        "    def check_login(self, email, password):\n",
        "        success, user_id, message, chat_sessions, daily_tip = authenticate_user(self.db, email, password)\n",
        "\n",
        "        if success:\n",
        "            try:\n",
        "            # Fetch all conversations for the user\n",
        "                conversations = get_all_conversations(self.db, user_id)\n",
        "                conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "                conv_ids = [c[\"id\"] for c in conversations]\n",
        "\n",
        "            # If there are conversations, load the most recent one\n",
        "                initial_history = []\n",
        "                initial_conv_id = None\n",
        "\n",
        "                return (\n",
        "                    message,                              # Login status message\n",
        "                    gr.update(visible=False),             # Hide login container\n",
        "                    gr.update(visible=True),              # Show chat container\n",
        "                    user_id,                              # User ID\n",
        "                    gr.update(choices=conv_choices,       # Update conversation list\n",
        "                            value=None),\n",
        "                    daily_tip,                            # Daily tip\n",
        "                    initial_history,                      # Initial chat history\n",
        "                    initial_conv_id,                      # Initial conversation ID\n",
        "                    conv_ids                              # List of conversation IDs\n",
        "              )\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading initial conversations: {e}\")\n",
        "                return (\n",
        "                    f\"Login successful but error loading conversations: {str(e)}\",\n",
        "                    gr.update(visible=True),\n",
        "                    gr.update(visible=False),\n",
        "                    \"\",\n",
        "                    gr.update(choices=[]),\n",
        "                    \"\",\n",
        "                    [],\n",
        "                    None,\n",
        "                    []\n",
        "                )\n",
        "        else:\n",
        "            return (\n",
        "                message,\n",
        "                gr.update(visible=True),\n",
        "                gr.update(visible=False),\n",
        "                \"\",\n",
        "                gr.update(choices=[]),\n",
        "                \"\",\n",
        "                [],\n",
        "                None,\n",
        "                []\n",
        "            )\n",
        "    def process_emotion_detection(self, user_id, image, history, conversation_id):\n",
        "        try:\n",
        "            if image is None:\n",
        "                 return history, conversation_id, gr.update(), [], gr.update()  # Added gr.update() for Image reset\n",
        "        # Detect emotion from the image\n",
        "            emotion_data = detect_emotion_from_image(image)\n",
        "\n",
        "        # Generate response based on detected emotion\n",
        "            response = generate_emotion_based_response(emotion_data)\n",
        "\n",
        "        # Update history with emotion detection result\n",
        "            new_history = history.copy()\n",
        "            emotion_message = f\"[Emotion Detection] Detected emotion: {emotion_data['dominant_emotion']}\"\n",
        "            new_history.append((emotion_message, response))\n",
        "\n",
        "        # Store conversation\n",
        "            if conversation_id is None:\n",
        "                conversation_id = f\"conv_{datetime.now().strftime('%Y%m%d%H%M%S')}_{random.randint(1000, 9999)}\"\n",
        "\n",
        "            store_conversation(self.db, user_id, conversation_id, emotion_message, response)\n",
        "\n",
        "        # Update conversation list\n",
        "            conversations = get_all_conversations(self.db, user_id)\n",
        "            conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "            conv_ids = [c[\"id\"] for c in conversations]\n",
        "\n",
        "            return new_history, conversation_id, gr.update(choices=conv_choices), conv_ids, gr.update(value=None)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing emotion detection: {e}\")\n",
        "            return history, conversation_id, gr.update(), [], gr.update(value=None)  # Reset image even on error\n",
        "    def register_new_user(self, email, password):\n",
        "        success, user_id, message, chat_sessions, daily_tip = register_user(self.db, email, password)\n",
        "\n",
        "        if success:\n",
        "            return message, gr.update(visible=False), gr.update(visible=True), user_id, gr.update(choices=chat_sessions, value=None), daily_tip\n",
        "        else:\n",
        "            return message, gr.update(visible=True), gr.update(visible=False), \"\", gr.update(choices=[]), \"\"\n",
        "\n",
        "    def process_user_input(self, user_id, user_message, audio_file, history):\n",
        "        return process_input(\n",
        "            self.db, user_id, user_message, audio_file, history,\n",
        "            self.asr_model, self.vector_db, self.llm\n",
        "        )\n",
        "\n",
        "    def new_chat(self):\n",
        "        return []\n",
        "\n",
        "    def load_session(self, user_id, session_timestamp):\n",
        "        return load_chat_by_session(self.db, user_id, session_timestamp)\n",
        "\n",
        "    def toggle_login_signup(self, is_login):\n",
        "        if is_login:\n",
        "            return gr.update(visible=True), gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)\n",
        "        else:\n",
        "            return gr.update(visible=False), gr.update(visible=True), gr.update(visible=False), gr.update(visible=True)\n",
        "\n",
        "    def load_conversation(self, user_id, selected_conversation, conversation_ids):\n",
        "        if not all([user_id, selected_conversation, conversation_ids]):\n",
        "            return [], None\n",
        "\n",
        "        try:\n",
        "            conversations = get_all_conversations(self.db, user_id)\n",
        "            conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "\n",
        "            if selected_conversation not in conv_choices:\n",
        "                return [], None\n",
        "\n",
        "            selected_idx = conv_choices.index(selected_conversation)\n",
        "\n",
        "            if selected_idx >= 0 and selected_idx < len(conversation_ids):\n",
        "                conversation_id = conversation_ids[selected_idx]\n",
        "                history = get_conversation_by_id(self.db, user_id, conversation_id)\n",
        "                return history, conversation_id\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading conversation: {e}\")\n",
        "        return [], None\n",
        "\n",
        "    def process_conversation_input(self, user_id, message, history, conversation_id):\n",
        "     try:\n",
        "        if not message:\n",
        "            return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "        # Get response using the LLM\n",
        "        llm = initialize_llm()\n",
        "        if llm:\n",
        "            # Analyze emotional content\n",
        "            emotions = analyze_emotional_content(message)\n",
        "\n",
        "            # Check for crisis keywords with more nuanced detection\n",
        "            crisis_check = check_for_crisis_and_severity(message)\n",
        "\n",
        "            if crisis_check['detected']:\n",
        "                response = generate_crisis_response(crisis_check['severity'], emotions)\n",
        "            else:\n",
        "                # Format the conversation history for context\n",
        "                conversation_context = \"\"\n",
        "                if history:\n",
        "                    for i, (user_msg, assistant_msg) in enumerate(history[-3:]):  # Include last 3 exchanges for context\n",
        "                        conversation_context += f\"User: {user_msg}\\nAssistant: {assistant_msg}\\n\\n\"\n",
        "\n",
        "                # Create prompt with conversation history and instructions for brevity\n",
        "                prompt = f\"\"\"You are Serene, a deeply empathetic mental wellbeing assistant with expertise in emotional support.\n",
        "\n",
        "                Previous conversation:\n",
        "                {conversation_context}\n",
        "\n",
        "                Current message: {message}\n",
        "\n",
        "                Remember to respond with warmth, empathy, and emotional intelligence, but keep your response brief and concise (2-3 sentences maximum). Focus on the most important aspects of the user's message.\n",
        "                \"\"\"\n",
        "\n",
        "                # Generate response using LLM with lower max_tokens\n",
        "                # Set temperature lower for more focused responses\n",
        "                llm_brief = initialize_llm(temperature=0.5)  # Lower temperature for more focused responses\n",
        "                base_response = llm_brief.invoke(prompt).content\n",
        "\n",
        "                # If response is still too long, truncate it\n",
        "                sentences = base_response.split('. ')\n",
        "                if len(sentences) > 3:\n",
        "                    base_response = '. '.join(sentences[:3]) + '.'\n",
        "\n",
        "                response = enhance_response_with_empathy(base_response, emotions)\n",
        "        else:\n",
        "            response = \"I'm here to listen and support you. What's on your mind today?\"\n",
        "\n",
        "        # Update history\n",
        "        new_history = history.copy()\n",
        "        new_history.append((message, response))\n",
        "\n",
        "        # Store conversation\n",
        "        if conversation_id is None:\n",
        "            conversation_id = f\"conv_{datetime.now().strftime('%Y%m%d%H%M%S')}_{random.randint(1000, 9999)}\"\n",
        "\n",
        "        store_conversation(self.db, user_id, conversation_id, message, response)\n",
        "\n",
        "        # Update conversation list\n",
        "        conversations = get_all_conversations(self.db, user_id)\n",
        "        conv_choices = [f\"{c['title']} ({c['last_updated']})\" for c in conversations]\n",
        "        conv_ids = [c[\"id\"] for c in conversations]\n",
        "\n",
        "        return new_history, \"\", conversation_id, gr.update(choices=conv_choices), conv_ids\n",
        "\n",
        "     except Exception as e:\n",
        "        print(f\"Error processing input: {e}\")\n",
        "        return history, \"\", conversation_id, gr.update(), []\n",
        "\n",
        "    def build_interface(self):\n",
        "        with gr.Blocks(theme=self.theme, css=\"\"\"\n",
        "            .gradio-container {max-width: 1200px !important}\n",
        "            .header-text {text-align: center; font-weight: 600 !important}\n",
        "            .chat-history {border-left: 1px solid rgba(0,0,0,0.1)}\n",
        "            .welcome-box {background-color: rgba(89, 193, 189, 0.1); padding: 20px; border-radius: 12px; margin-bottom: 20px}\n",
        "            .tip-box {background-color: linear-gradient(135deg, #43c6ac, #59C1BD);; border-left: 4px solid teal; padding: 12px; margin: 12px 0; border-radius: 4px}\n",
        "            .tab-buttons {text-align: center; margin-bottom: 20px;}\n",
        "            .tab-button {margin: 0 10px; padding: 8px 16px; border-radius: 20px; background-color: #f0f0f0; border: none; cursor: pointer;}\n",
        "            .tab-button.active {background-color: #59C1BD; color: white;}\n",
        "        \"\"\") as interface:\n",
        "            # State variables\n",
        "            user_id = gr.State(\"\")\n",
        "            current_conversation_id = gr.State(None)\n",
        "            conversation_ids = gr.State([])\n",
        "\n",
        "            # Login container\n",
        "            login_container = gr.Column(visible=True)\n",
        "            chat_container = gr.Column(visible=False)\n",
        "\n",
        "            with login_container:\n",
        "                gr.Markdown(\"# Mental Wellbeing Chatbot\", elem_classes=[\"header-text\"])\n",
        "\n",
        "                # Tab buttons for login/signup\n",
        "                with gr.Row(elem_classes=[\"tab-buttons\"]):\n",
        "                    login_tab_btn = gr.Button(\"Login\", elem_classes=[\"tab-button\", \"active\"])\n",
        "                    signup_tab_btn = gr.Button(\"Sign Up\", elem_classes=[\"tab-button\"])\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        # Login Form\n",
        "                        login_form = gr.Group(visible=True)\n",
        "                        with login_form:\n",
        "                            gr.Markdown(\"### Sign in to your account\")\n",
        "                            email_login = gr.Textbox(label=\"Email\", interactive=True, placeholder=\"Your email\")\n",
        "                            password_login = gr.Textbox(label=\"Password\", type=\"password\", interactive=True, placeholder=\"Your password\")\n",
        "                            login_button = gr.Button(\"Sign In\", variant=\"primary\", size=\"lg\")\n",
        "                            login_status = gr.Textbox(label=\"Status\", interactive=False, visible=False)\n",
        "\n",
        "                        # Register Form\n",
        "                        register_form = gr.Group(visible=False)\n",
        "                        with register_form:\n",
        "                            gr.Markdown(\"### Create a new account\")\n",
        "                            email_register = gr.Textbox(label=\"Email\", interactive=True, placeholder=\"Your email\")\n",
        "                            password_register = gr.Textbox(label=\"Password\", type=\"password\", interactive=True, placeholder=\"Create a password\")\n",
        "                            confirm_password = gr.Textbox(label=\"Confirm Password\", type=\"password\", interactive=True, placeholder=\"Confirm your password\")\n",
        "                            register_button = gr.Button(\"Create Account\", variant=\"primary\", size=\"lg\")\n",
        "                            register_status = gr.Textbox(label=\"Status\", interactive=False, visible=False)\n",
        "\n",
        "            with chat_container:\n",
        "                gr.Markdown(\"# Mental Wellbeing Chatbot\", elem_classes=[\"header-text\"])\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        with gr.Group(elem_classes=[\"welcome-box\"]):\n",
        "                            gr.Markdown(\"### Welcome back!\")\n",
        "                            daily_tip_display = gr.Markdown(elem_classes=[\"tip-box\"])\n",
        "\n",
        "                        gr.Markdown(\"### Quick Resources\")\n",
        "                        resource_links = gr.Markdown(\"\"\"\n",
        "                        - [Guided Meditation](https://www.mindful.org/meditation/mindfulness-getting-started/)\n",
        "                        - [Deep Breathing Exercises](https://tools.wearewithyou.org.uk/deepbreathing/)\n",
        "                        - [Positive Affirmations](https://www.priorygroup.com/self-care/positive-affirmations-for-mental-health)\n",
        "                        - [Crisis Support Resources](https://www.crisistextline.org/)\n",
        "                        \"\"\")\n",
        "\n",
        "                        gr.Markdown(\"### Start a New Chat or View Past Conversations\")\n",
        "                        conversation_list = gr.Radio(choices=[], label=\"Select a previous conversation or start typing below to begin a new chat\",\n",
        "                                                                        value=None)\n",
        "                        load_conversation_button = gr.Button(\"Load Selected Conversation\", variant=\"secondary\")\n",
        "                        new_chat_button = gr.Button(\"+ Start New Conversation\", variant=\"secondary\")\n",
        "\n",
        "                    with gr.Column(scale=3, elem_classes=[\"chat-history\"]):\n",
        "                        chat_display = gr.Chatbot(\n",
        "                            label=\"Your conversation\",\n",
        "                            height=500,\n",
        "                            avatar_images=[\n",
        "                                \"https://img.icons8.com/ios-filled/50/000000/user-male-circle.png\",\n",
        "                                \"https://img.icons8.com/ios-filled/50/59C1BD/teal-meditation.png\"\n",
        "                            ]\n",
        "                        )\n",
        "\n",
        "                        with gr.Row():\n",
        "                           user_input = gr.Textbox(\n",
        "                           label=\"Type your message...\",\n",
        "                           placeholder=\"Share how you're feeling or ask for support...\",\n",
        "                           lines=2,\n",
        "                           scale=4\n",
        "            )\n",
        "                           audio_input = gr.Audio(\n",
        "                           label=\"🎤 Speak\",\n",
        "                           source=\"microphone\",\n",
        "                           type=\"filepath\",\n",
        "                           streaming=False,  # Set to False for better browser compatibility\n",
        "                           format=\"wav\",     # Specify format for better compatibility\n",
        "                           scale=1\n",
        "            )\n",
        "                           emotion_input = gr.Image(\n",
        "                           label=\"📷 Detect Emotion\",\n",
        "                           source=\"webcam\",\n",
        "                           streaming=False,\n",
        "                           type=\"numpy\"\n",
        "           )\n",
        "\n",
        "\n",
        "                        send_button = gr.Button(\"Send Message\", variant=\"primary\")\n",
        "\n",
        "                        gr.Markdown(\"\"\"\n",
        "                        ### About the Chatbot\n",
        "                        This is an AI companion for mental wellbeing. Share your thoughts, feelings, and concerns in a safe, judgment-free space. While this chatbot can provide support and guidance, it's not a replacement for professional mental health care. If you're experiencing a crisis, please contact a mental health professional or crisis hotline.\n",
        "                        \"\"\")\n",
        "\n",
        "            # Connect the buttons to functions\n",
        "            login_tab_btn.click(\n",
        "                self.toggle_login_signup,\n",
        "                inputs=[gr.State(True)],\n",
        "                outputs=[login_form, register_form, login_tab_btn, signup_tab_btn]\n",
        "            )\n",
        "\n",
        "            signup_tab_btn.click(\n",
        "                self.toggle_login_signup,\n",
        "                inputs=[gr.State(False)],\n",
        "                outputs=[login_form, register_form, login_tab_btn, signup_tab_btn]\n",
        "            )\n",
        "# Add this with your other event handlers\n",
        "            emotion_input.change(\n",
        "                  self.process_emotion_detection,\n",
        "                  inputs=[user_id, emotion_input, chat_display, current_conversation_id],\n",
        "                outputs=[\n",
        "                    chat_display,\n",
        "                    current_conversation_id,\n",
        "                    conversation_list,\n",
        "                    conversation_ids,\n",
        "                    emotion_input  # Add emotion_input to outputs for reset\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            # Login functionality\n",
        "            # In build_interface method, update the login button click event\n",
        "            login_button.click(\n",
        "                self.check_login,\n",
        "                inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                login_status,\n",
        "                login_container,\n",
        "                chat_container,\n",
        "                user_id,\n",
        "                conversation_list,\n",
        "                daily_tip_display,\n",
        "                chat_display,              # Add chat display to outputs\n",
        "                current_conversation_id,    # Add current conversation ID\n",
        "                conversation_ids           # Add conversation IDs\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            # Also update the email and password submit events similarly\n",
        "            email_login.submit(\n",
        "                self.check_login,\n",
        "                inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                    login_status,\n",
        "                    login_container,\n",
        "                    chat_container,\n",
        "                    user_id,\n",
        "                    conversation_list,\n",
        "                    daily_tip_display,\n",
        "                    chat_display,\n",
        "                    current_conversation_id,\n",
        "                    conversation_ids\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            password_login.submit(\n",
        "                  self.check_login,\n",
        "                  inputs=[email_login, password_login],\n",
        "                outputs=[\n",
        "                      login_status,\n",
        "                      login_container,\n",
        "                      chat_container,\n",
        "                      user_id,\n",
        "                      conversation_list,\n",
        "                      daily_tip_display,\n",
        "                      chat_display,\n",
        "                      current_conversation_id,\n",
        "                      conversation_ids\n",
        "                    ]\n",
        "              )\n",
        "\n",
        "            # Registration functionality\n",
        "            def validate_and_register(email, password, confirm_password):\n",
        "                if password != confirm_password:\n",
        "                    return \"Passwords do not match. Please try again.\", gr.update(visible=True), gr.update(visible=False), \"\", gr.update(choices=[]), \"\"\n",
        "                return self.register_new_user(email, password)\n",
        "\n",
        "            register_button.click(\n",
        "                validate_and_register,\n",
        "                inputs=[email_register, password_register, confirm_password],\n",
        "                outputs=[register_status, login_container, chat_container, user_id, conversation_list, daily_tip_display]\n",
        "            )\n",
        "\n",
        "            # Chat functionality\n",
        "            send_button.click(\n",
        "                self.process_conversation_input,\n",
        "                inputs=[user_id, user_input, chat_display, current_conversation_id],\n",
        "                outputs=[chat_display, user_input, current_conversation_id, conversation_list, conversation_ids]\n",
        "            )\n",
        "\n",
        "            user_input.submit(\n",
        "                self.process_conversation_input,\n",
        "                inputs=[user_id, user_input, chat_display, current_conversation_id],\n",
        "                outputs=[chat_display, user_input, current_conversation_id, conversation_list, conversation_ids]\n",
        "            )\n",
        "\n",
        "            load_conversation_button.click(\n",
        "                self.load_conversation,\n",
        "                inputs=[user_id, conversation_list, conversation_ids],\n",
        "                outputs=[chat_display, current_conversation_id]\n",
        "            )\n",
        "            audio_input.change(\n",
        "               self.process_audio_input,\n",
        "               inputs=[user_id, gr.State(\"\"), audio_input, chat_display, current_conversation_id],  # Empty string for user_message\n",
        "               outputs=[chat_display, gr.State(\"\"), current_conversation_id, conversation_list, conversation_ids]\n",
        "             )\n",
        "\n",
        "            new_chat_button.click(\n",
        "                lambda: ([], None),\n",
        "                outputs=[chat_display, current_conversation_id]\n",
        "            )\n",
        "\n",
        "            return interface\n",
        "\n",
        "    def launch(self, **kwargs):\n",
        "        self.interface.launch(**kwargs)\n",
        "\n",
        "# Run the application\n",
        "if __name__ == \"__main__\":\n",
        "    app = WellbeingChatbotApp()\n",
        "    app.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "370cc7a1b6374d3a9387e15b121d16a3",
            "2aa3559b869f422a951a520249b5677d",
            "5af238e961684261bc1babfd693952d1",
            "b249dc843c0543aea9b25b11872facb8",
            "137588a8c8224bc995b43cbd769dfd57",
            "82b0fb004c164213a77ea3e5bc7e3fd8",
            "3ccf6f3669bd4fce846a032e61c32d2f",
            "ee6916ec91e14581afa98c045ea79164",
            "aceb5d76c7db4a1887297089b956a461",
            "6499123fd3674f869d450cb5be6505d5",
            "b8b3947043e344fdbb464b699704d9f8",
            "5b360d66571b46cd90fa5ee488531452",
            "ab5372a32d5b49c2a2f2fb2f13751900",
            "6b958901eec0490295022ff481204cd6",
            "d92897c9e50b4ad48460f56456c9d985",
            "905993ae0d6c436a804098439c0138b3",
            "9bf07f841d0e4017b58f190f91e09da5",
            "23fc4d16abd24e5e8c6480dca267fb2b",
            "1ba228a367ba48cab274c2c308d9623a",
            "50c00b4e1e354a4881fd41374d00429d",
            "5d6ee5f6a7024699942b93597ef1e58c",
            "b8a4ae0a96754ef88ce31a72babff96d",
            "071bbf9b9cb24446a72202e4c0e1e51b",
            "95aec29eb78344c58729eb0a942b5eea",
            "857ce1c7db454f748ff5629b75a26bfe",
            "1c98f72d983f4c7184b0eb8fa5219f97",
            "77772639f072474e878940bcaf32ffd3",
            "0319c60aced1450c8d7811c617c87e0f",
            "926eb3c71e4d4b67bc13239e88246566",
            "d7f2cc379fc248babc7f02460b7937e5",
            "1c6a5717c7424eda9c0011da7bcb4c40",
            "dfcf9bb3e3dc4a6ab7f6be7caa70c3d6",
            "92c3368458ba45bd9b4c58f77aefaba2",
            "b81b13e49f9343ceb192ed7de222a8d1",
            "3a0b75e81fb945e29454542b0a3f7ad2",
            "bde8d669e8864fb2a171e7815c8b159c",
            "3c11e51ca8d149209becd3ea62d207cd",
            "2f90c9e1e8ef41fda5c2f7c517df6672",
            "c9fa5b155381457d948022170fae02b0",
            "ab8144edbf3049b1ba043b2569a1e164",
            "69d836347ead477eb5f1a680cdc06731",
            "8d5e5dc8c92146d4bace3773f93f6e4b",
            "cf9bfd3e5b4745f9bc01f1576dea7484",
            "30582e7e64d34a23ae7a397c9ffb5342",
            "90ecb08a826145208bdf6fe498159e3f",
            "b1a2c0f070e641db9d4e7a8d09927e53",
            "03ea1621ce51407fabdacd68ed8b0ba4",
            "46b8b624fed74c188dccb7906aea5d13",
            "e7e238cd7f2944c9ad8dc405edc89b04",
            "7370eb06386247918474cc092c4f1f05",
            "5361c03f76f249799573d9f71db29f7f",
            "3aeca07fa761417fafb635a8a8859804",
            "0c1440b5e5f84e16b3b3c3ca52a6c138",
            "4d98ac8621b74f348ee5cb5bfb44824e",
            "16977cefb1144367823a4c3df7ecaf89",
            "884a0cbb0e0242199abdb04975dae6b0",
            "98a9bca1201e422fbd00c072c8a4e848",
            "6ce3d09bf9924e1e8bec0ad4eb355b80",
            "28adb847f5e247be9df00708b5663499",
            "be293cba84744b1ba58b6840ad60f738",
            "78ba7ddd97384639b17d47f2a7d60846",
            "3081d2d0dde54c3ea6e09f336133749e",
            "37567432cc6548ca8c8c7cb86e33a9d7",
            "2544e5259a0243e9bee1c3a85508c123",
            "8bb093f6846b40fab3cb1e78973bfba0",
            "5d720b2f1f8a46e187ede24b23310082",
            "b3d684c979c844378be706e3ca870a97",
            "80db1c21b9ea498d90cef92cb136cde5",
            "a908bbff04b84fb489e9638fb239043b",
            "37970f550d304f1fa4ce6ec002276f4f",
            "d3bc907a4da34965b614b5ad4cad93b9",
            "3f60f38d3b2548d3a795f37d9e1df515",
            "b1477ac7350b4860976f4c04eec33fbb",
            "1c7025123998471c9d4a34771d57ac8f",
            "c60cf7cad6214d03950913dd8a19185a",
            "aa58070574104e769c957af366e208d8",
            "11d316e05d8f4e2cb1d3689f3c014e6b",
            "36fbe54bc9c44887a1293c06fbbb940b",
            "7e014af11a1348e38ef1dd703d0d91a1",
            "c25af8020d5e4463b285e33653045bd6",
            "798c0c339eae417fba894939a05e783a",
            "39c3a165ab314b389f380ed627ceb622",
            "aac48fb2821e42b390de276cf6e98715",
            "7fdcce0811914de782983b0efdae1e6e",
            "89813208ed8548fb9824ec39b4877d11",
            "eacaca0d6a354d32b2b616cfb132d107",
            "453c605778554d99af1ce640ae747271",
            "b998191a82dd4827a684d40cfef23b83",
            "ad5814cca82846da8e3f1aaac71a026a",
            "9c709a8de2a94e9dbb2cbb6a506af8be",
            "4fd8cc00ccc649ec88ce66d2da5ffc8e",
            "88e84df38fc245828457fb898b58f528",
            "7faf920f90254c9fa14fc0c55ed0ff52",
            "4096378b8dff42d2b1f674fe1256c9e4",
            "649a3ee122034fb39ceadf96c1f64c91",
            "5d2bc09141e540fd949d928ee2c83e1c",
            "bc67461b0435479ca2bf018f6f01f37b",
            "1dba659b9dc7478cb926e671aa511f84",
            "6045bf4bc1d6442b9fe1bb6c71c4d27e",
            "512fa581b87a4036b5cb55709bfe155e",
            "711453d118144313b19f92f632510441",
            "2d8fa7ff10a8483ba9c9997769a755ef",
            "2e86532f96ce47bb9792c744b1875def",
            "4eaba67ff4064650921a6a58f50ddf75",
            "1f5ad7c76edf48279725de015ee14f74",
            "5911ec9bf4d341ec8961776a079df4b3",
            "01023f6c24c54fde85659d13a6ddbc50",
            "64075d77c272452ca5c0aa7bcf6afa13",
            "3a42179c01374db587e5cf5e0fba41eb",
            "d8cffcba7e424149b672dfa17d74f24f",
            "53ac8a73f42942388470f28cb21d4af7",
            "8c57181159da44409999aae105cfec1f",
            "0d12c8e068c54112b4586cf602370573",
            "14ee3c8bf09a4c43bcc8503310949063",
            "170948a3296f43d4882de456e4920890",
            "19b8b42dc1a5434587e417f1bb9fb9e0",
            "106fd877a0d849ac95f81efbbc0aa170",
            "73aeef42e9e24a2a885c06bfd8f242f4",
            "facf4a23824949e7836bb04ae7500c76",
            "4fe2d00ac0da49468d43eb0f797ae6ea",
            "14418fa02ad5451698e5694ca57cefdb",
            "52c9110f3cc74e7a8cfa3aa9e3e20f52",
            "5b450c136f654665afc7a94823cf0b3c",
            "f50c640d47d14a84802748ae40d63a17",
            "e8071ed6ed8f4b11b1d7688aa3a0ce7c",
            "ff4329d1322b4a429bbca2b9da70f021",
            "1b4be3ca5cd648e392eba8b13f9a363c",
            "b4f57957004c498ca0446641698e6e8d",
            "3ad5fc5ec9684782b6133962adde07db",
            "5dd698af020743aba5c9f5ef9a78e327",
            "20cb458610314b4d8dfc4c38f609624a",
            "ab7812ae0fe241caa8ee57aee6737450",
            "a5953442be4748ceac3b59f8ef1d23c5",
            "c5ad91de34a04d60aa3a2f5f057b8d48",
            "04442f15331c41f48c2bf5942d92b13e",
            "195644d78ff34a089413632636b363a0",
            "ca3542cc2f2f4fa49e9dcb5703431065",
            "67c9233b7e0b4a1cb2e4493faeb902cd",
            "e47964a54bf84e5c9f336dc5b30adae0",
            "c50e15aeb8914e6b81487066f098824d",
            "3b56694bab5049b8934175b48ff3edac",
            "d3ba80e2c6ea45378dbbf493432c179f",
            "4b2fa30750554af987b6961bb239e87f",
            "5e81158a93f847ceb439a76c7c5e65f5",
            "acf5051e6e854ef790c8ca573c56abc3",
            "764f09f70511431b9cfe629406a71532",
            "38ea2f3e83ef496fa1636c00497a03c7",
            "56ec5da979494895ba69ef8a795a17c7",
            "a680ddaee77949ed9d4f2eed02a3e663",
            "17a29b8a33dc49bb97c5d97e55c47a7d",
            "3bb95c56456f4444b9523b6197cfcde1",
            "57905346640c4efba10b182716ad7db1",
            "72285e7ec4d64c9295912cedd9316c3f",
            "18c696d3bb02431993cb762ed0db36e8",
            "37ac812fb9bd4d3495bd92c7fdb93aef",
            "f7ff7c2c32fc45e0933e164e4c407df9",
            "bdaaa83611954d2895cb808c55b58a81",
            "80f51ba165e14970acefceae0dd041bb",
            "91a76ba5742b423cb6fbe21272e68f4a",
            "956ed9c47a664397ab2ccebf2490afce",
            "48c3f62b19884e4f9a984a70ee0f7fb4",
            "28871d2f2d5a44b38d9083b6d89858d5",
            "b7a2b5ce26604ec1919e4840ecf2c814",
            "f22528f56909462bb58400a6cbbfac24",
            "47de78eefb334071823ac3fa71137a95",
            "d04a5f20ac7d4695b9d8d1e2e73b4774",
            "2be75e9097244534abe10d2795845e59",
            "f509c775e2c94fa49ff6aa779cfb9112",
            "20cfe73a1891425f820ca8fb031ce853",
            "ae57e6b3602940f9ba319a6aadecb1ce",
            "9630b5cd99e84b13ad48d60d4ad3a82b",
            "dd4dead8258f42a6b6334e10e07f56a5",
            "ef9ded3d27d04c5e85118e58d3268708",
            "90f89d66357c4a178222d9300490c30b",
            "9be16436fbd541b2b8a5a42a8ec1d73e",
            "a7dcef8c2c354584bd619d709abd0f4d",
            "b8f699bc52d242e28449b7d37cc5881f",
            "57d6aacc13594e86985792fd924d603d",
            "40e575f8b910422ea8ddea0fbf049a2a",
            "e6031fc257864d2ba154e61c8c461acc",
            "53cfa7559aa74ddd80e13edafa6d3eb0",
            "c48675ea348543e4902220065b0ee7cc",
            "e5b18c973e9c4ff2ab8a02485a770068",
            "71fb1652cac9424992677e464d03d193",
            "4dc4dc8be538452c9e760c29ad618a81",
            "06fa76c3ada848319edf1d34e86fe83f",
            "3882adcfb842499380b359e197b3747f",
            "622ea547eef64b7ba3897d904c6f4e9d",
            "d508d579dca3499ea22dc852e0cb5c2d",
            "265ef17cb5b643ee9a60cf4f61b74c42",
            "4d4b90e09eb847699ca806587da813c2",
            "7efd31911de544c2ad3bbb5db2872b23",
            "ffe8fd14045f4c03848e3974b25fe7ba",
            "12e6fb0d916c4920bcb5c2b0466600a1",
            "3dd97e2fe34c496ab63ab2a9f7f27ec8",
            "9cbdd0dcd4db48e889db9a7b602a41ba",
            "3d8111064cc94a06a92a01cdae7151d8",
            "31aaf6aeb2254df78bcf0ed8fcf80b9c",
            "6e66c90ca5d540e2bbb10dab9651a7f9",
            "c08749bb608e4ff0a6a2ed3b5ff6c509",
            "fcae8b3e2a244cdaa9902e3dae36b42d",
            "3310dca427194071ae04c184b20ff35a",
            "07c041f236db43e5a2b98790ff153c77",
            "74204cf69d96418cbab47ee2eb485c73",
            "8fcafa3eeaae4457be5a5622d14deebb",
            "91ba248fe5ae45c48cfd45be1caa0eed",
            "7f1a9c1182864915a74f28385c19a978",
            "e70f7c3055a3495580b28d279c9b26fc",
            "fde1130f853a44bba3533bd5a740933b",
            "e7594f45a779496fbf4ca0a2f1f53648",
            "8e954c4861d14450abca52bfdb548a70",
            "e14e7c8284f84aff8b72cd65ae0e6b8b",
            "9333eba7c07244cda5aba8c26f411777",
            "e0cd625927d24e109d2da782ac7e5d8f",
            "5f44c77e13d84aeaaeb3d8f2e440dc22",
            "519e164c3fb04bdfbbf756d491bf002b",
            "83870dc38b824fb283e45052901f1c9b",
            "72cd527c41bc4205b59b154874d1e40c",
            "9909c400cd644bb39827fff0d3c8aca6",
            "986f4fd5fb854cf6b80b4d8ea654cde9",
            "75661269209142db9ae6ad400a38e6e9",
            "041c9a8a1be344be8e7717ff74919b98",
            "3d350afc12ab473ea9e1f9bde6108061",
            "93f88a79156d43129cdff053692cc319",
            "1b75de7f09014c8cafe1526969bb50f8",
            "9e9ae30b55194b1e90c62890d6edcd3e",
            "fe849fc4e45a4a47adfab93294ca58c3",
            "e75d34cb1c5a46beba91071b78e3fa00",
            "8f8cbd0b220245729582b8f0fe30ec7e",
            "9cceefb41e7144a399627f19b17aff2c",
            "26742eb2883a45558cda726aabc41e94",
            "fd86e5ecf89a4783a556557ebf63339f",
            "78d52299c1304e5683afefb5abccc62d",
            "ce85a9b1a3a54849870d1ce22170fcf1",
            "b13f3e5601fe44f28086ae42455e4908",
            "0e9a95664b024e8b8046876e9b0d13ac",
            "e00b963560614da7bcf69de5e7486b4f",
            "d3129c1f28d845bab5f4388e5fd3cbca",
            "b30116afc0934754a7494b5b8738be28",
            "e6c4353117ac477dbee918e0882906ce",
            "1172e772d82342c0a751cb547bb590d1",
            "17a0f1208e694338b9bc1a15bd311ce1"
          ]
        },
        "id": "9ZoeiD6g9Fuj",
        "outputId": "8ae082b2-0a51-4225-bdc9-c00597983fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-04-07 08:12:51 - Directory /root/.deepface has been created\n",
            "25-04-07 08:12:51 - Directory /root/.deepface/weights has been created\n",
            "Loading ASR model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "370cc7a1b6374d3a9387e15b121d16a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b360d66571b46cd90fa5ee488531452"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "071bbf9b9cb24446a72202e4c0e1e51b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b81b13e49f9343ceb192ed7de222a8d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90ecb08a826145208bdf6fe498159e3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "884a0cbb0e0242199abdb04975dae6b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3d684c979c844378be706e3ca870a97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36fbe54bc9c44887a1293c06fbbb940b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad5814cca82846da8e3f1aaac71a026a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "512fa581b87a4036b5cb55709bfe155e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53ac8a73f42942388470f28cb21d4af7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASR model loaded successfully\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52c9110f3cc74e7a8cfa3aa9e3e20f52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5953442be4748ceac3b59f8ef1d23c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e81158a93f847ceb439a76c7c5e65f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37ac812fb9bd4d3495bd92c7fdb93aef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d04a5f20ac7d4695b9d8d1e2e73b4774"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8f699bc52d242e28449b7d37cc5881f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "622ea547eef64b7ba3897d904c6f4e9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e66c90ca5d540e2bbb10dab9651a7f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7594f45a779496fbf4ca0a2f1f53648"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75661269209142db9ae6ad400a38e6e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd86e5ecf89a4783a556557ebf63339f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://c88394400feee8b4e3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c88394400feee8b4e3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-04-07 08:19:44 - facial_expression_model_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5\n",
            "To: /root/.deepface/weights/facial_expression_model_weights.h5\n",
            "100%|██████████| 5.98M/5.98M [00:00<00:00, 67.7MB/s]\n",
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://c88394400feee8b4e3.gradio.live\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO22X1rcNzXY6SYNNFS0wU2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "370cc7a1b6374d3a9387e15b121d16a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2aa3559b869f422a951a520249b5677d",
              "IPY_MODEL_5af238e961684261bc1babfd693952d1",
              "IPY_MODEL_b249dc843c0543aea9b25b11872facb8"
            ],
            "layout": "IPY_MODEL_137588a8c8224bc995b43cbd769dfd57"
          }
        },
        "2aa3559b869f422a951a520249b5677d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b0fb004c164213a77ea3e5bc7e3fd8",
            "placeholder": "​",
            "style": "IPY_MODEL_3ccf6f3669bd4fce846a032e61c32d2f",
            "value": "config.json: 100%"
          }
        },
        "5af238e961684261bc1babfd693952d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee6916ec91e14581afa98c045ea79164",
            "max": 1967,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aceb5d76c7db4a1887297089b956a461",
            "value": 1967
          }
        },
        "b249dc843c0543aea9b25b11872facb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6499123fd3674f869d450cb5be6505d5",
            "placeholder": "​",
            "style": "IPY_MODEL_b8b3947043e344fdbb464b699704d9f8",
            "value": " 1.97k/1.97k [00:00&lt;00:00, 170kB/s]"
          }
        },
        "137588a8c8224bc995b43cbd769dfd57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82b0fb004c164213a77ea3e5bc7e3fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ccf6f3669bd4fce846a032e61c32d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee6916ec91e14581afa98c045ea79164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aceb5d76c7db4a1887297089b956a461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6499123fd3674f869d450cb5be6505d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b3947043e344fdbb464b699704d9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b360d66571b46cd90fa5ee488531452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab5372a32d5b49c2a2f2fb2f13751900",
              "IPY_MODEL_6b958901eec0490295022ff481204cd6",
              "IPY_MODEL_d92897c9e50b4ad48460f56456c9d985"
            ],
            "layout": "IPY_MODEL_905993ae0d6c436a804098439c0138b3"
          }
        },
        "ab5372a32d5b49c2a2f2fb2f13751900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bf07f841d0e4017b58f190f91e09da5",
            "placeholder": "​",
            "style": "IPY_MODEL_23fc4d16abd24e5e8c6480dca267fb2b",
            "value": "model.safetensors: 100%"
          }
        },
        "6b958901eec0490295022ff481204cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ba228a367ba48cab274c2c308d9623a",
            "max": 966995080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50c00b4e1e354a4881fd41374d00429d",
            "value": 966995080
          }
        },
        "d92897c9e50b4ad48460f56456c9d985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d6ee5f6a7024699942b93597ef1e58c",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a4ae0a96754ef88ce31a72babff96d",
            "value": " 967M/967M [00:06&lt;00:00, 158MB/s]"
          }
        },
        "905993ae0d6c436a804098439c0138b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bf07f841d0e4017b58f190f91e09da5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23fc4d16abd24e5e8c6480dca267fb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ba228a367ba48cab274c2c308d9623a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c00b4e1e354a4881fd41374d00429d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d6ee5f6a7024699942b93597ef1e58c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a4ae0a96754ef88ce31a72babff96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "071bbf9b9cb24446a72202e4c0e1e51b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95aec29eb78344c58729eb0a942b5eea",
              "IPY_MODEL_857ce1c7db454f748ff5629b75a26bfe",
              "IPY_MODEL_1c98f72d983f4c7184b0eb8fa5219f97"
            ],
            "layout": "IPY_MODEL_77772639f072474e878940bcaf32ffd3"
          }
        },
        "95aec29eb78344c58729eb0a942b5eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0319c60aced1450c8d7811c617c87e0f",
            "placeholder": "​",
            "style": "IPY_MODEL_926eb3c71e4d4b67bc13239e88246566",
            "value": "generation_config.json: 100%"
          }
        },
        "857ce1c7db454f748ff5629b75a26bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f2cc379fc248babc7f02460b7937e5",
            "max": 3868,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c6a5717c7424eda9c0011da7bcb4c40",
            "value": 3868
          }
        },
        "1c98f72d983f4c7184b0eb8fa5219f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfcf9bb3e3dc4a6ab7f6be7caa70c3d6",
            "placeholder": "​",
            "style": "IPY_MODEL_92c3368458ba45bd9b4c58f77aefaba2",
            "value": " 3.87k/3.87k [00:00&lt;00:00, 207kB/s]"
          }
        },
        "77772639f072474e878940bcaf32ffd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0319c60aced1450c8d7811c617c87e0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "926eb3c71e4d4b67bc13239e88246566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f2cc379fc248babc7f02460b7937e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6a5717c7424eda9c0011da7bcb4c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfcf9bb3e3dc4a6ab7f6be7caa70c3d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92c3368458ba45bd9b4c58f77aefaba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b81b13e49f9343ceb192ed7de222a8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a0b75e81fb945e29454542b0a3f7ad2",
              "IPY_MODEL_bde8d669e8864fb2a171e7815c8b159c",
              "IPY_MODEL_3c11e51ca8d149209becd3ea62d207cd"
            ],
            "layout": "IPY_MODEL_2f90c9e1e8ef41fda5c2f7c517df6672"
          }
        },
        "3a0b75e81fb945e29454542b0a3f7ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9fa5b155381457d948022170fae02b0",
            "placeholder": "​",
            "style": "IPY_MODEL_ab8144edbf3049b1ba043b2569a1e164",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "bde8d669e8864fb2a171e7815c8b159c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69d836347ead477eb5f1a680cdc06731",
            "max": 282683,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d5e5dc8c92146d4bace3773f93f6e4b",
            "value": 282683
          }
        },
        "3c11e51ca8d149209becd3ea62d207cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf9bfd3e5b4745f9bc01f1576dea7484",
            "placeholder": "​",
            "style": "IPY_MODEL_30582e7e64d34a23ae7a397c9ffb5342",
            "value": " 283k/283k [00:00&lt;00:00, 1.47MB/s]"
          }
        },
        "2f90c9e1e8ef41fda5c2f7c517df6672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9fa5b155381457d948022170fae02b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab8144edbf3049b1ba043b2569a1e164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69d836347ead477eb5f1a680cdc06731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d5e5dc8c92146d4bace3773f93f6e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf9bfd3e5b4745f9bc01f1576dea7484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30582e7e64d34a23ae7a397c9ffb5342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90ecb08a826145208bdf6fe498159e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1a2c0f070e641db9d4e7a8d09927e53",
              "IPY_MODEL_03ea1621ce51407fabdacd68ed8b0ba4",
              "IPY_MODEL_46b8b624fed74c188dccb7906aea5d13"
            ],
            "layout": "IPY_MODEL_e7e238cd7f2944c9ad8dc405edc89b04"
          }
        },
        "b1a2c0f070e641db9d4e7a8d09927e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7370eb06386247918474cc092c4f1f05",
            "placeholder": "​",
            "style": "IPY_MODEL_5361c03f76f249799573d9f71db29f7f",
            "value": "vocab.json: 100%"
          }
        },
        "03ea1621ce51407fabdacd68ed8b0ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aeca07fa761417fafb635a8a8859804",
            "max": 835550,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c1440b5e5f84e16b3b3c3ca52a6c138",
            "value": 835550
          }
        },
        "46b8b624fed74c188dccb7906aea5d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d98ac8621b74f348ee5cb5bfb44824e",
            "placeholder": "​",
            "style": "IPY_MODEL_16977cefb1144367823a4c3df7ecaf89",
            "value": " 836k/836k [00:00&lt;00:00, 1.69MB/s]"
          }
        },
        "e7e238cd7f2944c9ad8dc405edc89b04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7370eb06386247918474cc092c4f1f05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5361c03f76f249799573d9f71db29f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3aeca07fa761417fafb635a8a8859804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c1440b5e5f84e16b3b3c3ca52a6c138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d98ac8621b74f348ee5cb5bfb44824e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16977cefb1144367823a4c3df7ecaf89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "884a0cbb0e0242199abdb04975dae6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98a9bca1201e422fbd00c072c8a4e848",
              "IPY_MODEL_6ce3d09bf9924e1e8bec0ad4eb355b80",
              "IPY_MODEL_28adb847f5e247be9df00708b5663499"
            ],
            "layout": "IPY_MODEL_be293cba84744b1ba58b6840ad60f738"
          }
        },
        "98a9bca1201e422fbd00c072c8a4e848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78ba7ddd97384639b17d47f2a7d60846",
            "placeholder": "​",
            "style": "IPY_MODEL_3081d2d0dde54c3ea6e09f336133749e",
            "value": "tokenizer.json: 100%"
          }
        },
        "6ce3d09bf9924e1e8bec0ad4eb355b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37567432cc6548ca8c8c7cb86e33a9d7",
            "max": 2480466,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2544e5259a0243e9bee1c3a85508c123",
            "value": 2480466
          }
        },
        "28adb847f5e247be9df00708b5663499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bb093f6846b40fab3cb1e78973bfba0",
            "placeholder": "​",
            "style": "IPY_MODEL_5d720b2f1f8a46e187ede24b23310082",
            "value": " 2.48M/2.48M [00:00&lt;00:00, 20.6MB/s]"
          }
        },
        "be293cba84744b1ba58b6840ad60f738": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78ba7ddd97384639b17d47f2a7d60846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3081d2d0dde54c3ea6e09f336133749e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37567432cc6548ca8c8c7cb86e33a9d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2544e5259a0243e9bee1c3a85508c123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bb093f6846b40fab3cb1e78973bfba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d720b2f1f8a46e187ede24b23310082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3d684c979c844378be706e3ca870a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80db1c21b9ea498d90cef92cb136cde5",
              "IPY_MODEL_a908bbff04b84fb489e9638fb239043b",
              "IPY_MODEL_37970f550d304f1fa4ce6ec002276f4f"
            ],
            "layout": "IPY_MODEL_d3bc907a4da34965b614b5ad4cad93b9"
          }
        },
        "80db1c21b9ea498d90cef92cb136cde5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f60f38d3b2548d3a795f37d9e1df515",
            "placeholder": "​",
            "style": "IPY_MODEL_b1477ac7350b4860976f4c04eec33fbb",
            "value": "merges.txt: 100%"
          }
        },
        "a908bbff04b84fb489e9638fb239043b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7025123998471c9d4a34771d57ac8f",
            "max": 493869,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c60cf7cad6214d03950913dd8a19185a",
            "value": 493869
          }
        },
        "37970f550d304f1fa4ce6ec002276f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa58070574104e769c957af366e208d8",
            "placeholder": "​",
            "style": "IPY_MODEL_11d316e05d8f4e2cb1d3689f3c014e6b",
            "value": " 494k/494k [00:00&lt;00:00, 33.4MB/s]"
          }
        },
        "d3bc907a4da34965b614b5ad4cad93b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f60f38d3b2548d3a795f37d9e1df515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1477ac7350b4860976f4c04eec33fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c7025123998471c9d4a34771d57ac8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c60cf7cad6214d03950913dd8a19185a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa58070574104e769c957af366e208d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11d316e05d8f4e2cb1d3689f3c014e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36fbe54bc9c44887a1293c06fbbb940b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e014af11a1348e38ef1dd703d0d91a1",
              "IPY_MODEL_c25af8020d5e4463b285e33653045bd6",
              "IPY_MODEL_798c0c339eae417fba894939a05e783a"
            ],
            "layout": "IPY_MODEL_39c3a165ab314b389f380ed627ceb622"
          }
        },
        "7e014af11a1348e38ef1dd703d0d91a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aac48fb2821e42b390de276cf6e98715",
            "placeholder": "​",
            "style": "IPY_MODEL_7fdcce0811914de782983b0efdae1e6e",
            "value": "normalizer.json: 100%"
          }
        },
        "c25af8020d5e4463b285e33653045bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89813208ed8548fb9824ec39b4877d11",
            "max": 52666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eacaca0d6a354d32b2b616cfb132d107",
            "value": 52666
          }
        },
        "798c0c339eae417fba894939a05e783a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_453c605778554d99af1ce640ae747271",
            "placeholder": "​",
            "style": "IPY_MODEL_b998191a82dd4827a684d40cfef23b83",
            "value": " 52.7k/52.7k [00:00&lt;00:00, 3.86MB/s]"
          }
        },
        "39c3a165ab314b389f380ed627ceb622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aac48fb2821e42b390de276cf6e98715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fdcce0811914de782983b0efdae1e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89813208ed8548fb9824ec39b4877d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eacaca0d6a354d32b2b616cfb132d107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "453c605778554d99af1ce640ae747271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b998191a82dd4827a684d40cfef23b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad5814cca82846da8e3f1aaac71a026a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c709a8de2a94e9dbb2cbb6a506af8be",
              "IPY_MODEL_4fd8cc00ccc649ec88ce66d2da5ffc8e",
              "IPY_MODEL_88e84df38fc245828457fb898b58f528"
            ],
            "layout": "IPY_MODEL_7faf920f90254c9fa14fc0c55ed0ff52"
          }
        },
        "9c709a8de2a94e9dbb2cbb6a506af8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4096378b8dff42d2b1f674fe1256c9e4",
            "placeholder": "​",
            "style": "IPY_MODEL_649a3ee122034fb39ceadf96c1f64c91",
            "value": "added_tokens.json: 100%"
          }
        },
        "4fd8cc00ccc649ec88ce66d2da5ffc8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2bc09141e540fd949d928ee2c83e1c",
            "max": 34604,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc67461b0435479ca2bf018f6f01f37b",
            "value": 34604
          }
        },
        "88e84df38fc245828457fb898b58f528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dba659b9dc7478cb926e671aa511f84",
            "placeholder": "​",
            "style": "IPY_MODEL_6045bf4bc1d6442b9fe1bb6c71c4d27e",
            "value": " 34.6k/34.6k [00:00&lt;00:00, 2.51MB/s]"
          }
        },
        "7faf920f90254c9fa14fc0c55ed0ff52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4096378b8dff42d2b1f674fe1256c9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "649a3ee122034fb39ceadf96c1f64c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d2bc09141e540fd949d928ee2c83e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc67461b0435479ca2bf018f6f01f37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dba659b9dc7478cb926e671aa511f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6045bf4bc1d6442b9fe1bb6c71c4d27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "512fa581b87a4036b5cb55709bfe155e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_711453d118144313b19f92f632510441",
              "IPY_MODEL_2d8fa7ff10a8483ba9c9997769a755ef",
              "IPY_MODEL_2e86532f96ce47bb9792c744b1875def"
            ],
            "layout": "IPY_MODEL_4eaba67ff4064650921a6a58f50ddf75"
          }
        },
        "711453d118144313b19f92f632510441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f5ad7c76edf48279725de015ee14f74",
            "placeholder": "​",
            "style": "IPY_MODEL_5911ec9bf4d341ec8961776a079df4b3",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "2d8fa7ff10a8483ba9c9997769a755ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01023f6c24c54fde85659d13a6ddbc50",
            "max": 2194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64075d77c272452ca5c0aa7bcf6afa13",
            "value": 2194
          }
        },
        "2e86532f96ce47bb9792c744b1875def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a42179c01374db587e5cf5e0fba41eb",
            "placeholder": "​",
            "style": "IPY_MODEL_d8cffcba7e424149b672dfa17d74f24f",
            "value": " 2.19k/2.19k [00:00&lt;00:00, 197kB/s]"
          }
        },
        "4eaba67ff4064650921a6a58f50ddf75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f5ad7c76edf48279725de015ee14f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5911ec9bf4d341ec8961776a079df4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01023f6c24c54fde85659d13a6ddbc50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64075d77c272452ca5c0aa7bcf6afa13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a42179c01374db587e5cf5e0fba41eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8cffcba7e424149b672dfa17d74f24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53ac8a73f42942388470f28cb21d4af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c57181159da44409999aae105cfec1f",
              "IPY_MODEL_0d12c8e068c54112b4586cf602370573",
              "IPY_MODEL_14ee3c8bf09a4c43bcc8503310949063"
            ],
            "layout": "IPY_MODEL_170948a3296f43d4882de456e4920890"
          }
        },
        "8c57181159da44409999aae105cfec1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19b8b42dc1a5434587e417f1bb9fb9e0",
            "placeholder": "​",
            "style": "IPY_MODEL_106fd877a0d849ac95f81efbbc0aa170",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "0d12c8e068c54112b4586cf602370573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73aeef42e9e24a2a885c06bfd8f242f4",
            "max": 184990,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_facf4a23824949e7836bb04ae7500c76",
            "value": 184990
          }
        },
        "14ee3c8bf09a4c43bcc8503310949063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fe2d00ac0da49468d43eb0f797ae6ea",
            "placeholder": "​",
            "style": "IPY_MODEL_14418fa02ad5451698e5694ca57cefdb",
            "value": " 185k/185k [00:00&lt;00:00, 13.6MB/s]"
          }
        },
        "170948a3296f43d4882de456e4920890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19b8b42dc1a5434587e417f1bb9fb9e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106fd877a0d849ac95f81efbbc0aa170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73aeef42e9e24a2a885c06bfd8f242f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "facf4a23824949e7836bb04ae7500c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fe2d00ac0da49468d43eb0f797ae6ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14418fa02ad5451698e5694ca57cefdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52c9110f3cc74e7a8cfa3aa9e3e20f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b450c136f654665afc7a94823cf0b3c",
              "IPY_MODEL_f50c640d47d14a84802748ae40d63a17",
              "IPY_MODEL_e8071ed6ed8f4b11b1d7688aa3a0ce7c"
            ],
            "layout": "IPY_MODEL_ff4329d1322b4a429bbca2b9da70f021"
          }
        },
        "5b450c136f654665afc7a94823cf0b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b4be3ca5cd648e392eba8b13f9a363c",
            "placeholder": "​",
            "style": "IPY_MODEL_b4f57957004c498ca0446641698e6e8d",
            "value": "modules.json: 100%"
          }
        },
        "f50c640d47d14a84802748ae40d63a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ad5fc5ec9684782b6133962adde07db",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dd698af020743aba5c9f5ef9a78e327",
            "value": 349
          }
        },
        "e8071ed6ed8f4b11b1d7688aa3a0ce7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20cb458610314b4d8dfc4c38f609624a",
            "placeholder": "​",
            "style": "IPY_MODEL_ab7812ae0fe241caa8ee57aee6737450",
            "value": " 349/349 [00:00&lt;00:00, 19.2kB/s]"
          }
        },
        "ff4329d1322b4a429bbca2b9da70f021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b4be3ca5cd648e392eba8b13f9a363c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f57957004c498ca0446641698e6e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ad5fc5ec9684782b6133962adde07db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd698af020743aba5c9f5ef9a78e327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20cb458610314b4d8dfc4c38f609624a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7812ae0fe241caa8ee57aee6737450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5953442be4748ceac3b59f8ef1d23c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5ad91de34a04d60aa3a2f5f057b8d48",
              "IPY_MODEL_04442f15331c41f48c2bf5942d92b13e",
              "IPY_MODEL_195644d78ff34a089413632636b363a0"
            ],
            "layout": "IPY_MODEL_ca3542cc2f2f4fa49e9dcb5703431065"
          }
        },
        "c5ad91de34a04d60aa3a2f5f057b8d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67c9233b7e0b4a1cb2e4493faeb902cd",
            "placeholder": "​",
            "style": "IPY_MODEL_e47964a54bf84e5c9f336dc5b30adae0",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "04442f15331c41f48c2bf5942d92b13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c50e15aeb8914e6b81487066f098824d",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b56694bab5049b8934175b48ff3edac",
            "value": 116
          }
        },
        "195644d78ff34a089413632636b363a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3ba80e2c6ea45378dbbf493432c179f",
            "placeholder": "​",
            "style": "IPY_MODEL_4b2fa30750554af987b6961bb239e87f",
            "value": " 116/116 [00:00&lt;00:00, 11.4kB/s]"
          }
        },
        "ca3542cc2f2f4fa49e9dcb5703431065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67c9233b7e0b4a1cb2e4493faeb902cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e47964a54bf84e5c9f336dc5b30adae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c50e15aeb8914e6b81487066f098824d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b56694bab5049b8934175b48ff3edac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3ba80e2c6ea45378dbbf493432c179f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2fa30750554af987b6961bb239e87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e81158a93f847ceb439a76c7c5e65f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acf5051e6e854ef790c8ca573c56abc3",
              "IPY_MODEL_764f09f70511431b9cfe629406a71532",
              "IPY_MODEL_38ea2f3e83ef496fa1636c00497a03c7"
            ],
            "layout": "IPY_MODEL_56ec5da979494895ba69ef8a795a17c7"
          }
        },
        "acf5051e6e854ef790c8ca573c56abc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a680ddaee77949ed9d4f2eed02a3e663",
            "placeholder": "​",
            "style": "IPY_MODEL_17a29b8a33dc49bb97c5d97e55c47a7d",
            "value": "README.md: 100%"
          }
        },
        "764f09f70511431b9cfe629406a71532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb95c56456f4444b9523b6197cfcde1",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57905346640c4efba10b182716ad7db1",
            "value": 10454
          }
        },
        "38ea2f3e83ef496fa1636c00497a03c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72285e7ec4d64c9295912cedd9316c3f",
            "placeholder": "​",
            "style": "IPY_MODEL_18c696d3bb02431993cb762ed0db36e8",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 707kB/s]"
          }
        },
        "56ec5da979494895ba69ef8a795a17c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a680ddaee77949ed9d4f2eed02a3e663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a29b8a33dc49bb97c5d97e55c47a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bb95c56456f4444b9523b6197cfcde1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57905346640c4efba10b182716ad7db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72285e7ec4d64c9295912cedd9316c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18c696d3bb02431993cb762ed0db36e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37ac812fb9bd4d3495bd92c7fdb93aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7ff7c2c32fc45e0933e164e4c407df9",
              "IPY_MODEL_bdaaa83611954d2895cb808c55b58a81",
              "IPY_MODEL_80f51ba165e14970acefceae0dd041bb"
            ],
            "layout": "IPY_MODEL_91a76ba5742b423cb6fbe21272e68f4a"
          }
        },
        "f7ff7c2c32fc45e0933e164e4c407df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_956ed9c47a664397ab2ccebf2490afce",
            "placeholder": "​",
            "style": "IPY_MODEL_48c3f62b19884e4f9a984a70ee0f7fb4",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "bdaaa83611954d2895cb808c55b58a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28871d2f2d5a44b38d9083b6d89858d5",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7a2b5ce26604ec1919e4840ecf2c814",
            "value": 53
          }
        },
        "80f51ba165e14970acefceae0dd041bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f22528f56909462bb58400a6cbbfac24",
            "placeholder": "​",
            "style": "IPY_MODEL_47de78eefb334071823ac3fa71137a95",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.32kB/s]"
          }
        },
        "91a76ba5742b423cb6fbe21272e68f4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956ed9c47a664397ab2ccebf2490afce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48c3f62b19884e4f9a984a70ee0f7fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28871d2f2d5a44b38d9083b6d89858d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7a2b5ce26604ec1919e4840ecf2c814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f22528f56909462bb58400a6cbbfac24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47de78eefb334071823ac3fa71137a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d04a5f20ac7d4695b9d8d1e2e73b4774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2be75e9097244534abe10d2795845e59",
              "IPY_MODEL_f509c775e2c94fa49ff6aa779cfb9112",
              "IPY_MODEL_20cfe73a1891425f820ca8fb031ce853"
            ],
            "layout": "IPY_MODEL_ae57e6b3602940f9ba319a6aadecb1ce"
          }
        },
        "2be75e9097244534abe10d2795845e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9630b5cd99e84b13ad48d60d4ad3a82b",
            "placeholder": "​",
            "style": "IPY_MODEL_dd4dead8258f42a6b6334e10e07f56a5",
            "value": "config.json: 100%"
          }
        },
        "f509c775e2c94fa49ff6aa779cfb9112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef9ded3d27d04c5e85118e58d3268708",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90f89d66357c4a178222d9300490c30b",
            "value": 612
          }
        },
        "20cfe73a1891425f820ca8fb031ce853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9be16436fbd541b2b8a5a42a8ec1d73e",
            "placeholder": "​",
            "style": "IPY_MODEL_a7dcef8c2c354584bd619d709abd0f4d",
            "value": " 612/612 [00:00&lt;00:00, 46.8kB/s]"
          }
        },
        "ae57e6b3602940f9ba319a6aadecb1ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9630b5cd99e84b13ad48d60d4ad3a82b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd4dead8258f42a6b6334e10e07f56a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef9ded3d27d04c5e85118e58d3268708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90f89d66357c4a178222d9300490c30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9be16436fbd541b2b8a5a42a8ec1d73e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7dcef8c2c354584bd619d709abd0f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8f699bc52d242e28449b7d37cc5881f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57d6aacc13594e86985792fd924d603d",
              "IPY_MODEL_40e575f8b910422ea8ddea0fbf049a2a",
              "IPY_MODEL_e6031fc257864d2ba154e61c8c461acc"
            ],
            "layout": "IPY_MODEL_53cfa7559aa74ddd80e13edafa6d3eb0"
          }
        },
        "57d6aacc13594e86985792fd924d603d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48675ea348543e4902220065b0ee7cc",
            "placeholder": "​",
            "style": "IPY_MODEL_e5b18c973e9c4ff2ab8a02485a770068",
            "value": "model.safetensors: 100%"
          }
        },
        "40e575f8b910422ea8ddea0fbf049a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71fb1652cac9424992677e464d03d193",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dc4dc8be538452c9e760c29ad618a81",
            "value": 90868376
          }
        },
        "e6031fc257864d2ba154e61c8c461acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06fa76c3ada848319edf1d34e86fe83f",
            "placeholder": "​",
            "style": "IPY_MODEL_3882adcfb842499380b359e197b3747f",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 174MB/s]"
          }
        },
        "53cfa7559aa74ddd80e13edafa6d3eb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48675ea348543e4902220065b0ee7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b18c973e9c4ff2ab8a02485a770068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71fb1652cac9424992677e464d03d193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dc4dc8be538452c9e760c29ad618a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06fa76c3ada848319edf1d34e86fe83f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3882adcfb842499380b359e197b3747f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "622ea547eef64b7ba3897d904c6f4e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d508d579dca3499ea22dc852e0cb5c2d",
              "IPY_MODEL_265ef17cb5b643ee9a60cf4f61b74c42",
              "IPY_MODEL_4d4b90e09eb847699ca806587da813c2"
            ],
            "layout": "IPY_MODEL_7efd31911de544c2ad3bbb5db2872b23"
          }
        },
        "d508d579dca3499ea22dc852e0cb5c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe8fd14045f4c03848e3974b25fe7ba",
            "placeholder": "​",
            "style": "IPY_MODEL_12e6fb0d916c4920bcb5c2b0466600a1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "265ef17cb5b643ee9a60cf4f61b74c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd97e2fe34c496ab63ab2a9f7f27ec8",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cbdd0dcd4db48e889db9a7b602a41ba",
            "value": 350
          }
        },
        "4d4b90e09eb847699ca806587da813c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d8111064cc94a06a92a01cdae7151d8",
            "placeholder": "​",
            "style": "IPY_MODEL_31aaf6aeb2254df78bcf0ed8fcf80b9c",
            "value": " 350/350 [00:00&lt;00:00, 20.2kB/s]"
          }
        },
        "7efd31911de544c2ad3bbb5db2872b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe8fd14045f4c03848e3974b25fe7ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e6fb0d916c4920bcb5c2b0466600a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd97e2fe34c496ab63ab2a9f7f27ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cbdd0dcd4db48e889db9a7b602a41ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d8111064cc94a06a92a01cdae7151d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31aaf6aeb2254df78bcf0ed8fcf80b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e66c90ca5d540e2bbb10dab9651a7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c08749bb608e4ff0a6a2ed3b5ff6c509",
              "IPY_MODEL_fcae8b3e2a244cdaa9902e3dae36b42d",
              "IPY_MODEL_3310dca427194071ae04c184b20ff35a"
            ],
            "layout": "IPY_MODEL_07c041f236db43e5a2b98790ff153c77"
          }
        },
        "c08749bb608e4ff0a6a2ed3b5ff6c509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74204cf69d96418cbab47ee2eb485c73",
            "placeholder": "​",
            "style": "IPY_MODEL_8fcafa3eeaae4457be5a5622d14deebb",
            "value": "vocab.txt: 100%"
          }
        },
        "fcae8b3e2a244cdaa9902e3dae36b42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91ba248fe5ae45c48cfd45be1caa0eed",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f1a9c1182864915a74f28385c19a978",
            "value": 231508
          }
        },
        "3310dca427194071ae04c184b20ff35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e70f7c3055a3495580b28d279c9b26fc",
            "placeholder": "​",
            "style": "IPY_MODEL_fde1130f853a44bba3533bd5a740933b",
            "value": " 232k/232k [00:00&lt;00:00, 14.0MB/s]"
          }
        },
        "07c041f236db43e5a2b98790ff153c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74204cf69d96418cbab47ee2eb485c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fcafa3eeaae4457be5a5622d14deebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91ba248fe5ae45c48cfd45be1caa0eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f1a9c1182864915a74f28385c19a978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e70f7c3055a3495580b28d279c9b26fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fde1130f853a44bba3533bd5a740933b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7594f45a779496fbf4ca0a2f1f53648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e954c4861d14450abca52bfdb548a70",
              "IPY_MODEL_e14e7c8284f84aff8b72cd65ae0e6b8b",
              "IPY_MODEL_9333eba7c07244cda5aba8c26f411777"
            ],
            "layout": "IPY_MODEL_e0cd625927d24e109d2da782ac7e5d8f"
          }
        },
        "8e954c4861d14450abca52bfdb548a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f44c77e13d84aeaaeb3d8f2e440dc22",
            "placeholder": "​",
            "style": "IPY_MODEL_519e164c3fb04bdfbbf756d491bf002b",
            "value": "tokenizer.json: 100%"
          }
        },
        "e14e7c8284f84aff8b72cd65ae0e6b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83870dc38b824fb283e45052901f1c9b",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72cd527c41bc4205b59b154874d1e40c",
            "value": 466247
          }
        },
        "9333eba7c07244cda5aba8c26f411777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9909c400cd644bb39827fff0d3c8aca6",
            "placeholder": "​",
            "style": "IPY_MODEL_986f4fd5fb854cf6b80b4d8ea654cde9",
            "value": " 466k/466k [00:00&lt;00:00, 825kB/s]"
          }
        },
        "e0cd625927d24e109d2da782ac7e5d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f44c77e13d84aeaaeb3d8f2e440dc22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "519e164c3fb04bdfbbf756d491bf002b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83870dc38b824fb283e45052901f1c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72cd527c41bc4205b59b154874d1e40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9909c400cd644bb39827fff0d3c8aca6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "986f4fd5fb854cf6b80b4d8ea654cde9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75661269209142db9ae6ad400a38e6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_041c9a8a1be344be8e7717ff74919b98",
              "IPY_MODEL_3d350afc12ab473ea9e1f9bde6108061",
              "IPY_MODEL_93f88a79156d43129cdff053692cc319"
            ],
            "layout": "IPY_MODEL_1b75de7f09014c8cafe1526969bb50f8"
          }
        },
        "041c9a8a1be344be8e7717ff74919b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9ae30b55194b1e90c62890d6edcd3e",
            "placeholder": "​",
            "style": "IPY_MODEL_fe849fc4e45a4a47adfab93294ca58c3",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3d350afc12ab473ea9e1f9bde6108061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e75d34cb1c5a46beba91071b78e3fa00",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f8cbd0b220245729582b8f0fe30ec7e",
            "value": 112
          }
        },
        "93f88a79156d43129cdff053692cc319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cceefb41e7144a399627f19b17aff2c",
            "placeholder": "​",
            "style": "IPY_MODEL_26742eb2883a45558cda726aabc41e94",
            "value": " 112/112 [00:00&lt;00:00, 5.51kB/s]"
          }
        },
        "1b75de7f09014c8cafe1526969bb50f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e9ae30b55194b1e90c62890d6edcd3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe849fc4e45a4a47adfab93294ca58c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e75d34cb1c5a46beba91071b78e3fa00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f8cbd0b220245729582b8f0fe30ec7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cceefb41e7144a399627f19b17aff2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26742eb2883a45558cda726aabc41e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd86e5ecf89a4783a556557ebf63339f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78d52299c1304e5683afefb5abccc62d",
              "IPY_MODEL_ce85a9b1a3a54849870d1ce22170fcf1",
              "IPY_MODEL_b13f3e5601fe44f28086ae42455e4908"
            ],
            "layout": "IPY_MODEL_0e9a95664b024e8b8046876e9b0d13ac"
          }
        },
        "78d52299c1304e5683afefb5abccc62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e00b963560614da7bcf69de5e7486b4f",
            "placeholder": "​",
            "style": "IPY_MODEL_d3129c1f28d845bab5f4388e5fd3cbca",
            "value": "config.json: 100%"
          }
        },
        "ce85a9b1a3a54849870d1ce22170fcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b30116afc0934754a7494b5b8738be28",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6c4353117ac477dbee918e0882906ce",
            "value": 190
          }
        },
        "b13f3e5601fe44f28086ae42455e4908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1172e772d82342c0a751cb547bb590d1",
            "placeholder": "​",
            "style": "IPY_MODEL_17a0f1208e694338b9bc1a15bd311ce1",
            "value": " 190/190 [00:00&lt;00:00, 17.9kB/s]"
          }
        },
        "0e9a95664b024e8b8046876e9b0d13ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00b963560614da7bcf69de5e7486b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3129c1f28d845bab5f4388e5fd3cbca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b30116afc0934754a7494b5b8738be28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c4353117ac477dbee918e0882906ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1172e772d82342c0a751cb547bb590d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a0f1208e694338b9bc1a15bd311ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}